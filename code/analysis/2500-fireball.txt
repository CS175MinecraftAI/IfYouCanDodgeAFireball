Loading mission from ghast_survival_mission.xml
Iteration 2 Learning Q-Table
best: move_right current state : (0, -0.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 3 Learning Q-Table
best: nothing current state : (0, -0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.5, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.25, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 4 Learning Q-Table
best: nothing current state : (-1, -2, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -1.75, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.5, -9) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 5 Learning Q-Table
best: move_right current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -3, -9) 100 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -2, 2) 100 [('nothing', 0), ('move_left', 0)]
Reward: 144
Iteration 6 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, -1.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 7 Learning Q-Table
best: nothing current state : (0, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.25, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.75, -8) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 118
Iteration 8 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.5, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.0, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 9 Learning Q-Table
best: nothing current state : (0, 0.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -28.960180598157894)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -28.960180598157894)]
best: move_left current state : (0, 0.25, -18) -99.6991736329 [('nothing', -7.960180598157894), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.5, -8) -26.8347616943 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 180
Iteration 10 Learning Q-Table
best: nothing current state : (2, 3, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -20) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (0, -0.75, -9) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 170
Iteration 11 Learning Q-Table
best: move_right current state : (0, 0.0, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 0.0, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 42.6)]
Reward: 226
Iteration 12 Learning Q-Table
best: nothing current state : (-2, -3, -24) -100.0 [('nothing', 0), ('move_left', -28.96018059815789)]
best: nothing current state : (-2, -3, -24) -100.0 [('nothing', 0), ('move_left', -28.96018059815789)]
best: move_left current state : (-2, -2, -18) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -0.75, -8) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -50
Iteration 13 Learning Q-Table
best: nothing current state : (0, -1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.25, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -2, -8) -26.5339353272 [('nothing', 0), ('move_left', 0)]
Reward: 107
Iteration 14 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -28.96018059815789)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -28.96018059815789)]
best: nothing current state : (-1, -1.5, -19) -26.5339353272 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.75, -10) 150 [('nothing', 64.5), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 15 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 0.0, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.25, -8) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 16 Learning Q-Table
best: move_left current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 2, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.0, -9) -55.0161685623 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 17 Learning Q-Table
best: move_right current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -11.172491924096027)]
best: move_right current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -0.5, -19) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 18 Learning Q-Table
best: nothing current state : (0, -1.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.25, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -1.5, -7) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 19 Learning Q-Table
best: nothing current state : (-2, -3, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -2, -18) -100.0 [('nothing', 0), ('move_left', -30.0)]
best: nothing current state : (-1, 0.5, -8) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 118
Iteration 20 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 1.0, -17) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 21 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.5, -17) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.0, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 73
Iteration 22 Learning Q-Table
best: nothing current state : (2, 3, -24) -100.0 [('nothing', -30.0), ('move_right', -30.0)]
best: nothing current state : (2, 3, -24) -100.0 [('nothing', -30.0), ('move_right', -30.0)]
best: move_right current state : (2, 2, -18) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 0.75, -7) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: -100
Iteration 23 Learning Q-Table
best: move_left current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -7) 100 [('nothing', 0), ('move_right', 0)]
Reward: 116
Iteration 24 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -30.0)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -30.0)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 25 Learning Q-Table
best: move_right current state : (0, -0.0, -23) -100.0 [('nothing', -30.0), ('move_left', -29.909752089870274), ('move_right', -28.960180598157894)]
best: move_right current state : (0, -0.0, -23) -100.0 [('nothing', -30.0), ('move_left', -29.909752089870274), ('move_right', -28.960180598157894)]
best: move_left current state : (0, -0.0, -18) -37.241639747 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: move_right current state : (-1, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 97.62)]
Reward: 120
Iteration 26 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', -35.36353821304801)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', -35.36353821304801)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 27 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -53.17249192409602)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -53.17249192409602)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 64.5), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 28 Learning Q-Table
best: nothing current state : (0, 0.0, -24) -100.0 [('nothing', -28.960180598157894), ('move_left', -60.0), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 0.0, -24) -100.0 [('nothing', -28.960180598157894), ('move_left', -60.0), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 0.0, -18) -100.0 [('nothing', 0), ('move_left', 105.786), ('move_right', 0)]
best: nothing current state : (0, 0.25, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -45.0)]
Reward: -50
Iteration 29 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -28.96018059815789), ('move_right', 0)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -28.96018059815789), ('move_right', 0)]
best: move_left current state : (0, 0.25, -17) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 30 Learning Q-Table
best: move_right current state : (0, -0.0, -24) -100.0 [('nothing', -39.53632641871053), ('move_left', -60.0), ('move_right', -32.17249192409603)]
best: move_right current state : (0, -0.0, -24) -100.0 [('nothing', -39.53632641871053), ('move_left', -60.0), ('move_right', -32.17249192409603)]
best: move_left current state : (0, -1.25, -18) -26.5339353272 [('nothing', -7.960180598157904), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 104.334)]
best: move_left current state : (0, -2, 2) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 170
Iteration 31 Learning Q-Table
best: move_right current state : (-1, -2, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (-1, -2, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (-2, -2, -18) -63.803359642 [('nothing', -7.960180598157891), ('move_left', -30.0)]
best: nothing current state : (-2, -1.0, -7) -63.803359642 [('nothing', 0), ('move_left', 0)]
Reward: -250
Iteration 32 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -35.73230701686841)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -35.73230701686841)]
best: nothing current state : (-1, -1.5, -19) -37.241639747 [('nothing', 95.85), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 83.39999999999999), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 33 Learning Q-Table
best: nothing current state : (0, 0.0, -24) -100.0 [('nothing', -39.53632641871053), ('move_left', -60.0), ('move_right', -51.480924945025116)]
best: nothing current state : (0, 0.0, -24) -100.0 [('nothing', -39.53632641871053), ('move_left', -60.0), ('move_right', -51.480924945025116)]
best: move_right current state : (0, 0.25, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.5, -9) -100.0 [('nothing', 32.1), ('move_left', 0), ('move_right', 0)]
Reward: -50
Iteration 34 Learning Q-Table
best: nothing current state : (0, -1.75, -24) -100.0 [('nothing', -30.0), ('move_left', -32.17249192409603), ('move_right', -30.0)]
best: nothing current state : (0, -1.75, -24) -100.0 [('nothing', -30.0), ('move_left', -32.17249192409603), ('move_right', -30.0)]
best: move_left current state : (0, -1.25, -18) -100.0 [('nothing', -7.960180598157904), ('move_left', 76.3002), ('move_right', 0)]
best: nothing current state : (0, -0.5, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 35 Learning Q-Table
best: move_right current state : (0, 0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.75, -19) -37.5452564953 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -8) 100 [('nothing', 39.3), ('move_left', 0), ('move_right', 0)]
Reward: 44
Iteration 36 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -32.17249192409603), ('move_right', -35.36353821304801)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -32.17249192409603), ('move_right', -35.36353821304801)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 45.0), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 64.5), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 37 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -69.39323627096323)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -69.39323627096323)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 112.94999999999999), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 38 Learning Q-Table
best: move_right current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -60.0), ('move_right', -51.480924945025116)]
best: move_right current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -60.0), ('move_right', -51.480924945025116)]
best: move_right current state : (0, -0.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 254
Iteration 39 Learning Q-Table
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: move_right current state : (-1, -1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 131.85), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 40 Learning Q-Table
best: nothing current state : (0, -1.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 57.779999999999994)]
best: move_left current state : (-2, -1.75, -10) -37.241639747 [('nothing', 0), ('move_left', 0)]
Reward: -50
Iteration 41 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -28.430106835903914)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -28.430106835903914)]
best: nothing current state : (-1, -1.5, -19) -37.241639747 [('nothing', 137.11499999999998), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 122.88), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 42 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -30.0), ('move_left', -29.909752089870274), ('move_right', -38.94461834280656)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -30.0), ('move_left', -29.909752089870274), ('move_right', -38.94461834280656)]
best: move_left current state : (0, 0.25, -17) -37.241639747 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: move_left current state : (1, 3, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 254
Iteration 43 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -67.24775731377028)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -67.24775731377028)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 44 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -60.0), ('move_right', -71.40018567456559)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -60.0), ('move_right', -71.40018567456559)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 0), ('move_right', 0)]
Reward: 215
Iteration 45 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -23) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.25, -9) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 46 Learning Q-Table
best: move_left current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -28.96018059815789), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -28.96018059815789), ('move_right', -32.17249192409603)]
best: move_left current state : (1, 2, -18) -37.241639747 [('nothing', 0), ('move_left', 30.0), ('move_right', 0)]
best: nothing current state : (2, 2, -10) 100 [('nothing', 0), ('move_right', 0)]
Reward: 107
Iteration 47 Learning Q-Table
best: nothing current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -76.03361071779707)]
best: nothing current state : (2, 3, -24) -100.0 [('nothing', -72.0), ('move_right', -76.03361071779707)]
best: nothing current state : (2, 2, -18) -100.0 [('nothing', 0), ('move_right', -30.0)]
best: nothing current state : (2, 0.75, -8) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: -300
Iteration 48 Learning Q-Table
best: nothing current state : (2, 3, -23) -100.0 [('nothing', 5.539819401842102), ('move_right', -30.0)]
best: nothing current state : (2, 3, -23) -100.0 [('nothing', 5.539819401842102), ('move_right', -30.0)]
best: nothing current state : (2, 2, -18) -100.0 [('nothing', -30.0), ('move_right', -30.0)]
best: move_right current state : (2, 0.5, -8) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: -200
Loading mission from ghast_survival_mission.xml
Iteration 50 Learning Q-Table
best: nothing current state : (0, -0.0, -23) -100.0 [('nothing', -30.0), ('move_left', -39.60931838700522), ('move_right', -38.94461834280656)]
best: nothing current state : (0, -0.0, -23) -100.0 [('nothing', -30.0), ('move_left', -39.60931838700522), ('move_right', -38.94461834280656)]
best: move_right current state : (0, -0.0, -17) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 51 Learning Q-Table
best: move_right current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -41.19323627096325), ('move_right', -35.36353821304801)]
best: move_right current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -41.19323627096325), ('move_right', -35.36353821304801)]
best: nothing current state : (0, -1.5, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -2, -8) 150 [('nothing', 0), ('move_left', 32.1)]
Reward: 155
Iteration 52 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -10.939066709228769)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -10.939066709228769)]
best: nothing current state : (-1, -1.5, -19) -37.241639747 [('nothing', 177.84449999999998), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 131.595), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 5, 3) 200 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 53 Learning Q-Table
best: move_right current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -74.17249192409602), ('move_right', -71.40018567456559)]
best: move_right current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -74.17249192409602), ('move_right', -71.40018567456559)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -3, -8) 150 [('nothing', 0), ('move_left', 0)]
Reward: 142
Iteration 54 Learning Q-Table
best: move_right current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', -32.17249192409603), ('move_right', -30.0)]
best: move_right current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', -32.17249192409603), ('move_right', -30.0)]
best: nothing current state : (-2, -3, -18) -26.5339353272 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -2, -8) 100 [('nothing', 0), ('move_left', 68.97)]
Reward: 105
Iteration 55 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 13.523511379443839)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 13.523511379443839)]
best: nothing current state : (-1, -1.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 152.1165), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 56 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -74.17249192409602), ('move_right', -78.94031057035382)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -74.17249192409602), ('move_right', -78.94031057035382)]
best: nothing current state : (0, 1.25, -18) -26.5339353272 [('nothing', 30.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 57 Learning Q-Table
best: nothing current state : (1, 2, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 1.75, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.75, -7) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 58 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -71.8809249450251), ('move_right', -78.94031057035382)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -71.8809249450251), ('move_right', -78.94031057035382)]
best: nothing current state : (0, 1.25, -18) -26.5339353272 [('nothing', 66.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 64.5)]
Reward: 226
Iteration 59 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -76.03361071779707)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -76.03361071779707)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 60 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -59.476828059675476), ('move_right', -78.94031057035382)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -59.476828059675476), ('move_right', -78.94031057035382)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 112.94999999999999)]
Reward: 243
Iteration 61 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -85.39601942655398)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -85.39601942655398)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 110.38499999999999), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 143.565), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 62 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -57.09396023993074), ('move_right', -78.94031057035382)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -57.09396023993074), ('move_right', -78.94031057035382)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 63 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -58.834205522683796)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -58.834205522683796)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 61.5), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 164.9955), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 64 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -68.92595276610942), ('move_right', -78.94031057035382)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -68.92595276610942), ('move_right', -78.94031057035382)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 64.5), ('move_right', 0)]
Reward: 215
Iteration 65 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -51.69412446403655)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -51.69412446403655)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 137.54865), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 179.99685), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 66 Learning Q-Table
best: nothing current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -80.42065886037263), ('move_right', -78.94031057035382)]
best: nothing current state : (0, -0.0, -24) -100.0 [('nothing', -78.67542849309737), ('move_left', -80.42065886037263), ('move_right', -78.94031057035382)]
best: move_left current state : (0, -0.25, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.5, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 67 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -43.44461834280655), ('move_right', -32.17249192409603)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -43.44461834280655), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 0.25, -19) -37.5345128726 [('nothing', 0), ('move_left', 0), ('move_right', -20.37)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 68 Learning Q-Table
best: move_right current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -80.42065886037263), ('move_right', -78.94031057035382)]
best: move_right current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -80.42065886037263), ('move_right', -78.94031057035382)]
best: move_right current state : (0, -0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 118.0338)]
Reward: 253
Iteration 69 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -19.493722632547204)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -19.493722632547204)]
best: nothing current state : (-1, -1.5, -19) -37.241639747 [('nothing', 208.96965), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 150.516), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 70 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -80.42065886037263), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -80.42065886037263), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 45.0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 71 Learning Q-Table
best: move_left current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -43.184282559915225)]
best: move_left current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -43.184282559915225)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 0), ('move_right', 0)]
Reward: 167
Iteration 72 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -23.881472722983467)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -23.881472722983467)]
best: nothing current state : (1, 1.5, -19) -58.3854585078 [('nothing', 165.339), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 190.497795), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 73 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -74.96695312635686), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -74.96695312635686), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 110.38499999999999), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 50.1), ('move_right', 0)]
Reward: 215
Iteration 74 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -5.630968458425116)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', -5.630968458425116)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 195.28311), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 39.3)]
Reward: 215
Iteration 75 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -48.3215477866077), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -48.3215477866077), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 99.57), ('move_right', 0)]
Reward: 215
Iteration 76 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 25.683074480944526)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 25.683074480944526)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 193.488177), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 197.8484565), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 77 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -49.285264048783304), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -49.285264048783304), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 64.35), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 39.3), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 78 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 47.064424638503276)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 47.064424638503276)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 217.8866385), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 202.99391955), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 79 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -47.367176758244334), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -47.367176758244334), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 101.83500000000001), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 134.19899999999998), ('move_right', 0)]
Reward: 215
Iteration 80 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 66.13859687285628)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 66.13859687285628)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 239.79626085), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 206.595743685), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 81 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -34.77901565486706), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -34.77901565486706), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 156.5442), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 158.4393), ('move_right', 0)]
Reward: 215
Iteration 82 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 89.27571546784151)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 89.27571546784151)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 258.418822815), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 92.00999999999999)]
Reward: 215
Iteration 83 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -9.554542882502986), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -9.554542882502986), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 202.11273), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 64.5)]
Reward: 215
Iteration 84 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 107.84615574789304)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 107.84615574789304)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 253.4961759705), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 209.1170205795), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 85 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 21.77314705815187), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 21.77314705815187), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 205.828911), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 109.65)]
Reward: 215
Iteration 86 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 119.3686698905791)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 119.3686698905791)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 64.35), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 87 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 44.81738431661028), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 44.81738431661028), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 0)]
Reward: 163
Iteration 88 Learning Q-Table
best: move_left current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -43.44461834280655), ('move_right', -54.78109820863473)]
best: move_right current state : (0, 1.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 2, -17) -15.7875285356 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (1, 1.0, -4) -77.0156774993 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 89 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -51.0), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 221.9752377), ('move_right', 0)]
best: move_right current state : (0, -0.25, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 90 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 70.69057699930936)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 70.69057699930936)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 274.8361057005), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 128.90699999999998)]
Reward: 204
Iteration 91 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 5.635910460950486), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 5.635910460950486), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 0)]
Reward: 204
Iteration 92 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 102.97405501150865)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 102.97405501150865)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 276.05737399035), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.88191440565), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 93 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -11.515043275492555), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -11.515043275492555), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 106.371), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 175.40751), ('move_right', 0)]
Reward: 215
Iteration 94 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 125.93887010700317)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 125.93887010700317)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 285.1824293532), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.117340083955), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 95 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -5.109410891002696), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', -5.109410891002696), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 125.38266639000001), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 141.255)]
Reward: 215
Iteration 96 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 141.5394459567662)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 141.5394459567662)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 90.04499999999999), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.9821380587685), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 97 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 1.8657203692020872), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 1.8657203692020872), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 172.081953), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 187.285257), ('move_right', 0)]
Reward: 215
Iteration 98 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 93.91862024564031)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 93.91862024564031)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 308.2629025724265), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.58749664113796), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 99 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 23.970409560283557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 23.970409560283557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 137.2995), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 163.3785)]
Reward: 215
Iteration 100 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 126.04941301958016)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 126.04941301958016)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 171.92614141763053), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.01124764879657), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 101 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 29.008956094040585), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 29.008956094040585), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 175.14436647300002), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 92.00999999999999), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 102 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 107.63993961489925)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 107.63993961489925)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 301.50473611494004), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 214.3078733541576), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 103 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 40.677087283632396), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 40.677087283632396), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 190.1232), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 195.5996799), ('move_right', 0)]
Reward: 215
Iteration 104 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 136.8391979667536)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 136.8391979667536)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 324.8602807930399), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 151.4349)]
Reward: 215
Iteration 105 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 56.55074050038477), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 56.55074050038477), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 195.2040565311), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 178.86495)]
Reward: 215
Iteration 106 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 161.07303089054346)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 161.07303089054346)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 317.83266655512796), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.51551134791032), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 107 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 65.97424338550331), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 65.97424338550331), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 221.6429442), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 201.41977593000001), ('move_right', 0)]
Reward: 215
Iteration 108 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 175.9284296658228)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 175.9284296658228)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 229.55167328698036), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.66085794353722), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 109 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 83.71467303169442), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 83.71467303169442), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 236.76614397), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 109.65), ('move_right', 0)]
Reward: 215
Iteration 110 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 159.84291082807403)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 159.84291082807403)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 331.83751999296265), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 170.50443)]
Reward: 215
Iteration 111 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 100.66993371502818), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 100.66993371502818), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 235.30232457177001), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.705465)]
Reward: 215
Iteration 112 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 179.2688016534446)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 179.2688016534446)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 270.0844286839474), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.76260056047605), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 113 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 108.8871590479547), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 108.8871590479547), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 243.631300779), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 205.49384315100002), ('move_right', 0)]
Reward: 215
Iteration 114 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 174.34099783849942)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 174.34099783849942)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 320.3456772867053), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 214.83382039233322), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 115 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 120.35022096911038), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 120.35022096911038), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 277.1900634906), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 141.255), ('move_right', 0)]
Reward: 215
Iteration 116 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 189.1822210748033)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 189.1822210748033)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 333.6921202183937), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 214.88367427463325), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 117 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 138.44199312739937), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 138.44199312739937), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -58.3854585078 [('nothing', 0), ('move_left', 266.623266700239), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.3456902057), ('move_right', 0)]
Reward: 215
Iteration 118 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 203.57501021972251)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 203.57501021972251)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 343.04958643526555), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 215
Iteration 119 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 138.38073764691458), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 138.38073764691458), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.2938255)]
Reward: 215
Iteration 120 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 216.45720248622752)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 216.45720248622752)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 328.4375929950739), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 183.853101)]
Reward: 204
Iteration 121 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 78.19402442874417), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 78.19402442874417), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 76.5), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.34198314399), ('move_right', 0)]
Reward: 204
Iteration 122 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.8788277147854)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.8788277147854)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 304.4847105046859), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.8971707)]
Reward: 204
Iteration 123 Learning Q-Table
best: move_right current state : (0, 1.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 64.5), ('move_left', 0), ('move_right', 0)]
Reward: 265
Iteration 124 Learning Q-Table
best: move_left current state : (-2, -2.0, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -2.0, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-1, -0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.75, -9) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 125 Learning Q-Table
best: nothing current state : (0, 1.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 294.13999375187734), ('move_right', 0)]
best: move_right current state : (0, 1.5, -9) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 126 Learning Q-Table
best: nothing current state : (1, 3, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -19) -100.0 [('nothing', -16.50485056868419), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.5, -10) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 127 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 58.2419981255632), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 58.2419981255632), ('move_right', 0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 151.96499999999997)]
Reward: 215
Iteration 128 Learning Q-Table
best: move_left current state : (1, 3, -25) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (1, 3, -25) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: move_right current state : (2, 3, -19) -60.6879978231 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 1.75, -9) -60.6879978231 [('nothing', 0), ('move_right', 0)]
Reward: -300
Iteration 129 Learning Q-Table
best: nothing current state : (1, 3, -25) -100.0 [('nothing', -30.0), ('move_left', -39.20639934691634), ('move_right', -30.0)]
best: move_right current state : (1, 3, -25) -100.0 [('nothing', -30.0), ('move_left', -39.20639934691634), ('move_right', -30.0)]
best: nothing current state : (1, 3, -19) -99.5668313869 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.5, -9) -26.1007667141 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 108
Iteration 130 Learning Q-Table
best: nothing current state : (0, 2, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 2, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.75, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2.0, -10) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 179
Iteration 131 Learning Q-Table
best: nothing current state : (2, 4, -25) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -25) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -20) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 1.5, -10) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: -100
Iteration 132 Learning Q-Table
best: nothing current state : (0, 3, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 3, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.5, -9) -100.0 [('nothing', 7.470000000000002), ('move_left', 0), ('move_right', 0)]
Reward: 73
Iteration 133 Learning Q-Table
best: move_left current state : (0, 1.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 0), ('move_left', -11.172491924096027), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 202.60567785)]
Reward: 215
Iteration 134 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -51.0), ('move_right', 0)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -51.0), ('move_right', 0)]
best: move_right current state : (1, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 135 Learning Q-Table
best: move_right current state : (0, 0.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -1.5, -19) -26.5339353272 [('nothing', 236.43355499999998), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -1.5, -8) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 136 Learning Q-Table
best: move_left current state : (-1, -1.0, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -1.0, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 45.0), ('move_right', -20.37)]
best: nothing current state : (0, 2, -9) 100 [('nothing', 169.8612), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 137 Learning Q-Table
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', 0), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', 0), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 197.93781502815625), ('move_right', 0)]
best: move_left current state : (0, 0.25, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 138 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 139 Learning Q-Table
best: nothing current state : (0, 0.5, -25) -100.0 [('nothing', 62.96988590184209), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 0.5, -25) -100.0 [('nothing', 62.96988590184209), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 0.5, -20) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.5, -10) -100.0 [('nothing', 0), ('move_left', 54.3), ('move_right', 0)]
Reward: -300
Iteration 140 Learning Q-Table
best: move_left current state : (0, 0.5, -25) -100.0 [('nothing', -6.921079868710528), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -25) -100.0 [('nothing', -6.921079868710528), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 173.20284), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 141 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -51.0), ('move_right', -32.17249192409602)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -51.0), ('move_right', -32.17249192409602)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 0), ('move_right', -11.172491924096027)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 109.65), ('move_right', 0)]
Reward: 142
Iteration 142 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.12801949)]
Reward: 142
Iteration 143 Learning Q-Table
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', 8.381344508446873), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', 8.381344508446873), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 108.55647051970938), ('move_right', 0)]
best: move_left current state : (0, 0.25, -8) -100.0 [('nothing', -15.0), ('move_left', 0), ('move_right', -45.0)]
Reward: -50
Iteration 144 Learning Q-Table
best: move_left current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (1, 3, -19) -26.5339353272 [('nothing', -7.8302300142270616), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 100 [('nothing', 0), ('move_right', 61.199999999999996)]
Reward: 120
Iteration 145 Learning Q-Table
best: nothing current state : (2, 4, -25) -100.0 [('nothing', -51.0), ('move_right', -51.48092494502511)]
best: nothing current state : (2, 4, -25) -100.0 [('nothing', -51.0), ('move_right', -51.48092494502511)]
best: nothing current state : (2, 3, -20) -100.0 [('nothing', 0), ('move_right', -30.0)]
best: nothing current state : (2, 1.25, -10) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: -300
Loading mission from ghast_survival_mission.xml
Iteration 147 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 48.725636501963024), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 48.725636501963024), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 281.40954444342), ('move_right', 0)]
best: nothing current state : (2, 4, -6) 150 [('nothing', 0), ('move_right', 0)]
Reward: 209
Iteration 148 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.90041195359765)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.90041195359765)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 298.487880246906), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.91857199224327), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 149 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 89.57062828624221), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 89.57062828624221), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 260.575993719), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.43938820079302), ('move_right', 0)]
Reward: 215
Iteration 150 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.80416051749413)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.80416051749413)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 315.10844856328015), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.94300039457028), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 151 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 111.91205731791163), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 111.91205731791163), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 241.986681110394), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.4075717405551), ('move_right', 0)]
Reward: 215
Iteration 152 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.03526633307206)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.03526633307206)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 330.05881411266716), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.9601002761992), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 153 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 121.97426385749844), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 121.97426385749844), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 277.5129482994423), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.78530021838858), ('move_right', 0)]
Reward: 215
Iteration 154 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.7821500687927)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.7821500687927)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 318.4170877705072), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 155 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 139.6756885919237), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 139.6756885919237), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 302.7946538751262), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.749710152872), ('move_right', 0)]
Reward: 215
Iteration 156 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 215.80013945521102)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 215.80013945521102)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 340.52919996172676), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 178.489613643)]
Reward: 215
Iteration 157 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 159.65119757872654), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 159.65119757872654), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 320.78117075844995), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.42479710701042), ('move_right', 0)]
Reward: 215
Iteration 158 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.25867700900784)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.25867700900784)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 336.91732406610873), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.97207019333945), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 159 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 179.03000893448566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 179.03000893448566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 289.9350120635379), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.8973579749073), ('move_right', 0)]
Reward: 215
Iteration 160 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.0960905279802)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.0960905279802)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 345.33374790427797), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.9804491353376), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 161 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.34132927504345), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.34132927504345), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 333.5742586630181), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 163.3785), ('move_right', 0)]
Reward: 215
Iteration 162 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', -30.0)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', -30.0)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 351.22775827359584), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 64.5)]
Reward: 215
Iteration 163 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 199.45102749327793), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 199.45102749327793), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 312.12371583694875), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.2281505824351), ('move_right', 0)]
Reward: 215
Iteration 164 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.00720714271165)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.00720714271165)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 310.2094307915171), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.98631439473633), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 165 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.2926533982213), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.2926533982213), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 45.98952936379657), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 78.84)]
Reward: 215
Iteration 166 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.6076936391954)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.6076936391954)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 267.89196143935504), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.99042007631542), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 167 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 127.84153558973597), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 127.84153558973597), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 119.688)]
Reward: 215
Iteration 168 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 208.22048205514727)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 208.22048205514727)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 330.0622453965517), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.99329405342078), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 169 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 57.316582988719155), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 57.316582988719155), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 100.8446705546576), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 178.86495), ('move_right', 0)]
Reward: 215
Iteration 170 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.60051913347257)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.60051913347257)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 326.64249587248287), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.99530583739454), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 171 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 38.20251733440466), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 38.20251733440466), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 327.5155310641127), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 189.705465), ('move_right', 0)]
Reward: 215
Iteration 172 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.85293155701777)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.85293155701777)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 338.14833886195635), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.4427295501)]
Reward: 215
Iteration 173 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 96.03624085515916), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 96.03624085515916), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 135.68814765000002), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.32397449500002)]
Reward: 215
Iteration 174 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 55.40814688392085)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 55.40814688392085)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 338.53665606839945), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 109.65)]
Reward: 215
Iteration 175 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 75.75932096951539), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 75.75932096951539), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 169.2507543882603), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 128.90699999999998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 176 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.98137315034145)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.98137315034145)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 314.8706592478796), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.99671408617618), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 177 Learning Q-Table
best: nothing current state : (0, 2.0, -25) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 2.0, -25) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.5, -20) -100.0 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.5, -10) -100.0 [('nothing', 0), ('move_left', -51.99000000000001), ('move_right', 0)]
Reward: -300
Iteration 178 Learning Q-Table
best: move_left current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -30.0), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -30.0), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', -27.759)]
best: nothing current state : (2, 4, -9) 150 [('nothing', 0), ('move_right', 0)]
Reward: 215
Iteration 179 Learning Q-Table
best: move_right current state : (2, 5, -25) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 5, -25) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -19) -26.5339353272 [('nothing', -7.8302300142270616), ('move_left', 48.35999999999999), ('move_right', 0)]
best: move_right current state : (0, -1.5, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 180 Learning Q-Table
best: move_left current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -28.960180598157898), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -28.960180598157898), ('move_right', -28.960180598157898)]
best: nothing current state : (2, 4, -19) -26.5339353272 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -10) 100 [('nothing', 0), ('move_right', 0)]
Reward: 108
Iteration 181 Learning Q-Table
best: nothing current state : (2, 5, -25) -100.0 [('nothing', 0), ('move_right', -14.452180598157888)]
best: nothing current state : (2, 5, -25) -100.0 [('nothing', 0), ('move_right', -14.452180598157888)]
best: nothing current state : (2, 4, -19) -100.0 [('nothing', 30.0), ('move_right', 0)]
best: nothing current state : (2, 2, -10) -100.0 [('nothing', 32.1), ('move_right', 0)]
Reward: -250
Iteration 182 Learning Q-Table
best: move_right current state : (2, 5, -25) -100.0 [('nothing', -42.0), ('move_right', -14.452180598157888)]
best: move_right current state : (2, 5, -25) -100.0 [('nothing', -42.0), ('move_right', -14.452180598157888)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 77.895), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.99769986032334), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 183 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', -28.960180598157898)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 201.8788957035), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 119.355), ('move_right', 0)]
Reward: 215
Iteration 184 Learning Q-Table
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -12.566117688174376), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -12.566117688174376), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 202.1476280717822), ('move_right', 0)]
best: move_left current state : (0, 1.0, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -75.0)]
Reward: -100
Iteration 185 Learning Q-Table
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -32.17249192409603)]
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 95.85), ('move_right', -30.0)]
best: move_right current state : (-1, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 186 Learning Q-Table
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', 0.8480060398125957), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', 0.8480060398125957), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.25, -19) -100.0 [('nothing', 0), ('move_left', 103.23840584700001), ('move_right', 0)]
best: nothing current state : (0, 1.0, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -100
Iteration 187 Learning Q-Table
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -22.72592494502512)]
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -22.72592494502512)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 112.095), ('move_right', -30.0)]
best: move_right current state : (-1, -2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 188 Learning Q-Table
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -19.43487401803118), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -19.43487401803118), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.0, -20) -100.0 [('nothing', 0), ('move_left', 80.90639999999999), ('move_right', 0)]
best: nothing current state : (0, 1.0, -9) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -75.0)]
Reward: -150
Iteration 189 Learning Q-Table
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -11.239828059675489)]
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -11.239828059675489)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 123.4665), ('move_right', -30.0)]
best: move_right current state : (-1, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 42.6)]
Reward: 152
Iteration 190 Learning Q-Table
best: move_left current state : (0, 1.25, -25) -100.0 [('nothing', -40.33249181262183), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 1.25, -25) -100.0 [('nothing', -40.33249181262183), ('move_left', -28.960180598157898), ('move_right', -32.17249192409603)]
best: move_left current state : (0, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 191 Learning Q-Table
best: move_right current state : (2, 5, -25) -100.0 [('nothing', -42.0), ('move_right', -15.708207016868414)]
best: move_right current state : (2, 5, -25) -100.0 [('nothing', -42.0), ('move_right', -15.708207016868414)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 45.0), ('move_right', -27.759)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.10991068507002)]
Reward: 152
Iteration 192 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 11.331361694181574)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 11.331361694181574)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 26.634479999999996), ('move_right', 0)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 86.7), ('move_right', 0)]
Reward: 120
Iteration 193 Learning Q-Table
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: move_left current state : (1, 3, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 211
Iteration 194 Learning Q-Table
best: move_right current state : (2, 5, -25) -100.0 [('nothing', -42.0), ('move_right', -26.4559255099658)]
best: move_right current state : (2, 5, -25) -100.0 [('nothing', -42.0), ('move_right', -26.4559255099658)]
best: nothing current state : (1, 3, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -5, 2) 200 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 195 Learning Q-Table
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 0.21188976006926197)]
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 0.21188976006926197)]
best: nothing current state : (0, 1.5, -20) -37.241639747 [('nothing', 1.5), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 42.6)]
Reward: 215
Iteration 196 Learning Q-Table
best: move_left current state : (-1, -0.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -0.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 64.35)]
best: nothing current state : (0, 2, -10) -3.20585028238 [('nothing', 53.699999999999996), ('move_left', 0), ('move_right', 0)]
Reward: 26
Iteration 197 Learning Q-Table
best: nothing current state : (-1, -0.5, -25) -100.0 [('nothing', 8.13250807590397), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (-1, -0.5, -25) -100.0 [('nothing', 8.13250807590397), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (-1, -0.25, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, 0.5, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -50
Iteration 198 Learning Q-Table
best: move_right current state : (0, 1.25, -25) -100.0 [('nothing', -40.33249181262183), ('move_left', -52.44461834280656), ('move_right', -32.17249192409603)]
best: move_right current state : (0, 1.25, -25) -100.0 [('nothing', -40.33249181262183), ('move_left', -52.44461834280656), ('move_right', -32.17249192409603)]
best: nothing current state : (-1, -0.75, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -2.0, -9) 100 [('nothing', 0), ('move_left', 0)]
Reward: 141
Iteration 199 Learning Q-Table
best: nothing current state : (-2, -1.5, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -1.5, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -1.0, -19) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-1, 1.0, -9) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 170
Iteration 200 Learning Q-Table
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -31.574169092047544)]
best: move_right current state : (0, 2.0, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -31.574169092047544)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 222.12172699245002), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -2, -9) 150 [('nothing', 0), ('move_left', 42.3)]
Reward: 215
Iteration 201 Learning Q-Table
best: nothing current state : (-2, -1.5, -25) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: move_left current state : (-2, -1.5, -25) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: nothing current state : (-2, -1.0, -19) -100.0 [('nothing', 0), ('move_left', -7.960180598157884)]
best: move_left current state : (-1, 1.25, -9) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 202 Learning Q-Table
best: move_left current state : (0, 0.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 42.26688409290001), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 45.39), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 203 Learning Q-Table
best: move_left current state : (1, 4, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 4, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 4, -20) -61.0310870463 [('nothing', 0), ('move_right', 0)]
best: move_left current state : (1, 1.25, -10) -65.5028482809 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -3, 2) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 114
Iteration 204 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', -16.250194738168922)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', -16.250194738168922)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 213.175208894715), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 183.576937479549)]
Reward: 215
Iteration 205 Learning Q-Table
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -40.33249181262183), ('move_left', -52.44461834280656), ('move_right', -51.480924945025116)]
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -40.33249181262183), ('move_left', -52.44461834280656), ('move_right', -51.480924945025116)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 111.50333965024755), ('move_right', 0)]
best: nothing current state : (0, 0.75, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 206 Learning Q-Table
best: move_right current state : (0, 1.75, -25) -100.0 [('nothing', 0), ('move_left', -18.67249192409603), ('move_right', 0)]
best: nothing current state : (0, 1.75, -25) -100.0 [('nothing', 0), ('move_left', -18.67249192409603), ('move_right', 0)]
best: nothing current state : (0, 1.5, -20) -37.6662172368 [('nothing', 58.83), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.5, -10) -3.63042777222 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -100
Iteration 207 Learning Q-Table
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -45.78174237376102), ('move_left', -52.44461834280656), ('move_right', -51.480924945025116)]
best: nothing current state : (0, 1.25, -25) -100.0 [('nothing', -45.78174237376102), ('move_left', -52.44461834280656), ('move_right', -51.480924945025116)]
best: move_left current state : (0, 1.0, -20) -100.0 [('nothing', 0), ('move_left', 89.654136), ('move_right', 0)]
best: nothing current state : (0, 0.5, -9) -100.0 [('nothing', 27.129), ('move_left', 0), ('move_right', 0)]
Reward: -200
Iteration 208 Learning Q-Table
best: nothing current state : (0, 1.75, -25) -100.0 [('nothing', 6.349134828950295), ('move_left', -18.67249192409603), ('move_right', -30.0)]
best: nothing current state : (0, 1.75, -25) -100.0 [('nothing', 6.349134828950295), ('move_left', -18.67249192409603), ('move_right', -30.0)]
best: nothing current state : (0, 1.5, -20) -100.0 [('nothing', 40.09187166833352), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.25, -9) -100.0 [('nothing', 0), ('move_left', -45.0), ('move_right', 0)]
Reward: -250
Iteration 209 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 15.574419135143806)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 15.574419135143806)]
best: move_left current state : (0, 1.0, -20) -37.5386828277 [('nothing', 0), ('move_left', 40.8965952), ('move_right', 0)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 96.69), ('move_right', 0)]
Reward: 152
Iteration 210 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -9.090532893708858)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -9.090532893708858)]
best: move_right current state : (0, -0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 80.41014)]
best: nothing current state : (-2, -3, -9) 150 [('nothing', 30.0), ('move_left', 0)]
Reward: 200
Iteration 211 Learning Q-Table
best: move_left current state : (-2, -1.5, -25) -100.0 [('nothing', -60.0), ('move_left', -51.0)]
best: move_left current state : (-2, -1.5, -25) -100.0 [('nothing', -60.0), ('move_left', -51.0)]
best: move_right current state : (-1, 0.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 212 Learning Q-Table
best: move_right current state : (0, 0.25, -25) -100.0 [('nothing', 0), ('move_left', -16.280115370287895), ('move_right', 0)]
best: nothing current state : (0, 0.25, -25) -100.0 [('nothing', 0), ('move_left', -16.280115370287895), ('move_right', 0)]
best: nothing current state : (-2, -1.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -1.5, -9) -13.3133677951 [('nothing', 0), ('move_left', 0)]
Reward: 86
Iteration 213 Learning Q-Table
best: nothing current state : (-2, -1.5, -25) -100.0 [('nothing', -60.0), ('move_left', -64.6601805981579)]
best: nothing current state : (-2, -1.5, -25) -100.0 [('nothing', -60.0), ('move_left', -64.6601805981579)]
best: nothing current state : (-2, -1.0, -19) -100.0 [('nothing', -7.960180598157898), ('move_left', -7.960180598157884)]
best: move_left current state : (-2, -0.25, -9) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -200
Loading mission from ghast_survival_mission.xml
Iteration 215 Learning Q-Table
best: move_right current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', -39.60931838700522), ('move_right', -38.94461834280656)]
best: move_right current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', -39.60931838700522), ('move_right', -38.94461834280656)]
best: nothing current state : (0, -0.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -3, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 216 Learning Q-Table
best: nothing current state : (-1, -2, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', -42.529062072060015)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0), ('move_right', -42.529062072060015)]
best: move_left current state : (-1, -1.75, -19) -100.0 [('nothing', -7.960180598157898), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.5, -9) -26.5339353272 [('nothing', -41.009699999999995), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 217 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 71.63425907104283), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 71.63425907104283), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 249.2957274701652), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 148.2816)]
Reward: 199
Iteration 218 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.987978381445)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.987978381445)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 297.0214990304432), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 193.0038562356843)]
Reward: 204
Iteration 219 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 92.76020766668351), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 92.76020766668351), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 161.652594943197), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.45970540770458), ('move_right', 0)]
Reward: 204
Iteration 220 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 213.02554265204844)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 213.02554265204844)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 310.81620619201556), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 42.6)]
Reward: 204
Iteration 221 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 84.46774325147966), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 84.46774325147966), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 48.0523377551733), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 197.2938255), ('move_right', 0)]
Reward: 204
Iteration 222 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 210.19024978994256)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 210.19024978994256)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 340.5415599936124), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 196.39838990222634), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 223 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 41.370629678491724), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 41.370629678491724), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 137.8247840786213), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.92678214650002)]
Reward: 215
Iteration 224 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.12315092694746)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.12315092694746)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 342.2986089661966), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 201.97887293155844), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 225 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 38.134384074434564), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 38.134384074434564), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 327.75504626059467), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.3217937853932), ('move_right', 0)]
Reward: 215
Iteration 226 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.50329641462616)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.50329641462616)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 275.3513443344109), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.30269936497902)]
Reward: 215
Iteration 227 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 96.06040213212471), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 96.06040213212471), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 331.1725112448789), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.42525564977524), ('move_right', 0)]
Reward: 215
Iteration 228 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.18521886646556)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.18521886646556)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 329.9084756993686), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 205.8852110520909), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 229 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 137.63385426779308), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 137.63385426779308), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.25, -18) -26.5339353272 [('nothing', 110.55), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 154.73489999999998), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 230 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.34201531817857)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.34201531817857)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 296.63675084358135), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 64.5)]
Reward: 215
Iteration 231 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 100.54851738929726), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 100.54851738929726), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 204.15538349898492), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.74874750255)]
Reward: 226
Iteration 232 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.85794405170338)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.85794405170338)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 337.7014963051853), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 208.61964773646363), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 233 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 99.45808529810753), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 99.45808529810753), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 251.13339270005446), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.324123251785)]
Reward: 215
Iteration 234 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.15082912959008)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.15082912959008)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 271.99572559050694), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.91188955548532)]
Reward: 215
Iteration 235 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 112.78818559459557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 112.78818559459557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 285.39061186557365), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 163.49712)]
Reward: 215
Iteration 236 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 201.4318061437691)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 201.4318061437691)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 343.9769417345688), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.83832268883972)]
Reward: 215
Iteration 237 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 135.6087328777311), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 135.6087328777311), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 293.82256430590155), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.2268862762495)]
Reward: 215
Iteration 238 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 215.23516622285112)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 215.23516622285112)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 295.97057478000045), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.5868258821878)]
Reward: 215
Iteration 239 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 150.9003903820862), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 150.9003903820862), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 263.99148922911564), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.15882039337464)]
Reward: 215
Iteration 240 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.2832968658999)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.2832968658999)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 314.7554501106566), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.51077811753146)]
Reward: 215
Iteration 241 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 152.655228112099), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 152.655228112099), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 337.82507051803424), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.11117427536226)]
Reward: 215
Iteration 242 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.3524509152309)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.3524509152309)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 328.4820485127191), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 64.5), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 243 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 179.24600023572168), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 179.24600023572168), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 315.24386089700596), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.07782199275357)]
Reward: 215
Iteration 244 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.5188382703813)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.5188382703813)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 294.28743395890336), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.85754468227202)]
Reward: 215
Iteration 245 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.87286651001094), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.87286651001094), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 294.34168857839336), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 246 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 204.1769250528419)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 204.1769250528419)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 314.55846717591396), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.80028127759041)]
Reward: 204
Iteration 247 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', -39.60931838700522), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', -39.60931838700522), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 222.49472808254927), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.19767895484267), ('move_right', 0)]
Reward: 204
Iteration 248 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 205.1188957656675)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 205.1188957656675)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 347.5353560208501), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 210.53375341552453), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 249 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.64102120642963), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.64102120642963), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 251.03918200487536), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.0544753949275)]
Reward: 204
Iteration 250 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.8836532440644)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.8836532440644)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 351.4348752392524), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.1601968943133)]
Reward: 215
Iteration 251 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 174.48797752186732), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 174.48797752186732), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 330.1940492257302), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 169.51442999999998), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 252 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.68883924446288)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.68883924446288)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.87362739086717), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 253 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -41.19323627096325), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -41.19323627096325), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 144.20655), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 204.641988), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 254 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 128.60969554702802)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 128.60969554702802)]
best: move_left current state : (1, 1.75, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', -4.736258560676714)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 148.0485), ('move_right', 0)]
Reward: 142
Iteration 255 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -20.10742869), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -20.10742869), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.25, -18) -100.0 [('nothing', 168.80546999999999), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.5, -9) -100.0 [('nothing', -41.009699999999995), ('move_left', 0), ('move_right', 54.3)]
Reward: -300
Iteration 256 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -14.433559083000006), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -14.433559083000006), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.25, -18) -100.0 [('nothing', 104.45382899999998), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.75, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 257 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -29.76734265810001), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -29.76734265810001), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 340.54833456634776), ('move_right', 0)]
best: move_right current state : (0, 0.0, -9) -100.0 [('nothing', 0), ('move_left', -90.0), ('move_right', 0)]
Reward: -150
Iteration 258 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 57.854294958823594)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 57.854294958823594)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 345.20268815580516), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 235.01153917360702), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 259 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 189.02730710893016), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 189.02730710893016), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 208.38383419644344), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.43837526838988), ('move_right', 0)]
Reward: 215
Iteration 260 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 111.88632099382204)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 111.88632099382204)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 329.0310114064169), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.6121378260193)]
Reward: 204
Iteration 261 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 165.87408463702624), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 165.87408463702624), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 264.7056133442373), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.80686268787292), ('move_right', 0)]
Reward: 204
Iteration 262 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 144.8572361935045)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 144.8572361935045)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 354.05247173577067), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.3284964782135)]
Reward: 215
Iteration 263 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 166.56336265103167), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 166.56336265103167), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 285.243770021891), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.46480388151105), ('move_right', 0)]
Reward: 215
Iteration 264 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 178.65562625802644)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 178.65562625802644)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 355.6352791585035), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 229.00807742152492), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 265 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.99499293819343), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.99499293819343), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 254.0001965180274), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 199.30567785), ('move_right', 0)]
Reward: 215
Iteration 266 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.78934153001168)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.78934153001168)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.64711863740996), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.02994753474945)]
Reward: 204
Iteration 267 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 166.23637341398572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 166.23637341398572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 326.9901634580111), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 178.947984)]
Reward: 204
Iteration 268 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.78649406407328)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.78649406407328)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 338.8053493322976), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 224.80565419506743), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 269 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 182.29001850309731), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 182.29001850309731), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 307.510080179777), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.73813277644925)]
Reward: 204
Iteration 270 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.71965872044456)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.71965872044456)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 349.60544079112856), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.9209632743246)]
Reward: 204
Iteration 271 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.6835450820052), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.6835450820052), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 282.59184091761915), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 204.01397449499999), ('move_right', 0)]
Reward: 215
Iteration 272 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.82185512860175)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.82185512860175)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.1619673066118), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.44467429202723)]
Reward: 204
Iteration 273 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.19585323453148), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.19585323453148), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 293.83598814732795), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.12536271705773), ('move_right', 0)]
Reward: 204
Iteration 274 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.46370818384688)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.46370818384688)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 352.4000975360874), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.8639579365472), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 275 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 190.22771311021253), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 190.22771311021253), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 327.57750962060777), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 186.4635888)]
Reward: 215
Iteration 276 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.472133065423)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.472133065423)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 357.1453434611457), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.41127200441906)]
Reward: 215
Iteration 277 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 10.061714955703238), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 10.061714955703238), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 346.01090164523265), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.9877539019404), ('move_right', 0)]
Reward: 215
Iteration 278 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 108.17420771516842)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 108.17420771516842)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 360.7467794022364), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.80477055558305), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 279 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 202.47247146517321), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 202.47247146517321), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 330.24333337442545), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.41669294351448)]
Reward: 215
Iteration 280 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.3016042600438)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.3016042600438)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.4641767482404), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.98789040309333)]
Reward: 215
Iteration 281 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 208.63123811385285), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 208.63123811385285), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 304.0184809908334), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.09168506046012)]
Reward: 215
Iteration 282 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.39019540834488)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.39019540834488)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 356.92512202412775), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.36333938890814), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 283 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 208.2872303787891), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 208.2872303787891), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 338.99534124515213), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 186.46010099999998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 284 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.17818146898372)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.17818146898372)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.12129084469626), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.3543375722357), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 285 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 81.88629036440418), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 81.88629036440418), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 48.9)]
Reward: 215
Iteration 286 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.8009336835396)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.8009336835396)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.35658723356187), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.79152328216534)]
Reward: 215
Iteration 287 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.32717171460197), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.32717171460197), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 323.77849595877865), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.79142773135828), ('move_right', 0)]
Reward: 215
Iteration 288 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.29513782445025)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.29513782445025)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.48706804814293), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.05406629751573)]
Reward: 215
Iteration 289 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.69007706375893), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.69007706375893), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 338.2347691716065), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.2641795423221)]
Reward: 215
Iteration 290 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.98022496746202)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.98022496746202)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 358.23925565622534), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.937846408261)]
Reward: 204
Iteration 291 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 28.36022265692502), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 28.36022265692502), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 314.02280051824687), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.0539994119508), ('move_right', 0)]
Reward: 204
Iteration 292 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.085442249995)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.085442249995)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.6912048629581), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.648036300565), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 293 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 220.28099277201716), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 220.28099277201716), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 345.44359228282116), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.08492567962546)]
Reward: 215
Iteration 294 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 151.7734872971928)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 151.7734872971928)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.57825429424014), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 216.1536254103955), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 295 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 222.46623441221035), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 222.46623441221035), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 350.73599230186244), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.6594479757378)]
Reward: 215
Iteration 296 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.30699043572605)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.30699043572605)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.05086562908673), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.80753778727686), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 297 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.77466985500996), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.77466985500996), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 334.88237549055253), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.06161358301645)]
Reward: 204
Iteration 298 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.66997239557634)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.66997239557634)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 359.64883288183603), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.2564924857827)]
Reward: 215
Iteration 299 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.4344896215767), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.4344896215767), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 354.61302900402507), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 170.8755)]
Reward: 226
Iteration 300 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4034499432963)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4034499432963)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 89.41454999999999), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 109.65), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 301 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 30.327360509234325), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 30.327360509234325), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.25, -18) -100.0 [('nothing', 43.11768029999999), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.25, -8) -100.0 [('nothing', -15.0), ('move_left', -15.0), ('move_right', -45.0)]
Reward: -300
Iteration 302 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -16.835543553535974), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -16.835543553535974), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 321.1404422117214), ('move_right', 0)]
best: move_left current state : (0, -0.25, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 303 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 180.84659936214953)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 180.84659936214953)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.95716752295476), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.5652764510938), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 304 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.11555951221516), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.11555951221516), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 305 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.70727788629506)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.70727788629506)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 359.83113076302004), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 146.23395), ('move_right', 0)]
Reward: 215
Iteration 306 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 148.4207110603927), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 148.4207110603927), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 343.63614691829173), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, 2) 200 [('nothing', 0), ('move_right', 0)]
Reward: 142
Iteration 307 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 33.55725217604123), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 33.55725217604123), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_left current state : (0, 1.25, -19) -100.0 [('nothing', 0), ('move_left', 88.20381886503), ('move_right', 0)]
best: move_left current state : (0, 0.25, -8) -100.0 [('nothing', -100.5), ('move_left', -15.0), ('move_right', -45.0)]
Reward: -100
Iteration 308 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.48089553626457)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.48089553626457)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 362.3396002013965), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.39569351576566), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 309 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 85.09881541716368), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 85.09881541716368), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 194.798309548205), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.63779958836557), ('move_right', 0)]
Reward: 215
Iteration 310 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.6660150117081)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.6660150117081)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 340.751976534114), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 215.27698546103596), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 311 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 178.0251612196045), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 178.0251612196045), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 285.54530284280423), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.04312950811152)]
Reward: 204
Iteration 312 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.71931154433386)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.71931154433386)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.27786727654376), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.19388982272517), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 313 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 89.04848305831817), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 89.04848305831817), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 244.25015656025317), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 226
Iteration 314 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.72669766583894)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.72669766583894)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 348.1094792121906), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 215.13572287590762), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 315 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 106.64880451074077), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 106.64880451074077), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 308.1946508423964), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.2464597118559), ('move_right', 0)]
Reward: 215
Iteration 316 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.76904020564842)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.76904020564842)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 363.2564281957072), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.09500601313533), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 317 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 178.1087117824684), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 178.1087117824684), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 45.0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.37252179829912), ('move_right', 0)]
Reward: 153
Iteration 318 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -1.0487778172621374), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -1.0487778172621374), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 235.32510959217723), ('move_right', 0)]
best: move_left current state : (0, 0.25, -8) -100.0 [('nothing', -100.5), ('move_left', -40.5), ('move_right', -45.0)]
Reward: -100
Iteration 319 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.34276467857003)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.34276467857003)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 363.80800154093566), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.6795447400479)]
Reward: 204
Iteration 320 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 112.43983968705115), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 112.43983968705115), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 59.67), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 194.5607652588094), ('move_right', 0)]
Reward: 204
Iteration 321 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.7098438131837)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.7098438131837)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 108.56208821726015)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.06650420919473), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 322 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -17.745792313770295), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -17.745792313770295), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 207.3371814), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 226.6493916), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 323 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 174.4930252103106)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 174.4930252103106)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 363.16946450066933), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.37568131803354)]
Reward: 215
Iteration 324 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 64.43639585683978), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 64.43639585683978), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 344.49177030281754), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.93019065567808)]
Reward: 215
Iteration 325 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 186.6547367981491)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 186.6547367981491)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 140.485185), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 119.355), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 326 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 18.86338840556967), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', 18.86338840556967), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_left current state : (0, 1.25, -19) -100.0 [('nothing', 0), ('move_left', 27.242673205521), ('move_right', 0)]
best: nothing current state : (0, -0.0, -9) -100.0 [('nothing', 0), ('move_left', -90.0), ('move_right', -45.0)]
Reward: -300
Iteration 327 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.13577639926032)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.13577639926032)]
best: nothing current state : (1, 1.5, -18) -26.9465522806 [('nothing', 365.2526740403982), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 237.2465529464363), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 328 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 134.94006648614143), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 134.94006648614143), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 122.57757671452406), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 197.39253568116658), ('move_right', 0)]
Reward: 215
Iteration 329 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.98688000743488)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.98688000743488)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 353.2173523113057), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 230.57258706250542), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 330 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 116.28051626653706), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 116.28051626653706), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 324.11019350323426), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 202.6747749768166), ('move_right', 0)]
Reward: 215
Iteration 331 Learning Q-Table
best: move_right current state : (2, 1.75, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 1.75, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (1, 0.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.06297692262348)]
Reward: 278
Iteration 332 Learning Q-Table
best: move_right current state : (0, -2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -3, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -2, -8) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -100
Iteration 333 Learning Q-Table
best: nothing current state : (0, -3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -2, -17) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.75, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 334 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -12.666000000000002)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -12.666000000000002)]
best: move_right current state : (0, -0.25, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.75113345897466)]
Reward: 142
Iteration 335 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 146.45692751345018), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 146.45692751345018), ('move_right', -87.43070932334369)]
best: nothing current state : (1, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -9) 100 [('nothing', 0), ('move_right', 0)]
Reward: 131
Iteration 336 Learning Q-Table
best: nothing current state : (2, 1.75, -24) -100.0 [('nothing', 0), ('move_right', -28.96018059815789)]
best: nothing current state : (2, 1.75, -24) -100.0 [('nothing', 0), ('move_right', -28.96018059815789)]
best: move_right current state : (2, 1.0, -19) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, -0.25, -10) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: 84
Iteration 337 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 102.27113895649832), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 102.27113895649832), ('move_right', -56.22141343812249)]
best: move_left current state : (1, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 1.75, -6) 100 [('nothing', 0), ('move_right', 0)]
Reward: 118
Iteration 338 Learning Q-Table
best: move_right current state : (2, 1.75, -24) -100.0 [('nothing', -51.0), ('move_right', -28.96018059815789)]
best: move_right current state : (2, 1.75, -24) -100.0 [('nothing', -51.0), ('move_right', -28.96018059815789)]
best: move_left current state : (1, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 231.14408384583643)]
Reward: 131
Iteration 339 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 73.55966866125723), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 73.55966866125723), ('move_right', -87.43070932334369)]
best: move_right current state : (2, 1.75, -19) -37.241639747 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 1.5, -6) -2.52115111324 [('nothing', 0), ('move_right', 0)]
Reward: -200
Iteration 340 Learning Q-Table
best: move_right current state : (1, 0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.5, -19) -37.241639747 [('nothing', 45.0), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -3, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 341 Learning Q-Table
best: move_right current state : (0, -1.5, -24) -100.0 [('nothing', -30.0), ('move_left', -32.17249192409603), ('move_right', -12.666000000000002)]
best: move_right current state : (0, -1.5, -24) -100.0 [('nothing', -30.0), ('move_left', -32.17249192409603), ('move_right', -12.666000000000002)]
best: nothing current state : (0, -2, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -3, -8) 150 [('nothing', 0), ('move_left', 42.6)]
Reward: 211
Iteration 342 Learning Q-Table
best: nothing current state : (-2, -4, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -4, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -3, -19) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, -0.0, -8) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 343 Learning Q-Table
best: move_left current state : (0, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -19) -47.8784607102 [('nothing', 54.629999999999995), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.0, -8) -65.6388261835 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Loading mission from ghast_survival_mission.xml
Iteration 345 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 42.629616671390934), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 42.629616671390934), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 76.5), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -7) 150 [('nothing', 0), ('move_right', 0)]
Reward: 208
Iteration 346 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.1835297745001)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.1835297745001)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 361.42392273666565), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 225.90081094375378), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 347 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 19.31927613878404), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 19.31927613878404), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 332.679567945309), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 190.12579342128225)]
Reward: 204
Iteration 348 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 143.84369066054646)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 143.84369066054646)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.8508377122096), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 109.65)]
Reward: 215
Iteration 349 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 81.15487175664549), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 81.15487175664549), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 348.8232964086757), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 187.41285)]
Reward: 226
Iteration 350 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.68315573905375)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.68315573905375)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 338.1905863985467), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.1008586920855)]
Reward: 215
Iteration 351 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 129.2829072281585), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 129.2829072281585), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 190.0220644045168), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 0), ('move_right', 0)]
Reward: 215
Iteration 352 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.17520433874375)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.17520433874375)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 342.06366808660835), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.27060108445986)]
Reward: 215
Iteration 353 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 118.5444737829081), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 118.5444737829081), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 178.01544508316178), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 207.3097821465), ('move_right', 0)]
Reward: 215
Iteration 354 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.38156286494524)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.38156286494524)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 346.0257479859638), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.63056766062766), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 355 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 107.4255845748263), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 107.4255845748263), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 231.80374620216324), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 209.61684750255), ('move_right', 0)]
Reward: 215
Iteration 356 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.1146378030929)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.1146378030929)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 354.00719388836296), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 220.34139736243935), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 357 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 23.830551071815755), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 23.830551071815755), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 98.55), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -7) 150 [('nothing', 62.4), ('move_right', 0)]
Reward: 215
Iteration 358 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 183.28565417788752)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 183.28565417788752)]
best: nothing current state : (1, 0.75, -15) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -4, -3) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 359 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 115.77885246486949), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 115.77885246486949), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 270.14767659227925), ('move_right', 0)]
best: nothing current state : (2, 4, -7) 150 [('nothing', 108.17999999999999), ('move_right', 0)]
Reward: 226
Iteration 360 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.42222403051605)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.42222403051605)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 358.90745493058586), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.73897815370754), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 361 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 133.12931910493452), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 133.12931910493452), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 349.903957322245), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 206.3723424837716), ('move_right', 0)]
Reward: 215
Iteration 362 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.90761270237908)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.90761270237908)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.85691189752237), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.61728470759527), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 363 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.20152997196976), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.20152997196976), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 345.400162486073), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.28805539489758)]
Reward: 215
Iteration 364 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.93222186276418)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.93222186276418)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 362.03132954587863), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.83209929531668), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 365 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 189.88862780210468), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 189.88862780210468), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 351.844472870703), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.9606397386401), ('move_right', 0)]
Reward: 215
Iteration 366 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.5894622436025)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.5894622436025)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.5850237405442), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.28246950672167), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 367 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 209.51520072452627), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 209.51520072452627), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 345.06653035872034), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.5016387764283)]
Reward: 215
Iteration 368 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 102.56369936384456)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 102.56369936384456)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 185.51341301484052)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 141.255)]
Reward: 289
Iteration 369 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 20.818919202202892), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 20.818919202202892), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 258.13084446), ('move_right', -30.0)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 245.35457412), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 370 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.0279500945271)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.0279500945271)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 364.39425747039746), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 215.89772865470516), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 371 Learning Q-Table
best: nothing current state : (0, -1.5, -24) -100.0 [('nothing', -30.0), ('move_left', -32.17249192409603), ('move_right', -41.03869192409603)]
best: nothing current state : (0, -1.5, -24) -100.0 [('nothing', -30.0), ('move_left', -32.17249192409603), ('move_right', -41.03869192409603)]
best: nothing current state : (0, -1.25, -20) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.75, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 51.0)]
Reward: -300
Iteration 372 Learning Q-Table
best: nothing current state : (0, -2, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -19) -100.0 [('nothing', 57.779999999999994), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 91.02000000000001)]
Reward: -300
Iteration 373 Learning Q-Table
best: move_right current state : (0, -2, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -17) -26.5339353272 [('nothing', 0), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -2, -6) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 374 Learning Q-Table
best: move_left current state : (0, -3, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.75, -19) -26.5339353272 [('nothing', 0), ('move_left', 41.79), ('move_right', 0)]
best: move_left current state : (0, 0.25, -10) -44.5351109483 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 84
Iteration 375 Learning Q-Table
best: move_left current state : (0, -2, -24) -100.0 [('nothing', -7.960180598157894), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -2, -24) -100.0 [('nothing', -7.960180598157894), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 15.892466715499832), ('move_right', 0)]
best: move_left current state : (1, 2.0, -8) 150 [('nothing', 0), ('move_left', 112.94999999999999), ('move_right', 0)]
Reward: 221
Iteration 376 Learning Q-Table
best: move_right current state : (2, 1.25, -25) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 1.25, -25) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_left current state : (1, -0.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) -3.20585028238 [('nothing', 0), ('move_left', 0), ('move_right', 185.5785)]
Reward: -100
Iteration 377 Learning Q-Table
best: nothing current state : (2, 1.25, -25) -100.0 [('nothing', -11.17249192409602), ('move_right', -30.0)]
best: nothing current state : (2, 1.25, -25) -100.0 [('nothing', -11.17249192409602), ('move_right', -30.0)]
best: nothing current state : (2, 1.0, -19) -100.0 [('nothing', 0), ('move_right', -30.0)]
best: nothing current state : (2, 0.5, -8) -100.0 [('nothing', 0), ('move_right', -60.0)]
Reward: -300
Iteration 378 Learning Q-Table
best: move_right current state : (2, 1.25, -25) -100.0 [('nothing', -58.820744346867215), ('move_right', -30.0)]
best: move_right current state : (2, 1.25, -25) -100.0 [('nothing', -58.820744346867215), ('move_right', -30.0)]
best: move_right current state : (1, -0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 379 Learning Q-Table
best: move_left current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 29.27350807590397)]
best: nothing current state : (0, -0.25, -8) -65.6388261835 [('nothing', 0), ('move_left', -90.0), ('move_right', 0)]
Reward: -150
Iteration 380 Learning Q-Table
best: nothing current state : (-2, -5, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -5, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -4, -19) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -1.75, -8) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -100
Loading mission from ghast_survival_mission.xml
Iteration 382 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 17.286205152113126), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 17.286205152113126), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 132.70499999999998), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 64.5), ('move_right', 0)]
Reward: 208
Iteration 383 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.4653503831922)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.4653503831922)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.8452988256898), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 384 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.00810769068846), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.00810769068846), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 346.69706288403273), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 195.02207069999997), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 385 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4191543177836)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4191543177836)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 300.3917091779829), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 215.6284100582936), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 386 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 22.951663008321283), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 22.951663008321283), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 145.1372295776428), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 98.72999999999999)]
Reward: 215
Iteration 387 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.93842885174735)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.93842885174735)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 363.47156047071), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.43988704080553), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 388 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 224.44230232459572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 224.44230232459572), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -37.241639747 [('nothing', 157.24349999999998), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 133.611)]
Reward: 215
Iteration 389 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.52587641334014)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.52587641334014)]
best: move_right current state : (1, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.30792092856387), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 390 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 59.840004855446), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 59.840004855446), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 170.98155), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 391 Learning Q-Table
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -29.62282615444493), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: nothing current state : (0, 1.75, -24) -100.0 [('nothing', -29.62282615444493), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_left current state : (0, 1.25, -18) -100.0 [('nothing', -4.317623790000006), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.75, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 392 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 142.90793289118022)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 142.90793289118022)]
best: move_left current state : (0, 0.75, -18) -15.7875285356 [('nothing', 0), ('move_left', 353.97932293108414), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 67.8)]
Reward: 163
Iteration 393 Learning Q-Table
best: move_right current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -49.9601805981579), ('move_right', -43.184282559915225)]
best: move_right current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -49.9601805981579), ('move_right', -43.184282559915225)]
best: move_left current state : (0, -0.75, -16) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -6) 150 [('nothing', 32.1), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 394 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 172.11016970312096), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 172.11016970312096), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 248
Iteration 395 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 180.49309134247468)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 180.49309134247468)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 319.9627194420761), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 240.7155446499947), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 396 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 91.51693819402678), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 91.51693819402678), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 266.55737361459546), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.7724478170481), ('move_right', 0)]
Reward: 215
Iteration 397 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 193.37379917419722)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 193.37379917419722)]
best: move_left current state : (1, 1.5, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.1894207591219)]
Reward: 110
Iteration 398 Learning Q-Table
best: move_left current state : (1, 2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (1, 2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -30.0)]
best: move_right current state : (2, 2, -15) -47.8784607102 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 1.25, -4) -34.8988702318 [('nothing', 0), ('move_right', 0)]
Reward: -100
Iteration 399 Learning Q-Table
best: nothing current state : (1, 2, -23) -100.0 [('nothing', 0), ('move_left', -35.363538213048), ('move_right', -30.0)]
best: nothing current state : (1, 2, -23) -100.0 [('nothing', 0), ('move_left', -35.363538213048), ('move_right', -30.0)]
best: move_left current state : (1, 2.0, -19) -100.0 [('nothing', -16.50485056868419), ('move_left', 164.025809958097), ('move_right', -11.172491924096027)]
best: move_left current state : (1, 0.25, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 400 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 99.99812120889007)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 98.48843286098545)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 364.06205844173866), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 178.73259453138533)]
Reward: 215
Iteration 401 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 115.06888822203948), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 27.434841055021707), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 2.0, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 0)]
Reward: 215
Iteration 402 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 69.54521470451868)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 69.54521470451868)]
best: move_right current state : (1, 1.25, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 109.59237627856916)]
best: move_right current state : (0, -2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 403 Learning Q-Table
best: move_right current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -2, -17) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -2, -7) 100 [('nothing', 0), ('move_left', 0)]
Reward: 135
Iteration 404 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 16.872797233120934)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 16.872797233120934)]
best: nothing current state : (-1, -1.5, -19) -15.7875285356 [('nothing', 195.5034885), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 83.39999999999999)]
Reward: 226
Iteration 405 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 58.77867407193415), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 58.77867407193415), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 294.8218958753313), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 145.36499999999998), ('move_right', 0)]
Reward: 243
Iteration 406 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 55.82310461605712)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 55.82310461605712)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 341.18856700445167), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 233.0008812549963), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 407 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 100.6314600147954), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 100.6314600147954), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 294.9848271127319), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 100 [('nothing', 118.473), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 408 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 112.47256273441758)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 112.47256273441758)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 353.73226127961505), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 234.2006168784974), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 409 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 129.97728954601845), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 129.97728954601845), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 272.0312789789123), ('move_right', 0)]
best: nothing current state : (2, 4, -5) 150 [('nothing', 0), ('move_right', 0)]
Reward: 215
Iteration 410 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 163.7969823221634)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 163.7969823221634)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.87276795927977), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 228.4404318149482), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 411 Learning Q-Table
best: move_left current state : (0, 0.0, -20) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.0, -20) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.25, -12) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 2, 1) -3.20585028238 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 23
Iteration 412 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 14.468130177838486), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 14.468130177838486), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 235.42189528523863), ('move_right', 0)]
best: move_left current state : (1, 3, -6) 150 [('nothing', 0), ('move_left', 76.2), ('move_right', 0)]
Reward: 226
Iteration 413 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 194.5595374151404)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 194.5595374151404)]
best: move_left current state : (1, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 30.0), ('move_right', 0)]
best: move_left current state : (0, -4, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 163
Iteration 414 Learning Q-Table
best: nothing current state : (0, 1.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.25, -17) -100.0 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -6) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -50
Iteration 415 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -16.5)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 84.8180669706679), ('move_right', -11.172491924096027)]
best: nothing current state : (2, 2, -8) 100 [('nothing', 0), ('move_right', 0)]
Reward: 126
Iteration 416 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 113.01918426650226)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 113.01918426650226)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 367.5430671159803), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 100 [('nothing', 0), ('move_left', 166.863765), ('move_right', 0)]
Reward: 213
Iteration 417 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 143.6333057777287), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 143.6333057777287), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 176.21506070434998), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 64.5)]
Reward: 215
Iteration 418 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 157.20385719724965)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 157.20385719724965)]
best: nothing current state : (1, 1.0, -17) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, -0.5, -8) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 419 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 121.23534033161906), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 121.23534033161906), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 334.913435588101), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.85114714349982)]
Reward: 215
Iteration 420 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 74.67916182502675)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 74.67916182502675)]
best: nothing current state : (2, 1.75, -14) -68.6546849676 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (0, -4, -4) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 421 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 51.79407911190064), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 51.79407911190064), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 232.65532669966703), ('move_right', 0)]
best: move_left current state : (1, 3, -6) 150 [('nothing', 0), ('move_left', 121.14000000000001), ('move_right', 0)]
Reward: 237
Iteration 422 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 10.679007787247798)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 10.679007787247798)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 353.46321926863266), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 224.40830227046374), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 423 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 149.97523069551562), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 149.97523069551562), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -16) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 424 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 155.89029169981893)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 155.89029169981893)]
best: move_right current state : (1, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 121.71466339499841)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 96.36)]
Reward: 278
Iteration 425 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 12.927822800654305), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -35.363538213048)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 187.700542493045), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 426 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -60.41123283996458), ('move_right', -54.78109820863473)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 0)]
best: nothing current state : (0, -1.25, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 427 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 44.725746052507944)]
best: nothing current state : (-2, -3, -23) -100.0 [('nothing', -30.0), ('move_left', -53.17249192409603)]
best: move_right current state : (0, -0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.0, -10) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 34
Iteration 428 Learning Q-Table
best: nothing current state : (-2, -3, -23) -100.0 [('nothing', -28.960180598157898), ('move_left', -53.17249192409603)]
best: nothing current state : (-2, -3, -23) -100.0 [('nothing', -28.960180598157898), ('move_left', -53.17249192409603)]
best: nothing current state : (-2, -1.75, -15) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, 0.25, -3) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -300
Iteration 429 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -7.691977763244431)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -7.691977763244431)]
best: nothing current state : (-1, -2.0, -18) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.75, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 430 Learning Q-Table
best: move_right current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -30.0), ('move_right', -5.581485790276815)]
best: move_right current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -30.0), ('move_right', -5.581485790276815)]
best: move_left current state : (0, -2, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 431 Learning Q-Table
best: move_right current state : (0, -3, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 4.5768194018421084)]
best: move_right current state : (0, -3, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 4.5768194018421084)]
best: nothing current state : (-1, -4, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -3, -10) 100 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -1.75, 2) 100 [('nothing', 0), ('move_left', 0)]
Reward: 120
Iteration 432 Learning Q-Table
best: move_left current state : (-2, -5, -24) -100.0 [('nothing', -51.0), ('move_left', 0)]
best: move_left current state : (-2, -5, -24) -100.0 [('nothing', -51.0), ('move_left', 0)]
best: move_left current state : (-1, -2, -19) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 433 Learning Q-Table
best: move_left current state : (0, -1.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.5, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 1.75, -9) 100 [('nothing', -90.0), ('move_right', 0)]
Reward: 146
Iteration 434 Learning Q-Table
best: move_right current state : (2, 1.0, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 1.0, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (1, -0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 45.0)]
best: nothing current state : (0, -4, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 435 Learning Q-Table
best: nothing current state : (0, -3, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -28.968718342806557)]
best: nothing current state : (0, -3, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -28.968718342806557)]
best: nothing current state : (0, -2, -19) -100.0 [('nothing', 37.751999999999995), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -90.0)]
Reward: -250
Iteration 436 Learning Q-Table
best: move_right current state : (0, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 2.0254617869519924)]
best: move_right current state : (0, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 2.0254617869519924)]
best: move_left current state : (-1, -4, -19) -46.8615063441 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -2, -6) 100 [('nothing', 0), ('move_left', 0)]
Reward: -100
Iteration 437 Learning Q-Table
best: nothing current state : (-1, -1.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -1.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -0.75, -20) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, 0.5, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 438 Learning Q-Table
best: nothing current state : (-1, -0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, 0.0, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -0.5, -8) -60.512037568 [('nothing', 0), ('move_left', 0)]
Reward: -100
Iteration 439 Learning Q-Table
best: move_left current state : (-2, -1.0, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -1.0, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-1, 0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 100 [('nothing', 184.187085), ('move_left', 0), ('move_right', 0)]
Reward: 191
Iteration 440 Learning Q-Table
best: move_left current state : (0, 2, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 140.21175653948973)]
best: nothing current state : (0, 1.25, -8) -65.6388261835 [('nothing', 32.1), ('move_left', 0), ('move_right', 0)]
Reward: -250
Loading mission from ghast_survival_mission.xml
Iteration 442 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 73.87996146413454), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 73.87996146413454), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 244.20072868976692), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 209
Iteration 443 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 116.67742261021489)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 116.67742261021489)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 365.7669891987921), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 221.5858115893246), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 444 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 76.02248088870303), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 76.02248088870303), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 340.89474905472065), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 195.02451216)]
Reward: 215
Iteration 445 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 78.15073301861524)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 78.15073301861524)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 359.74674416918197), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.61006811252722), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 446 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 126.52398074035041), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 126.52398074035041), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 346.1945652288229), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 211.231793251785), ('move_right', 0)]
Reward: 215
Iteration 447 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 159.23180066269202)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 159.23180066269202)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 337.33927648118623), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.22704767876905), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -4, 2) 200 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 448 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 163.46497548873427), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 163.46497548873427), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 350.70573363571157), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.04071347193366), ('move_right', 0)]
Reward: 215
Iteration 449 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 183.7038628100824)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 183.7038628100824)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 362.70574135218556), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.61281617196974)]
Reward: 215
Iteration 450 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 96.01601103366636), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 96.01601103366636), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 313.1255260517589), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.92849943035355), ('move_right', 0)]
Reward: 215
Iteration 451 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 208.44424577455547)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 208.44424577455547)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 346.60560784046106), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.75893337513833), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 452 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.46471100873143), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.46471100873143), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 215.94051008283685), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 204.31544949), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 453 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 127.26599815073726)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 127.26599815073726)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 217.23588911038837)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 150.852)]
Reward: 300
Iteration 454 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -20.950524039541982), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -20.950524039541982), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 342.13367798630446), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 258.448201884), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 455 Learning Q-Table
best: move_left current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -60.41123283996458), ('move_right', -67.3069493442022)]
best: move_left current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -60.41123283996458), ('move_right', -67.3069493442022)]
best: nothing current state : (2, 3, -18) -15.7875285356 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -9) 100 [('nothing', 0), ('move_right', 39.3)]
Reward: 118
Iteration 456 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.93247379616926)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.93247379616926)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 355.7778637981208), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.43125336259683), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 457 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 167.04727013280515), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 167.04727013280515), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 257.45299190498577), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.54994960124748), ('move_right', 0)]
Reward: 215
Iteration 458 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.2135988726587)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.2135988726587)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 367.5126359159519), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.22897132037883)]
Reward: 204
Iteration 459 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 132.18868494093624), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 132.18868494093624), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 328.43216018635803), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.98496472087322), ('move_right', 0)]
Reward: 204
Iteration 460 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.33977177259865)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.33977177259865)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 358.07388066746364), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.90187735381778), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 461 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 165.20880606630143), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 165.20880606630143), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 354.1062275865782), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.98947530461126), ('move_right', 0)]
Reward: 204
Iteration 462 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 239.9875125169621)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 239.9875125169621)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 351.4516055008642), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.93131414767245), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 463 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 189.70554059828842), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 189.70554059828842), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 356.1712019019881), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 212.3622552762495), ('move_right', 0)]
Reward: 215
Iteration 464 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.46655981397484)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.46655981397484)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 354.2955180949067), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 199.26027992426518)]
Reward: 215
Iteration 465 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.47274706530231), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.47274706530231), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 289.2820792138643), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.8926327132279), ('move_right', 0)]
Reward: 215
Iteration 466 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.4550667000965)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.4550667000965)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 359.8222796733699), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 203.98219594698563)]
Reward: 204
Iteration 467 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 203.055366111713), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 203.055366111713), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.72484289925953), ('move_right', 0)]
Reward: 204
Iteration 468 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.50169237903052)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.50169237903052)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 352.78494664371425), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.15191990337073), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 469 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 116.40249771752238), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 116.40249771752238), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 328.0664180653373), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.70739002948167), ('move_right', 0)]
Reward: 215
Iteration 470 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.42648806027773)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.42648806027773)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 355.5950386216112), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.0063439323595), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 471 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 162.10154691640489), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 162.10154691640489), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 362.0280351556131), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.59517302063716), ('move_right', 0)]
Reward: 215
Iteration 472 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 128.5207068779559)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 128.5207068779559)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 357.8184302148357), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.60444075265164), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 473 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 150.94149322370896), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 150.94149322370896), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 361.5981765151203), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.916621114446), ('move_right', 0)]
Reward: 215
Iteration 474 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.02310852685616), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 475 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -32.17249192409603), ('move_right', -41.03869192409603)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -32.17249192409603), ('move_right', -41.03869192409603)]
best: move_right current state : (0, -0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 110.287098)]
best: move_right current state : (0, 1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 35.4)]
Reward: 152
Iteration 476 Learning Q-Table
best: move_right current state : (0, -1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: move_right current state : (-1, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 158.52366)]
Reward: 142
Iteration 477 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -21.60710687096325), ('move_right', -41.03869192409603)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -21.60710687096325), ('move_right', -41.03869192409603)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 44.050200000000004), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 67.8), ('move_right', 0)]
Reward: 289
Iteration 478 Learning Q-Table
best: nothing current state : (2, 2, -24) -100.0 [('nothing', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (2, 2, -24) -100.0 [('nothing', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (2, 1.75, -18) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 0.5, -8) -100.0 [('nothing', -90.0), ('move_right', -60.0)]
Reward: -300
Iteration 479 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -28.960180598157898)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -28.960180598157898)]
best: move_left current state : (1, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 66.0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 236.5161759687993), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 480 Learning Q-Table
best: nothing current state : (0, 0.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 96.29446499999999), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 1.75, -8) -26.5339353272 [('nothing', 0), ('move_right', 0)]
Reward: -50
Iteration 481 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -29.432307016868428)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -29.432307016868428)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 109.20693255805685)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 208.1613231781595), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 482 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -30.87009540783217), ('move_right', -41.03869192409603)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -30.87009540783217), ('move_right', -41.03869192409603)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 96.17514), ('move_right', 0)]
best: nothing current state : (0, 1.75, -9) 150 [('nothing', 54.3), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 483 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -16.80071574254874)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -16.80071574254874)]
best: nothing current state : (1, 0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 229.11292622471166), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 484 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 48.349982149755604), ('move_right', -35.363538213048)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 48.349982149755604), ('move_right', -35.363538213048)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 45.0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 107.55), ('move_right', 0)]
Reward: 153
Iteration 485 Learning Q-Table
best: move_left current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -49.9601805981579), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -49.9601805981579), ('move_right', -55.965256352617374)]
best: move_right current state : (2, 2, -18) -26.5339353272 [('nothing', -51.0), ('move_right', -30.0)]
best: move_right current state : (2, 1.75, -6) -5.01999024652 [('nothing', 0), ('move_right', 35.4)]
Reward: 44
Iteration 486 Learning Q-Table
best: move_right current state : (1, 1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.5, -17) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 100 [('nothing', 224.87904835729816), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 487 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -21.71670538364041), ('move_right', -41.03869192409603)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -21.71670538364041), ('move_right', -41.03869192409603)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 0), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 186.23095949999998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 488 Learning Q-Table
best: move_right current state : (1, 1.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 1.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 124.057098), ('move_right', 0)]
best: move_right current state : (0, -0.5, -8) -65.6388261835 [('nothing', 0), ('move_left', -90.0), ('move_right', 0)]
Reward: 51
Iteration 489 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -43.932992943880144)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -43.932992943880144)]
best: move_left current state : (1, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 162.15485279063978), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.71533385010872), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 490 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.75, -18) -100.0 [('nothing', 0), ('move_left', 337.2587096545806), ('move_right', 0)]
best: move_right current state : (0, 0.25, -8) -100.0 [('nothing', -100.5), ('move_left', -58.349999999999994), ('move_right', -45.0)]
Reward: -50
Iteration 491 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -11.066819821682067)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', -11.066819821682067)]
best: move_left current state : (1, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 222.02299710848047), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 203.98753716288994)]
Reward: 152
Iteration 492 Learning Q-Table
best: move_right current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -1.1116605000000035), ('move_right', 0)]
best: move_right current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -1.1116605000000035), ('move_right', 0)]
best: move_right current state : (0, -0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 193.8007336950761), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 493 Learning Q-Table
best: nothing current state : (-1, -3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -2, -19) -100.0 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: move_left current state : (-2, -1.75, -8) -61.7164595346 [('nothing', -30.0), ('move_left', 0)]
Reward: -250
Iteration 494 Learning Q-Table
best: nothing current state : (-1, -3, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -3, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -2, -18) -100.0 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -2, -8) -26.5339353272 [('nothing', 0), ('move_left', 79.779)]
Reward: 79
Iteration 495 Learning Q-Table
best: move_left current state : (-2, -4, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -4, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, -2, -18) -37.241639747 [('nothing', 47.473519401842104), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 70.38)]
Reward: 215
Iteration 496 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 55.80224464411591), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 55.80224464411591), ('move_right', -56.92696867322963)]
best: nothing current state : (0, -0.5, -19) -37.241639747 [('nothing', 76.5), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 174.6555), ('move_right', 0)]
Reward: 215
Iteration 497 Learning Q-Table
best: move_left current state : (1, 1.75, -23) -100.0 [('nothing', 0), ('move_left', 29.2569488018421), ('move_right', -30.0)]
best: move_left current state : (1, 1.75, -23) -100.0 [('nothing', 0), ('move_left', 29.2569488018421), ('move_right', -30.0)]
best: move_right current state : (2, 2, -18) -61.030281088 [('nothing', -51.0), ('move_right', -11.885997073956666)]
best: nothing current state : (2, 1.25, -8) -61.030281088 [('nothing', 0), ('move_right', 0)]
Reward: -250
Iteration 498 Learning Q-Table
best: move_left current state : (1, 1.75, -24) -100.0 [('nothing', -11.172491924096027), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (1, 1.75, -24) -100.0 [('nothing', -11.172491924096027), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (2, 2, -19) -37.5991138778 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 1.25, -8) -20.9601525107 [('nothing', -75.0), ('move_right', 0)]
Reward: -100
Iteration 499 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 29.899944659208792)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 29.899944659208792)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 183.89324974408765)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.36051358655328), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 500 Learning Q-Table
best: move_right current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -44.161874366706186), ('move_right', -41.03869192409603)]
best: move_right current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -44.161874366706186), ('move_right', -41.03869192409603)]
best: nothing current state : (-1, -3, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -3, -9) 100 [('nothing', 81.0), ('move_left', 0)]
Reward: 146
Iteration 501 Learning Q-Table
best: nothing current state : (-2, -4, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: move_left current state : (-2, -4, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: nothing current state : (-2, -3, -18) -100.0 [('nothing', 50.690999999999995), ('move_left', 0)]
best: move_right current state : (-1, 0.5, -7) -37.241639747 [('nothing', -90.0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 502 Learning Q-Table
best: nothing current state : (0, -2, -24) -100.0 [('nothing', -7.960180598157894), ('move_left', -27.404751909446077), ('move_right', -30.0)]
best: nothing current state : (0, -2, -24) -100.0 [('nothing', -7.960180598157894), ('move_left', -27.404751909446077), ('move_right', -30.0)]
best: nothing current state : (0, -2, -20) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.75, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -54.3)]
Reward: -300
Loading mission from ghast_survival_mission.xml
Iteration 504 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 181.96600628703632), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 181.96600628703632), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 192.58109675820646), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.89580300044986)]
Reward: 209
Iteration 505 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.31687263051987)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.31687263051987)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 242.32072237727186)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 242.3523595105873), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 506 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 29.83907932678511), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 29.83907932678511), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 242.17550863087948), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 245.41374131880002), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 507 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.58176899386876)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.58176899386876)]
best: nothing current state : (0, 0.5, -18) -15.7875285356 [('nothing', 59.4459449018421), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 195.59640000000002)]
Reward: 226
Iteration 508 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 156.19035283022947), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 156.19035283022947), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 310.16524526367334), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 207.520814643), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 509 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 148.60476320558405)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 148.60476320558405)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 287.3302135172665)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 256.3466516574111), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 510 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 64.57982751985553), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 64.57982751985553), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 145.29108143128946), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 194.86167164999998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 511 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -67.3069493442022)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -67.3069493442022)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 112.45836), ('move_right', -20.37)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 180.7046355), ('move_right', 0)]
Reward: 131
Iteration 512 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 173.42263996210474), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 173.42263996210474), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 339.09800154671257), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 201.017158512)]
Reward: 205
Iteration 513 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 161.26221770093088)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 161.26221770093088)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.5542333761805), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 266.14265616018776), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 514 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 194.1650678393292), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 194.1650678393292), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 324.3719160774713), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.2270621003149)]
Reward: 215
Iteration 515 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.78964180534786)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.78964180534786)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 376.5307602113827), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 250.79985931213142), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 516 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.26694171261394), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.26694171261394), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 358.02851791426656), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.25894347022043)]
Reward: 215
Iteration 517 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.2517967290004)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.2517967290004)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 383.8114899416073), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 240.05990151849198), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 518 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.2229226490137), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.2229226490137), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 361.693709894918), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.6812604291543)]
Reward: 215
Iteration 519 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.95952409462458)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.95952409462458)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 385.6860134146727), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 126.1485), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 520 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 229.09166689868897), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 229.09166689868897), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 334.52845988432443), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 213.15357869337464), ('move_right', 0)]
Reward: 215
Iteration 521 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.0172902924811)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.0172902924811)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 352.82475939027086), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 232.5419310629444), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 522 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.7625241962217), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.7625241962217), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 343.1159955270395), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.676882300408)]
Reward: 215
Iteration 523 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.69935042366012)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.69935042366012)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.73991089207294), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 227.27935174406107), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 524 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.20838499730914), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.20838499730914), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 361.6899750551889), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.8416347801122), ('move_right', 0)]
Reward: 215
Iteration 525 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.85133796602605)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.85133796602605)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.4017431476694), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 223.59554622084275), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 526 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.68037009057701), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.68037009057701), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 358.6976455810527), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 216.3645702501), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 527 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.45627892236115)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.45627892236115)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.5598840696214), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 188.39127601402296)]
Reward: 215
Iteration 528 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.6130608136237), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.6130608136237), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 362.0354729726659), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.48914434607855), ('move_right', 0)]
Reward: 215
Iteration 529 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.62717986838135)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.62717986838135)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 323.0351449593099)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.37389320981606)]
Reward: 278
Iteration 530 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 59.833023095127814), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 59.833023095127814), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 205.1622584969026), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 258.48961892316004), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 531 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -45.54984846503756)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -45.54984846503756)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 108.765)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.01688235458994), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 532 Learning Q-Table
best: move_right current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -51.0), ('move_right', -42.529062072060015)]
best: move_right current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -51.0), ('move_right', -42.529062072060015)]
best: nothing current state : (-2, -2, -18) -61.3741746879 [('nothing', -24.71313431132317), ('move_left', -30.0)]
best: nothing current state : (-2, -1.0, -8) -61.3741746879 [('nothing', 0), ('move_left', 0)]
Reward: -300
Iteration 533 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -40.747922647319115)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -40.747922647319115)]
best: nothing current state : (-1, -1.5, -18) -26.5339353272 [('nothing', 90.63494999999999), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 200.903170155), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 534 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.66729253724031), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.66729253724031), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 1.25, -18) -26.5339353272 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 198.988995)]
Reward: 142
Iteration 535 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 14.477612896374183), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 14.477612896374183), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 266.1604666247798), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.25, -8) -100.0 [('nothing', -45.0), ('move_left', -90.0), ('move_right', 0)]
Reward: -250
Iteration 536 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 38.98246901489587), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 38.98246901489587), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 156.31232663734588), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -8) -100.0 [('nothing', -45.0), ('move_left', -90.0), ('move_right', -75.0)]
Reward: -250
Iteration 537 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -28.215574523684197)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -28.215574523684197)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 67.14832074494453), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.86172524687123)]
Reward: 142
Iteration 538 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.9977229817669), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.3738176102856)]
Reward: 242
Iteration 539 Learning Q-Table
best: move_right current state : (2, 5, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 5, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -19) -26.5339353272 [('nothing', -7.8302300142270616), ('move_left', 78.852), ('move_right', 0)]
best: nothing current state : (0, -0.0, -8) 100 [('nothing', 0), ('move_left', 0), ('move_right', -45.0)]
Reward: -250
Iteration 540 Learning Q-Table
best: nothing current state : (2, 6, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 6, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -19) -99.6975184111 [('nothing', 0.629999999999999), ('move_right', 0)]
best: move_right current state : (0, 0.25, -9) -26.8364169161 [('nothing', -75.0), ('move_left', -45.0), ('move_right', 0)]
Reward: 107
Iteration 541 Learning Q-Table
best: move_right current state : (0, 4, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 4, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.25, -18) -26.5339353272 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 104.6966985)]
best: move_left current state : (0, -0.75, -9) 100 [('nothing', -90.0), ('move_left', 0), ('move_right', -54.3)]
Reward: 191
Iteration 542 Learning Q-Table
best: move_right current state : (0, 1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -0.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -1.25, -8) 100 [('nothing', 0), ('move_left', 0)]
Reward: -150
Loading mission from ghast_survival_mission.xml
Iteration 544 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 144.40692417791033), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 144.40692417791033), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 288.14697843725565), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.94240104225497), ('move_right', 0)]
Reward: 209
Iteration 545 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 165.13753195492382)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 165.13753195492382)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.5093016529419), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 99.90495)]
Reward: 215
Iteration 546 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 158.56875985755602), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 158.56875985755602), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 348.9842615590501), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.45968072957848), ('move_right', 0)]
Reward: 215
Iteration 547 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.189388797502)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.189388797502)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 326.62799615705933), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 241.41181764821295), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 548 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 186.73322976984633), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 186.73322976984633), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.0268873102086), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.22177651070493), ('move_right', 0)]
Reward: 215
Iteration 549 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 194.48888226617134)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 194.48888226617134)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 346.0631426044054), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 134.433465)]
Reward: 215
Iteration 550 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 186.71595517511935), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 186.71595517511935), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 176.3903797451315), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 186.75885), ('move_right', 0)]
Reward: 215
Iteration 551 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.26079040721132)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.26079040721132)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 327.5742393230838), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 233.48827235374907), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 552 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.66114643379711), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.66114643379711), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.0853540703575), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.75524355749346), ('move_right', 0)]
Reward: 215
Iteration 553 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 211.00097976948368)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 211.00097976948368)]
best: move_left current state : (1, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 261.6123591248033), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 141.255)]
Reward: 152
Iteration 554 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -28.56658654125348)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -28.56658654125348)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 187.440564706377)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 165.79324485), ('move_right', 0)]
Reward: 289
Iteration 555 Learning Q-Table
best: nothing current state : (-1, -2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -1.5, -18) -100.0 [('nothing', 168.71541604649997), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, 0.0, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 556 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -30.293241451281276)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -30.293241451281276)]
best: nothing current state : (0, -0.5, -19) -37.241639747 [('nothing', 150.94664999999998), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 134.16), ('move_right', 0)]
Reward: 215
Iteration 557 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.22822812660732), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.22822812660732), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.3863209164983), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 181.8922965)]
Reward: 229
Iteration 558 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.69464448381518)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.69464448381518)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 358.0702545554546), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 227.94179064762434), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 559 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.81547536541672), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.81547536541672), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 350.4381135915488), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 195.23119499999999), ('move_right', 0)]
Reward: 215
Iteration 560 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.434835581211)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.434835581211)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 344.3484492322834), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 224.05925345333705), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 561 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.54208623509845), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.54208623509845), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 348.87603801408414), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.1286704902454), ('move_right', 0)]
Reward: 215
Iteration 562 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.4487390783748)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.4487390783748)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 353.2616904985995), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.34147741733594), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 563 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 154.6581019479651), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 154.6581019479651), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.4518277569325), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 121.185), ('move_right', 0)]
Reward: 215
Iteration 564 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.8324439062843)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.8324439062843)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 330.03676943446175)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.20320767280987)]
Reward: 278
Iteration 565 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 74.47161311750236), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 74.47161311750236), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 299.297963358), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 242.14273324621203), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 566 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 197.22421297792167)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 197.22421297792167)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 335.1867009059662)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 158.60342550000001)]
Reward: 289
Iteration 567 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 109.74702626555562), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 109.74702626555562), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 310.8856052187555), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 256.1999132723484), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 568 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 206.44046743223902)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 206.44046743223902)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 358.6856265742204), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.43903419213515), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 569 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.08209117063626), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.08209117063626), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 339.4798976348334), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 201.1618365), ('move_right', 0)]
Reward: 215
Iteration 570 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.23356096657966)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.23356096657966)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.91164885959483), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.10732393449462), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 571 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.7412525117375), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.7412525117375), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 342.9844792943834), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.39006934317177), ('move_right', 0)]
Reward: 215
Iteration 572 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.57680673632632)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.57680673632632)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.77035138206475), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 221.4422453709669)]
Reward: 215
Iteration 573 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.34172862243526), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 185.33603909249743), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 195.15374999999997), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.02460754999998)]
Reward: 204
Iteration 574 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.57468953188996)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.57468953188996)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.0719195787354), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.50957175967682)]
Reward: 215
Iteration 575 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 194.54002176345392), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 194.54002176345392), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 328.77177942985276), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 205.31328555), ('move_right', 0)]
Reward: 226
Iteration 576 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.7636779477857)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.7636779477857)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 361.42753653727993), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.15670023177378)]
Reward: 215
Iteration 577 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.84936846521566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.84936846521566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 349.40615630901993), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.57304854022024), ('move_right', 0)]
Reward: 215
Iteration 578 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.09034360053795)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.09034360053795)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 363.4462856456281), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.17512675414622), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 579 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.95622422019903), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.95622422019903), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.95622397838), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.70113397815416), ('move_right', 0)]
Reward: 215
Iteration 580 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.52463428996896)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.52463428996896)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.1032152330178), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.72239785)]
Reward: 226
Iteration 581 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.19604354949544), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.19604354949544), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 336.73423126589694), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 211.51929988499998), ('move_right', 0)]
Reward: 226
Iteration 582 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 219.94152325073742)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 219.94152325073742)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 361.2889700181125), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.205678495)]
Reward: 215
Iteration 583 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 180.32117176659028), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 180.32117176659028), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 344.16975185162784), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 109.65)]
Reward: 215
Iteration 584 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 230.1732653568539)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 230.1732653568539)]
best: move_right current state : (1, 1.0, -15) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -3) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 267
Iteration 585 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 18.384806906671024), ('move_right', -35.363538213048)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 18.384806906671024), ('move_right', -35.363538213048)]
best: nothing current state : (0, 0.5, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 586 Learning Q-Table
best: move_left current state : (0, 1.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -4.736258560676707)]
best: move_left current state : (0, 1.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -4.736258560676707)]
best: nothing current state : (2, 3, -17) -15.7875285356 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 2.0, -7) -2.86343351626 [('nothing', 0), ('move_right', 34.8)]
Reward: 97
Iteration 587 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 128.94879382570173)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 128.94879382570173)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.76398256117875), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.8439749465)]
Reward: 226
Iteration 588 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 200.51556519394364), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 200.51556519394364), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -58.3854585078 [('nothing', 240.41500726499999), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -7) 100 [('nothing', 74.39999999999999), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 589 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.43802797472574)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 169.23316984818695)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 359.48798027677515), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 590 Learning Q-Table
best: move_right current state : (0, 0.0, -22) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -22) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.0, -16) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.75, -6) -44.5351109483 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 591 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.897319266258), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.897319266258), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 318.8138262961395), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 198.417225285)]
Reward: 240
Iteration 592 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 215.13712105266737)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 215.13712105266737)]
best: move_right current state : (1, 1.25, -18) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 327.2117182841763)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.52258872790236), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 593 Learning Q-Table
best: nothing current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', -16.090815763488177), ('move_right', -35.363538213048)]
best: nothing current state : (0, -0.75, -23) -100.0 [('nothing', 0), ('move_left', -16.090815763488177), ('move_right', -35.363538213048)]
best: nothing current state : (0, -0.25, -17) -100.0 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.0, -5) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 594 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -37.5), ('move_left', -16.090815763488177), ('move_right', -35.363538213048)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -37.5), ('move_left', -16.090815763488177), ('move_right', -35.363538213048)]
best: move_right current state : (0, 1.0, -16) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 3, -4) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 595 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 173.96976026292387), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 173.96976026292387), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 224.50092082159205), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 2, -5) 150 [('nothing', 64.5), ('move_left', 0), ('move_right', 0)]
Reward: 224
Iteration 596 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 213.39596200907204)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 213.39596200907204)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 339.0049794172941)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.99078246255)]
Reward: 267
Iteration 597 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 141.12841935335769), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 141.12841935335769), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 327.15139432446364), ('move_right', -30.0)]
best: nothing current state : (0, 2.0, -7) 150 [('nothing', 86.7), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 598 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 218.90617530744265)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 218.90617530744265)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 346.5007203308709)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 229.893547723785)]
Reward: 278
Iteration 599 Learning Q-Table
best: move_right current state : (0, -0.75, -23) -100.0 [('nothing', -37.5), ('move_left', -40.22375163259962), ('move_right', -35.363538213048)]
best: move_right current state : (0, -0.75, -23) -100.0 [('nothing', -37.5), ('move_left', -40.22375163259962), ('move_right', -35.363538213048)]
best: move_right current state : (-1, -2, -14) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -2, -3) 100 [('nothing', 0), ('move_left', 0)]
Reward: 143
Iteration 600 Learning Q-Table
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -71.27212641871053), ('move_left', -53.17249192409603)]
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -71.27212641871053), ('move_left', -53.17249192409603)]
best: move_left current state : (-1, -1.25, -17) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 601 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 23.18142630163087), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 23.18142630163087), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -19) -100.0 [('nothing', 0), ('move_left', 300.01597602712457), ('move_right', -30.0)]
best: nothing current state : (0, -0.75, -5) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 602 Learning Q-Table
best: move_right current state : (1, 2, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 2, -23) -100.0 [('nothing', -1.7922570125709), ('move_left', -35.363538213048), ('move_right', -30.0)]
best: move_left current state : (0, 0.75, -18) -26.960741585 [('nothing', 0), ('move_left', 357.1796969783123), ('move_right', 0)]
best: nothing current state : (0, -1.25, -8) 100 [('nothing', 86.7), ('move_left', 0), ('move_right', 0)]
Reward: -200
Iteration 603 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 7.275378234877756)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -6.727071832895657), ('move_right', -16.5)]
best: move_left current state : (0, -0.75, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -3) -22.6376828886 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Loading mission from ghast_survival_mission.xml
Iteration 605 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 160.16892783236642), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 160.16892783236642), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 221.50064457511442), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 149.3295), ('move_right', 0)]
Reward: 209
Iteration 606 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 203.7765705367641)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 203.7765705367641)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 356.5185685487451)]
best: nothing current state : (0, -4, -6) 150 [('nothing', 86.7), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 607 Learning Q-Table
best: nothing current state : (0, -0.75, -23) -100.0 [('nothing', -37.5), ('move_left', -40.22375163259962), ('move_right', -53.7146573472915)]
best: nothing current state : (0, -0.75, -23) -100.0 [('nothing', -37.5), ('move_left', -40.22375163259962), ('move_right', -53.7146573472915)]
best: move_right current state : (0, -0.5, -17) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 97.46371450718945)]
best: move_left current state : (0, 0.25, -5) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -200
Iteration 608 Learning Q-Table
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -71.27212641871053), ('move_left', -69.39323627096323)]
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -71.27212641871053), ('move_left', -69.39323627096323)]
best: move_right current state : (0, -0.5, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 124.14022010852284)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 205.1322191085), ('move_left', 0), ('move_right', 0)]
Reward: 120
Iteration 609 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', -32.17249192409603), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', -32.17249192409603), ('move_right', -49.9601805981579)]
best: nothing current state : (0, -0.25, -18) -37.241639747 [('nothing', 100.86928784999999), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 266.0399392906439), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 610 Learning Q-Table
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -1.1116605000000035), ('move_right', -19.960180598157898)]
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -1.1116605000000035), ('move_right', -19.960180598157898)]
best: move_left current state : (1, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 51.0), ('move_right', 0)]
best: nothing current state : (2, 2, -8) 100 [('nothing', 37.8), ('move_right', 0)]
Reward: 137
Iteration 611 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 225.01204689037507)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 225.01204689037507)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 364.0317153831055), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -3, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 612 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.41209077706455), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.41209077706455), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 220.6105050855), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 613 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 234.5454555140982)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 234.5454555140982)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 296.6415861937426), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 244.32548340664948)]
Reward: 215
Iteration 614 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 149.60826225703292), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 149.60826225703292), ('move_right', -56.22141343812249)]
best: move_right current state : (0, 1.0, -16) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 45.0)]
best: nothing current state : (1, 3, -7) 100 [('nothing', 113.28), ('move_left', 0), ('move_right', 0)]
Reward: 110
Iteration 615 Learning Q-Table
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -14.438342948157903), ('move_right', -19.960180598157898)]
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -14.438342948157903), ('move_right', -19.960180598157898)]
best: move_left current state : (1, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 77.04), ('move_right', 0)]
best: nothing current state : (2, 2, -8) 100 [('nothing', 67.56), ('move_right', 0)]
Reward: 148
Iteration 616 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.8629113796817)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.8629113796817)]
best: nothing current state : (1, 1.5, -18) -15.7875285356 [('nothing', 325.9467553576147), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 124.65), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 617 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 198.5114344714373), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 198.5114344714373), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 327.69484599279764), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 62.699999999999996), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 618 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.75180601238486)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.75180601238486)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 310.5577287503303), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 217.20969016224166)]
Reward: 226
Iteration 619 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.09396600374936), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.09396600374936), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 1.0, -16) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 95.48400000000001)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.8635099195), ('move_right', 0)]
Reward: 131
Iteration 620 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 55.23179121927898), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -15.955020661868431), ('move_right', -19.960180598157898)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 65.91862864614211), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.0, -10) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 10.2)]
Reward: 86
Iteration 621 Learning Q-Table
best: nothing current state : (1, 2, -23) -100.0 [('nothing', 97.81110670919337), ('move_left', -35.363538213048), ('move_right', -30.0)]
best: nothing current state : (1, 2, -23) -100.0 [('nothing', 97.81110670919337), ('move_left', -35.363538213048), ('move_right', -30.0)]
best: move_left current state : (1, 1.75, -17) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 0.0, -4) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 622 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 221.0018027938955)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 221.0018027938955)]
best: move_right current state : (1, 1.0, -17) -26.5339353272 [('nothing', -14.363538213047999), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -3, -4) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 623 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', -40.22375163259962), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', -40.22375163259962), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.75, -16) -37.241639747 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 144.09), ('move_left', 0), ('move_right', 0)]
Reward: 224
Iteration 624 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -9.44520884370367), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -9.44520884370367), ('move_right', -16.5)]
best: move_left current state : (1, 2, -18) -37.241639747 [('nothing', 0), ('move_left', 104.196), ('move_right', 0)]
best: nothing current state : (2, 2.0, -6) 100 [('nothing', 0), ('move_right', 0)]
Reward: 107
Iteration 625 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.3334022356106)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 125.74108135756897)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 320.57299798412157)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 238.26581210953165), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 626 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', -46.82911806691577), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', -46.82911806691577), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 306.0357878848186), ('move_right', 0)]
best: move_right current state : (0, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 627 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 176.23047574737686)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 176.23047574737686)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 340.8808422217446)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 235.52783838465464)]
Reward: 289
Iteration 628 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 164.76281992059344), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 164.76281992059344), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 362.4715743846897), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 168.063), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 629 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -26.92535678545427)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -7.525338114688594), ('move_right', -16.5)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 128.612598), ('move_right', 0)]
best: move_left current state : (0, -0.75, -9) -55.0161685623 [('nothing', -90.0), ('move_left', 57.3), ('move_right', -54.3)]
best: move_left current state : (1, -0.25, 4) -59.0123508616 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 630 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 193.45309376559115)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 193.45309376559115)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 327.5533171739037), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 251.56948686925824)]
Reward: 215
Iteration 631 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 143.25079560446665), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 143.25079560446665), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 349.1490020692828), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.79079378470792), ('move_right', 0)]
Reward: 215
Iteration 632 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 164.75570597219811)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 164.75570597219811)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 349.75816808251005), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 240.59864080848078)]
Reward: 215
Iteration 633 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 86.05329165582702), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 86.05329165582702), ('move_right', -56.22141343812249)]
best: move_right current state : (0, 1.0, -16) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 176.59785297585)]
best: move_left current state : (1, 3, -6) 150 [('nothing', 0), ('move_left', 155.89800000000002), ('move_right', 0)]
Reward: 142
Iteration 634 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -51.10535118422457)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -51.10535118422457)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 90.71396803131582), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 144.4785)]
Reward: 142
Iteration 635 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.6567193308635), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.6567193308635), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 342.6737486362988), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.85355564929554), ('move_right', 0)]
Reward: 204
Iteration 636 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.2962640071338)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.2962640071338)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 299.82220076817384), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 256.78606847667214), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 637 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 192.6016475243362), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 192.6016475243362), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 2.0, -17) -15.7875285356 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 167.23065), ('move_right', 0)]
Reward: 215
Iteration 638 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.68155311134979)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.68155311134979)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.0103099003013), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.84678311356916)]
Reward: 215
Iteration 639 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 122.58489470635863), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 122.58489470635863), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 361.71055137032255), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.59748895450687), ('move_right', 0)]
Reward: 215
Iteration 640 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 213.81999954987734)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 213.81999954987734)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.36125186428166), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 244.2502479336705), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 641 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 158.95905349249978), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 158.95905349249978), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 259.22505151937304), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 60.0)]
Reward: 215
Iteration 642 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.02219464604073)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.02219464604073)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 331.91136108072334), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 235.47517355356933), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 643 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 156.86636097646573), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 156.86636097646573), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 293.1963921949583), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.6182422681548), ('move_right', 0)]
Reward: 215
Iteration 644 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 201.51066886398888)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 201.51066886398888)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 373.3279506850983), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 229.33262148749853), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 645 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 84.25647945367601), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 84.25647945367601), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 2.0, -17) -15.7875285356 [('nothing', 126.66919499999999), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 141.255)]
Reward: 215
Iteration 646 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.4164526523495)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 224.0956728121638)]
best: nothing current state : (1, 1.5, -18) -15.7875285356 [('nothing', 375.12935192581836), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.71748000000002)]
Reward: 226
Iteration 647 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 168.8051897438556), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 168.8051897438556), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 314.02294721691726), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 190.40445694365), ('move_right', 0)]
Reward: 226
Iteration 648 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 264.66951798558347)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 264.66951798558347)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 369.0057903480729), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 232.91904856593655)]
Reward: 215
Iteration 649 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.4103363876162), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.4103363876162), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 321.9374001349371), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 213.70750508536224), ('move_right', 0)]
Reward: 215
Iteration 650 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 263.79790777023425)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 263.79790777023425)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 354.2749410706176)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.54333399615558)]
Reward: 289
Iteration 651 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 191.9029543357263), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 191.9029543357263), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 34.83950183925147), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 250.7279575034507), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 652 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -37.51973601772035)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -37.51973601772035)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 225.9463687494639)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 225.03283504124897), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 653 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -51.0), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -51.0), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 158.2623420955225), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 179.59255337595002), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 654 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 12.559914814277036)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 25.35586212156008), ('move_right', -16.5)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 151.84332762192108), ('move_right', 0)]
best: move_right current state : (0, -1.0, -8) -65.6388261835 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 655 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 197.1202187002938)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 197.1202187002938)]
best: nothing current state : (1, 1.5, -18) -26.8583455996 [('nothing', 373.17976781343197), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 244.2229845288743), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 656 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.0082749136546), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.0082749136546), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 334.4684316200646), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.89205769950001)]
Reward: 220
Iteration 657 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.88057975435393)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.88057975435393)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 361.255458948279)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.39274817949843)]
Reward: 278
Iteration 658 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 115.82373798862595), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 115.82373798862595), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 244.45753606356112), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 212.414787363165), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 659 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 234.03286291437357)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 234.03286291437357)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 379.4927328280647), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 152.80395), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 660 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 208.5861413274197), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 208.5861413274197), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 342.39551944389524), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.33276958770836), ('move_right', 0)]
Reward: 215
Iteration 661 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.710643290323)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.710643290323)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 364.56493797818354), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 236.2749237256489)]
Reward: 204
Iteration 662 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.76877416420447), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.76877416420447), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 353.84153958391033), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 202.21201095840001)]
Reward: 204
Iteration 663 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.29443977258512)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.29443977258512)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 356.48609797964525), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 235.456089170212), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 664 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 227.8181118660202), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 227.8181118660202), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 361.67663264557785), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.09525355975356), ('move_right', 0)]
Reward: 215
Iteration 665 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.89175663654527)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.89175663654527)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.1770953368153), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 229.3192624191484), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 666 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.80317617579146), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.80317617579146), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 348.6766944870392), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.83293871139585), ('move_right', 0)]
Reward: 215
Iteration 667 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.3171776484684)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.3171776484684)]
best: nothing current state : (1, 1.5, -18) -15.7875285356 [('nothing', 369.4197454615152), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 245.9803337973089)]
Reward: 226
Iteration 668 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.7050510710079), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.7050510710079), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.22356775434616), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.62444038965)]
Reward: 226
Iteration 669 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.9116894317057)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.9116894317057)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 371.07793370242314), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 226.59244660795423)]
Reward: 204
Iteration 670 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.50042547785148), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.50042547785148), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 88.08658172258734)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.1830570979771), ('move_right', 0)]
Reward: 142
Iteration 671 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -13.60130099353805)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -13.60130099353805)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 86.59868148028929), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 225.02348369340388), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 672 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.31609175311434), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.31609175311434), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 349.32769074019785), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 192.52813996858396), ('move_right', 0)]
Reward: 204
Iteration 673 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.2890707888249)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.2890707888249)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 377.3879219622533), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 203.11643858538272), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 674 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 194.35939085108149), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 194.35939085108149), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 279.8447114534423), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 195.96969797800878), ('move_right', 0)]
Reward: 215
Iteration 675 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.95854554269556)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.95854554269556)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.10647694919214), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.81471262556795)]
Reward: 204
Iteration 676 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 191.04480643363183), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 191.04480643363183), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 170.91552433520428)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 201.67878858460614), ('move_right', 0)]
Reward: 142
Iteration 677 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -12.501486849547742)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', -12.501486849547742)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 270.6723086369994)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 40.71), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 678 Learning Q-Table
best: move_left current state : (-1, -2, -23) -100.0 [('nothing', -0.38537518605001253), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -2, -23) -100.0 [('nothing', -0.38537518605001253), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 209.66140547965077), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 185.4441), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 679 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 43.490471198258504)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 43.490471198258504)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 173.12612214422367), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 206.6815070097679), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 680 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 156.04584120594566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 156.04584120594566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 347.2878255087137), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 183.77515200922429), ('move_right', 0)]
Reward: 204
Iteration 681 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.04274436648666)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.04274436648666)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.0189476521049), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 190.27705490683752), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 682 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 184.45825589861818), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 184.45825589861818), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.3438295449373), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 189.842606406457), ('move_right', 0)]
Reward: 215
Iteration 683 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.77542475401424)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.77542475401424)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.0963798285247), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 197.69393843478628), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 684 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.06374739435603), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.06374739435603), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.4022189198306), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 221.96167232719992)]
Reward: 215
Iteration 685 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.6115306782095)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.6115306782095)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 372.7322875740825), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 171.462765), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 686 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 221.49279692790236), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 221.49279692790236), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 351.39346260339323), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 197.38982448451992), ('move_right', 0)]
Reward: 215
Iteration 687 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.37526582287535)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.37526582287535)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.0756474104032), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.07029883789755)]
Reward: 204
Iteration 688 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.50281603239173), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.50281603239173), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 343.2340234588669), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 202.67287713916394), ('move_right', 0)]
Reward: 204
Iteration 689 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.0251997009758)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.0251997009758)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.4740428386515), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 202.8857569043504), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 690 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.0619976621764), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.0619976621764), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.2700549420414), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.87317062903995)]
Reward: 215
Iteration 691 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.0996720441206)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.0996720441206)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 347.98050482257713), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.74920918652828)]
Reward: 204
Iteration 692 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.65192292203986), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.65192292203986), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 346.065679562956), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 203.07101399741475), ('move_right', 0)]
Reward: 204
Iteration 693 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.79142995356153)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.79142995356153)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 352.11111613176246), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 206.52002983304527), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 694 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.7158693161568), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.7158693161568), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 366.6509896481409), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 203.34970979819033), ('move_right', 0)]
Reward: 215
Iteration 695 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.9148438829258)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.9148438829258)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 353.4337902421473), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 209.0640208831317), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 696 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.12391349165603), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.12391349165603), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 299.6822074108122), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 201.083119860555), ('move_right', 0)]
Reward: 215
Iteration 697 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.59803586659623)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.59803586659623)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 355.1228594344426), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.4244464305698)]
Reward: 215
Iteration 698 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.11890974330686), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.11890974330686), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 350.19237116773127), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 206.84479685873322), ('move_right', 0)]
Reward: 215
Iteration 699 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.48299101285414)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.48299101285414)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.49755705836117), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.84481461819217), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 700 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 238.58076757247628), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 238.58076757247628), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 315.10248114573506), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.29135780111326), ('move_right', 0)]
Reward: 215
Iteration 701 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.62718022834835)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.62718022834835)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 358.5017343263105), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.09711250139884)]
Reward: 215
Iteration 702 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.577101046296), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.577101046296), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 199.42735355985), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 158.02769999999998)]
Reward: 215
Iteration 703 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.1293658595791)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.1293658595791)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 357.35143080185776), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.09137023273453), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 704 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 71.24403555689648), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 71.24403555689648), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 244.84930120258008), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 175.11938999999998)]
Reward: 215
Iteration 705 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.32349341816666)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.32349341816666)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 356.41333553328076), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.26797875097918)]
Reward: 204
Iteration 706 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 193.6719962022043), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 193.6719962022043), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 353.3526809962572), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 202.74840767088)]
Reward: 204
Iteration 707 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.77795412860488)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.77795412860488)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 358.1697284985903), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.78758512568544)]
Reward: 204
Iteration 708 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 209.40370971632413), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 209.40370971632413), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 348.16727989329365), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.0039504607793), ('move_right', 0)]
Reward: 204
Iteration 709 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.2229945155045)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.9808371621914)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 359.280347778837), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.96395916291416), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 710 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 94.36543465244365), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 94.36543465244365), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 328.3591441423485), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 181.561455), ('move_right', 0)]
Reward: 204
Iteration 711 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 225.15034730951055)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 225.15034730951055)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 358.65508548671886), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.27477141403992), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 712 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 222.07260017125708), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 222.07260017125708), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 329.319837399644), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.90276532254552), ('move_right', 0)]
Reward: 215
Iteration 713 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.029276838577)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.029276838577)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.1409912649152), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.69233998982793), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 714 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.28659074161524), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.28659074161524), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.18809887503187), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.73193572578185), ('move_right', 0)]
Reward: 215
Iteration 715 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 279.99819842308904)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 279.99819842308904)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 363.39664571764484)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.68463799287954), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 716 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 125.4536968129486), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 125.4536968129486), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 353.17139899864407), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 240.0095702524155), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 717 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 53.420985883890154)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 53.420985883890154)]
best: move_left current state : (0, -1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 143.73495)]
Reward: 142
Iteration 718 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.39686258348235), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.39686258348235), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.66060569315573), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.41121944032795)]
Reward: 226
Iteration 719 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.69029924238245)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.69029924238245)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 358.7734126311208), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 202.755271395), ('move_right', 0)]
Reward: 215
Iteration 720 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.70349359228834), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.70349359228834), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.75124993025685), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.0123550080473), ('move_right', 0)]
Reward: 215
Iteration 721 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.54274133490793)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.54274133490793)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.3854311940602), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 232.27924659501568), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 722 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.957639895521), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.957639895521), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.929581453594), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.3666774918275), ('move_right', 0)]
Reward: 215
Iteration 723 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.9353676944957)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.9353676944957)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.95357581434683), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 227.09547261651096), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 724 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.289041764785), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.289041764785), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.16071026506404), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.55667424427924), ('move_right', 0)]
Reward: 215
Iteration 725 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.38064953229315)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.38064953229315)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 369.9961448549961), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 223.46683083155767), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 726 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.99036171671082), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.99036171671082), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 338.19471577651444), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.90864850563312), ('move_right', 0)]
Reward: 215
Iteration 727 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 276.0575520132979)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 276.0575520132979)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 363.18304340021524)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 239.98623365811622)]
Reward: 289
Iteration 728 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 161.5965155445612), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 161.5965155445612), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 364.2228503747755), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 235.3903511542155), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 729 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 8.43450952056521)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 8.43450952056521)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 228.19273760388694), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 143.214465)]
Reward: 142
Iteration 730 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.29148733649401), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.29148733649401), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 345.60889559525003), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.68785360822957)]
Reward: 216
Iteration 731 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.8051175309461)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.8051175309461)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.03735064796456), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 220.92678158209037), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 732 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.92652921596292), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.92652921596292), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.3857898173074), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.95519917507), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 733 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.9146068678938)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.9146068678938)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.0041799282023), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.14874710746327), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 734 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.09181547227024), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.09181547227024), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.85661262463617), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.5360539539432), ('move_right', 0)]
Reward: 215
Iteration 735 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.78129818782844)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.78129818782844)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.4475500819806), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 217.90412297522428), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 736 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.74876269388398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.74876269388398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.7794994588286), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.97523776776023), ('move_right', 0)]
Reward: 215
Iteration 737 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.6209931579162)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.6209931579162)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.906395882389), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.0513095879798)]
Reward: 215
Iteration 738 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.89780312520946), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.89780312520946), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.7382209515081), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.28266643743217), ('move_right', 0)]
Reward: 215
Iteration 739 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.534122051162)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.534122051162)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 369.6845219499537), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.032886082657), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 740 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.3897478749412), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.3897478749412), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.1325829991439), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.4978665062025), ('move_right', 0)]
Reward: 215
Iteration 741 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.1190614226416)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.1190614226416)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.34986999406624), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.4230202578599), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 742 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.5524178140441), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.5524178140441), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.4604450234283), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.2814975257607)]
Reward: 215
Iteration 743 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.61581206997295)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.61581206997295)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.8890311897647), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.99611418050193), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 744 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.1523340527633), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.1523340527633), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.90676077412803), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.68967197099548), ('move_right', 0)]
Reward: 215
Iteration 745 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.5375972077526)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.5375972077526)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.02115608698585), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.69727992635134), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 746 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3061701450767), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3061701450767), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.54216805126146), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 217.9970482680325)]
Reward: 215
Iteration 747 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.3224842733647)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.3224842733647)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.32399323879554), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.48809594844593), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 748 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.81678891877425), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.81678891877425), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.9786321162928), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 188.2930185), ('move_right', 0)]
Reward: 215
Iteration 749 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.36275636483606)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.36275636483606)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.77322405169065), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.34166716391215), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 750 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 132.39105557531906), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 132.39105557531906), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 268.93032784180605), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 187.083573)]
Reward: 215
Iteration 751 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.92571607273453)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.92571607273453)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 356.9679702602846), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 215.2391670147385), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 752 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.2051612798719), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.2051612798719), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.47294803140494), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.64850655434176), ('move_right', 0)]
Reward: 215
Iteration 753 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.16590040490354)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.16590040490354)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.3437569853571), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.16741691031694), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 754 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.22531670717393), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.22531670717393), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.825615588286), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.75395458803922), ('move_right', 0)]
Reward: 215
Iteration 755 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.1590767808817)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.1590767808817)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 361.4718150732043), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.13591671158585)]
Reward: 204
Iteration 756 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.54522577334967), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.54522577334967), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.01828106353935), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.123885369616)]
Reward: 204
Iteration 757 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.8804063444825)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.8804063444825)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.99085496284505), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.11719183722187), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 758 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 144.39265665710724), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 144.39265665710724), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 232.007457491895), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 196.30511295), ('move_right', 0)]
Reward: 215
Iteration 759 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.15336033183337)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.15336033183337)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.7287560251581), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.08203428605532), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 760 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3269617622487), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3269617622487), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.5015545972853), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.82776821162744), ('move_right', 0)]
Reward: 215
Iteration 761 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.6657984416729)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.6657984416729)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.53473950342726), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.0574240002387), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 762 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.6191590146018), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.6191590146018), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.54163413318827), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 217.09793378762276)]
Reward: 215
Iteration 763 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.6663001620413)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.6663001620413)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 361.07104556471876), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.2951416981101)]
Reward: 204
Iteration 764 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.9234096260817), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.9234096260817), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 370.5731006086075), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.3867197587312)]
Reward: 204
Iteration 765 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.8152318587485)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.8152318587485)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.3915448524707), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.00659918867706)]
Reward: 204
Iteration 766 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.9458249967434), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.9458249967434), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.3499623553623), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.8794377481392), ('move_right', 0)]
Reward: 204
Iteration 767 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.6279451587073)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.6279451587073)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.8760611533326), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.0401968001671), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 768 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.40688560617116), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.40688560617116), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.19941868158793), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 216.46855365133592)]
Reward: 215
Iteration 769 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.142199358937)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.142199358937)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.52530184738293), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.02813776011698), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 770 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5844649306383), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5844649306383), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 366.00852402951864), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 216.02798755593514)]
Reward: 215
Iteration 771 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.69694950731287)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.69694950731287)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.97615262120314), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.01969643208187), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 772 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.7391907362064), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.7391907362064), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.18015917251233), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.61560642369744), ('move_right', 0)]
Reward: 215
Iteration 773 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.2205298433221)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.2205298433221)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.23827440473616), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.01378750245732), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 774 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 141.71691630938565), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 141.71691630938565), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 359.20411728821193), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 195.4585011)]
Reward: 215
Iteration 775 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.2533612876503)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.2533612876503)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 361.6709283340525), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.10461943207395)]
Reward: 204
Iteration 776 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.8113006689403), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.8113006689403), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.1088049731954), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.63092449658822), ('move_right', 0)]
Reward: 204
Iteration 777 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.90613947747494)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.90613947747494)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.00103566345894), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.00965125172013), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 778 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.84037136205893), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.84037136205893), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.41079334786787), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.7195912891546)]
Reward: 215
Iteration 779 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.7621164091741)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.7621164091741)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.28921576446675), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.0067558762041), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 780 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.3513173596437), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.3513173596437), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 355.08043243174836), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.04164714761174), ('move_right', 0)]
Reward: 215
Iteration 781 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.760065617604)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.760065617604)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.504477797988), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.00472911334288), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 782 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.69755995717907), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.69755995717907), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.10343273025387), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 217.33710827275502)]
Reward: 226
Iteration 783 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.9232086735613)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.9232086735613)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.65455319259445), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.30331037934002), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 784 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.3591411909436), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.3591411909436), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.5687968465074), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.52915300332822), ('move_right', 0)]
Reward: 215
Iteration 785 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.48243143111335)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.48243143111335)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.7491803486181), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.312317265538), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 786 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.9618572894548), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.9618572894548), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.05690369355364), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.57040710232974), ('move_right', 0)]
Reward: 215
Iteration 787 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.9022755082069)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.9022755082069)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.2181214236941), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.6186220858766), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 788 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.1301906125266), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.1301906125266), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 365.0735353930042), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.78277037969684), ('move_right', 0)]
Reward: 215
Iteration 789 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.03684868469514)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.03684868469514)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 361.5036203399373), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.13303546011363), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 790 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.35301344851194), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.35301344851194), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.41095471618644), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.2992849716308), ('move_right', 0)]
Reward: 215
Iteration 791 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.2043882571718)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.2043882571718)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.3382716223488), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.47323360245176)]
Reward: 204
Iteration 792 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.2102152306564), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.2102152306564), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 366.0143630874436), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.8479392657878), ('move_right', 0)]
Reward: 204
Iteration 793 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.184372668567)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.184372668567)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.0787602163797), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.79312482207953), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 794 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.87896766359654), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.87896766359654), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.57745379281977), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.80949948014157), ('move_right', 0)]
Reward: 215
Iteration 795 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.59250833475295)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.59250833475295)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.89306959808965), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.55518737545566), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 796 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.5283329042056), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.5283329042056), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.5470674990163), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.1666496360991), ('move_right', 0)]
Reward: 215
Iteration 797 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.12249611559605)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.12249611559605)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.39170493129944), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.03126352171623)]
Reward: 215
Iteration 798 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.27377268449095), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.27377268449095), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 365.4171863536446), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.41665474526937), ('move_right', 0)]
Reward: 215
Iteration 799 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.64307816214915)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.64307816214915)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.5835725084245), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.38863116281897), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 800 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.744304861141), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.744304861141), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.986305889012), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 211.59355748605145), ('move_right', 0)]
Reward: 215
Iteration 801 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.16504586787386)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.16504586787386)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.72509010474283), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.2720418139733), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 802 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.7567245713444), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.7567245713444), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.96848136812383), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.59165832168856), ('move_right', 0)]
Reward: 215
Iteration 803 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.17287854077665)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.17287854077665)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 371.22400047758555)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.1904292697813), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 804 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 190.21192406952946), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 190.21192406952946), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.33294214014114), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 229.27324580795084), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 805 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.72803452366145)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.72803452366145)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.48917561751193), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.02188446520137)]
Reward: 215
Iteration 806 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.8600710122204), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.8600710122204), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 367.41503324048404), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.71416082518198), ('move_right', 0)]
Reward: 215
Iteration 807 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.1961962536587)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.1961962536587)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 361.84898827181877), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 234.03330048884692), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 808 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 266.6663790825416), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 266.6663790825416), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 365.117026871132), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.7999125776274), ('move_right', 0)]
Reward: 204
Iteration 809 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.1195419350107)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.1195419350107)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 359.44932928662075), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.11531912564095)]
Reward: 204
Iteration 810 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.0290814950227), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.0290814950227), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 365.0218925830806), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.57070383111184)]
Reward: 204
Iteration 811 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.5459862163977)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.5459862163977)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.5042819369272), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 225.02331034219284), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 812 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.154432897344), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.154432897344), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 366.6047715158934), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.50371390240824)]
Reward: 215
Iteration 813 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.97329433439864)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.97329433439864)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 362.89244487599024), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.016317239535), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 814 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.52935388475095), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.52935388475095), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 364.15543445419326), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 212.61549024023603), ('move_right', 0)]
Reward: 215
Iteration 815 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4765475727801)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4765475727801)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.4599904585069), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 206.42868997649998), ('move_right', 0)]
Reward: 204
Iteration 816 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.2446861314876), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.2446861314876), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.6644359409469), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.55993880433917), ('move_right', 0)]
Reward: 204
Iteration 817 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.2113998403402)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.2113998403402)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.25060031390484), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.9114220676745), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 818 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.0981191502293), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.0981191502293), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 366.2744542318478), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.2919571630374), ('move_right', 0)]
Reward: 215
Iteration 819 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.5629793842517)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.5629793842517)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 369.4139291152443)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.102236)]
Reward: 300
Iteration 820 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 212.88804889255508), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 212.88804889255508), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.17970511120467), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 247.19127206556558), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 821 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.6820057428728)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.6820057428728)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 359.6491262383268), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.43799544737215), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 822 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.690839076557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 263.690839076557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.6934511900061), ('move_right', 0)]
best: nothing current state : (2, 4, -7) 150 [('nothing', 143.526), ('move_right', 0)]
Reward: 215
Iteration 823 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.8996499674129)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.8996499674129)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.3488468400357), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.28072338794865)]
Reward: 215
Iteration 824 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 174.7905846789375), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 174.7905846789375), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.43308679996454), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.00437001412618), ('move_right', 0)]
Reward: 215
Iteration 825 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.37422843104184)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.37422843104184)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 366.920421180671)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 254.69036356068136)]
Reward: 289
Iteration 826 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 229.31536515999207), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 229.31536515999207), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 180.01118321898718), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 259.7338904458959), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 827 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.0655943318346)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.0655943318346)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.6284098044096), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.4065968131605), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 828 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.7314421124338), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 264.7314421124338), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 361.58653595748996), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.20305900988834), ('move_right', 0)]
Reward: 215
Iteration 829 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.9742583754492)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.9742583754492)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.46186590703485), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.68461776921234), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 830 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.6154783418546), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.6154783418546), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 342.64321583300426), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 205.2581839023885), ('move_right', 0)]
Reward: 226
Iteration 831 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.860360036767)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.860360036767)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.8286914656881), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.47923243844863), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 832 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.9636189910416), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.9636189910416), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 346.42770625381957), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.35259973168576)]
Reward: 215
Iteration 833 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.5906788672855)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.5906788672855)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.92385375751627), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.13546270691404), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 834 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.84266457171708), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.84266457171708), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 374.08317519751296), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.04214130692185), ('move_right', 0)]
Reward: 215
Iteration 835 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.4304507361968)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.4304507361968)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.2873364423356), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.19482389483983), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 836 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.65463716129796), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.65463716129796), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.40447176421304), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.24681981218004)]
Reward: 215
Iteration 837 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.1273358498805)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.1273358498805)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 179.1461295), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 184.5239355), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 838 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 45.40179734740384)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 45.40179734740384)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 246.68361604589958)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.53637672638789), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 839 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -17.181477969501145), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -17.181477969501145), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 193.437819808516)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 158.412), ('move_right', 0)]
Reward: 152
Iteration 840 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 182.35161865359458), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 182.35161865359458), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 144.60603853851126), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 265.2137233121271), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 841 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 76.82616235879466)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 76.82616235879466)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 282.63944425004604)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 238.27546370847153), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 842 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 17.044130765746104), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 17.044130765746104), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0.7998077980773068)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 250.149606318489), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 843 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 142.06776402091168), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 142.06776402091168), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 289.37630138926426), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 156.4884), ('move_right', 0)]
Reward: 215
Iteration 844 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 109.60996632801218)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 109.60996632801218)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 314.3302500875737)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 845 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -20.00165804865056), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', -20.00165804865056), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -0.5, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 227.93007386596122)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 846 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 154.08783330732143), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 154.08783330732143), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -17) -15.7875285356 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 220.7047244229423), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 847 Learning Q-Table
best: nothing current state : (0, 1.5, -23) -100.0 [('nothing', 0), ('move_left', -25.736258560676706), ('move_right', -4.736258560676707)]
best: nothing current state : (0, 1.5, -23) -100.0 [('nothing', 0), ('move_left', -25.736258560676706), ('move_right', -4.736258560676707)]
best: move_left current state : (0, 1.25, -17) -100.0 [('nothing', 0), ('move_left', 17.136461786951994), ('move_right', 0)]
best: move_left current state : (0, 0.5, -5) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -100
Iteration 848 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 213.17279334675848)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 213.17279334675848)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 378.2514038946741)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 253.49282459593007), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 849 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 30.070173120446654), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 30.070173120446654), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 370.77086503033564), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 216.51086999999998), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 850 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.96011795045646)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.96011795045646)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 362.2857870010404), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 267.44497721715106), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 851 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.00709561807645), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.00709561807645), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 361.77149287320947), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.6294989148453), ('move_right', 0)]
Reward: 226
Iteration 852 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.3853267415356)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.3853267415356)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 365.6296065850537), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 251.71148405200574), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 853 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5762341964585), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5762341964585), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 362.3288946857002), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 217.3406492403917), ('move_right', 0)]
Reward: 215
Iteration 854 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.186118770495)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.186118770495)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 376.45416982513933), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 240.698038836404), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 855 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.62954041913497), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.62954041913497), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.1051742971794), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 216.6384544682742), ('move_right', 0)]
Reward: 215
Iteration 856 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.60299587384029)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.60299587384029)]
best: nothing current state : (1, 1.5, -18) -15.7875285356 [('nothing', 367.2595826780869), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 232.9886271854828), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 857 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.4120499843904), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.4120499843904), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.4651583485078), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.93597579092852)]
Reward: 226
Iteration 858 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.86371335443755)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.86371335443755)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.97829603030567), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.89203902983797), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 859 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8678018954678), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8678018954678), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.50640358123405), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 216.14691812779193), ('move_right', 0)]
Reward: 215
Iteration 860 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.5379075590401)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.5379075590401)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 374.65241893016537), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 226.12442732088658), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 861 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 199.5108433911496), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 199.5108433911496), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 362.1985579452014), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 114.99), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 862 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 273.2350188312152)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 273.2350188312152)]
best: move_right current state : (1, 1.25, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 159.10826437649888)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 264.98325449247693)]
Reward: 289
Iteration 863 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 95.62522475444828), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 95.62522475444828), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 225.78834397059603), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 222.2933070960596), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 864 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 138.85355953178458)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 138.85355953178458)]
best: move_right current state : (0, -1.0, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 272.18827814473383)]
Reward: 300
Iteration 865 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -8.093765939992927)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -8.093765939992927)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 247.39621383575553), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 220.10531496724172), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 866 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 71.4612331115725)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 71.4612331115725)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 284.2089441752014), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.29650637156405)]
Reward: 142
Iteration 867 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3992018030398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3992018030398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 102.63461663999999), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 211.48072873167195), ('move_right', 0)]
Reward: 226
Iteration 868 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.6120803722198)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.6120803722198)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 385.8238301050509)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 226.0870991246206), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 869 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 105.71397992113472), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 100.10788876931731), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 369.49286652123493), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 229.20669917669085), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 870 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 213.2607339341236)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 213.2607339341236)]
best: move_right current state : (1, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 235.87076141129228)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 244.96096938723443), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 871 Learning Q-Table
best: move_right current state : (0, -1.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -2, -19) -47.8784607102 [('nothing', 0), ('move_left', 12.985062139629456), ('move_right', 0)]
best: move_left current state : (-1, -1.5, -8) -13.9975690372 [('nothing', 0), ('move_left', 32.1), ('move_right', 0)]
Reward: -100
Iteration 872 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', -24.432449915963254), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', -24.432449915963254), ('move_right', -49.9601805981579)]
best: nothing current state : (0, 0.75, -17) -15.7875285356 [('nothing', 294.509930972485), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 2, -5) 150 [('nothing', 0), ('move_left', 83.39999999999999), ('move_right', 0)]
Reward: 226
Iteration 873 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 55.34192117351048), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 55.34192117351048), ('move_right', -16.5)]
best: move_left current state : (1, 2, -18) -58.3854585078 [('nothing', 0), ('move_left', 102.9372), ('move_right', 0)]
best: nothing current state : (2, 2, -6) 100 [('nothing', 32.1), ('move_right', 0)]
Reward: 121
Iteration 874 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.8154246939112)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 191.08356157911632)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 375.09402144738175), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 280.5317947013137)]
Reward: 215
Iteration 875 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 177.70628804107983), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 177.70628804107983), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2, -16) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -6) 150 [('nothing', 62.699999999999996), ('move_right', 0)]
Reward: 163
Iteration 876 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 31.104867269120657), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 31.104867269120657), ('move_right', -16.5)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 89.37264687946752), ('move_right', -11.172491924096027)]
best: nothing current state : (2, 2, -8) 100 [('nothing', 91.69200000000001), ('move_right', 0)]
Reward: 107
Iteration 877 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 235.11420761549994)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 235.11420761549994)]
best: move_right current state : (1, 1.0, -17) -15.7875285356 [('nothing', -14.363538213047999), ('move_left', 0), ('move_right', 45.0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 260.8722562909196)]
Reward: 300
Iteration 878 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 74.03215257558949), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 74.03215257558949), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 372.4070163178717), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 240.77372047706922), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 879 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 219.69586575947275)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 219.69586575947275)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 391.72535342356133), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 237.7715652)]
Reward: 215
Iteration 880 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 98.65814306807917), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 216.1446658332691), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -15.7875285356 [('nothing', 266.2967541293265), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.83651011217037), ('move_right', 0)]
Reward: 215
Iteration 881 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.34453146054142)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.34453146054142)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 380.72733052851873), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 882 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 103.90409989763614), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 103.90409989763614), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.95717617860316), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.17277386852604)]
Reward: 226
Iteration 883 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 152.34368677017324)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 152.34368677017324)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 382.90281081092184)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 254.8726785710641), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 884 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 172.9632014967347), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 172.9632014967347), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.25, -17) -15.7875285356 [('nothing', 0), ('move_left', 76.5), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 234.957609), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 885 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.68687925683858)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.68687925683858)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 389.4937711389645)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 261.8108749997449), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 886 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 131.37211977417815), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 131.37211977417815), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 377.917027565631), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 251.94160433394845), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 887 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.29268826079965)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.29268826079965)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 311.50913136996314), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 142.8501255)]
Reward: 215
Iteration 888 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 149.7475308578302), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 149.7475308578302), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 333.035990561641), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.4209417079682)]
Reward: 226
Iteration 889 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 192.5512433842399)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 192.5512433842399)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 396.18890229719864)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 273.26761249982144), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 890 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 118.2879824870376), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 118.2879824870376), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 276.1769516807395), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 251.1703263), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 891 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 106.32536583250328)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 106.32536583250328)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 247.69925582272086), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 205.70008298354998), ('move_right', 0)]
Reward: 120
Iteration 892 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 175.77388817081555), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 175.77388817081555), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.0654408302132), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 215.80284268945437), ('move_right', 0)]
Reward: 194
Iteration 893 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.38512926945268)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.38512926945268)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 390.5392169564929), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.80755446009482)]
Reward: 215
Iteration 894 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 201.50117337047695), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 201.50117337047695), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.32185548558004), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.26198988261805), ('move_right', 0)]
Reward: 215
Iteration 895 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.0711749774068)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.0711749774068)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 378.8335440658736), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 179.99005808848497), ('move_right', 0)]
Reward: 204
Iteration 896 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.17488608091185), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.17488608091185), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 225.14450361002483)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.98339291783265), ('move_right', 0)]
Reward: 131
Iteration 897 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 119.77735223141065)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 119.77735223141065)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 280.0995039709696), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 164.49508785)]
Reward: 142
Iteration 898 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 226.45403376140962), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 226.45403376140962), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 313.67496406651765), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 201.913579065), ('move_right', 0)]
Reward: 215
Iteration 899 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.92739377985083)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.92739377985083)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 375.3197182075735), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.36528812206637)]
Reward: 204
Iteration 900 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 191.30559074148783), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 191.30559074148783), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.38666138798555), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 205.8395053455), ('move_right', 0)]
Reward: 204
Iteration 901 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.08491051000976)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.08491051000976)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.93338918192137), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 277.987328749875), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 902 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.06973133727925), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.06973133727925), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 343.65147590553914), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 186.98837504248286), ('move_right', 0)]
Reward: 215
Iteration 903 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.47927351342537)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.47927351342537)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 385.2495710523075), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 259.0911301249125), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 904 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.28407410959932), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.28407410959932), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 341.65254564662223), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 195.391862529738), ('move_right', 0)]
Reward: 215
Iteration 905 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 275.2501821769321)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 275.2501821769321)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 392.402038774089), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 245.86379108743876), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 906 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.62212364661016), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.62212364661016), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.8038958046915), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.668639422549), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 907 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 281.4355585579213)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 281.4355585579213)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 364.180498272657), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 204
Iteration 908 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.30416336993852), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.30416336993852), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.66331889004874), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.69949268177828)]
Reward: 204
Iteration 909 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.086548548246)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.086548548246)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 404.3125153579855)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 236.60465376120712), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 910 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 176.3754115134561), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 176.3754115134561), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 269.7398329082351), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 263.0591230337639), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 911 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 138.91381715512043)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 138.91381715512043)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 290.4181791346787), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 157.746561495)]
best: nothing current state : (0, -3, 3) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 170
Iteration 912 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 175.4245573337319), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 175.4245573337319), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 312.73561994589375), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 248.64138612363473), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 913 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 16.41270922812869), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 16.41270922812869), ('move_right', -16.5)]
best: move_left current state : (1, 2, -18) -37.241639747 [('nothing', 0), ('move_left', 111.68604), ('move_right', 0)]
best: move_right current state : (2, 2.0, -7) 100 [('nothing', 0), ('move_right', 53.459999999999994)]
Reward: 107
Iteration 914 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 284.19415799301)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 284.19415799301)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 393.44056446809395), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 252.32325763284499), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 915 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.63941810187555), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.63941810187555), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 2.0, -17) -15.7875285356 [('nothing', 176.04493649999998), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 201.32095077)]
Reward: 215
Iteration 916 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 288.0078993373773)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 288.0078993373773)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 399.000156878952)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 155.4225930465)]
Reward: 289
Iteration 917 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 34.10334636368902)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 34.10334636368902)]
best: move_left current state : (-1, -0.25, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -1.5, -9) 100 [('nothing', 0), ('move_left', 25.8)]
Reward: -50
Iteration 918 Learning Q-Table
best: move_right current state : (-1, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -0.5, -7) -21.6402882518 [('nothing', 0), ('move_left', 0)]
Reward: -300
Iteration 919 Learning Q-Table
best: move_left current state : (-1, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -28.960180598157905)]
best: nothing current state : (-1, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -28.960180598157905)]
best: move_left current state : (0, 2.0, -19) -26.2205848916 [('nothing', 0), ('move_left', 135.632973205521), ('move_right', -27.759)]
best: nothing current state : (0, 2, -9) 100 [('nothing', 247.1446894236836), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 920 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 23.617245753538363)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 23.617245753538363)]
best: move_left current state : (0, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 96.960852), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 199.35570168544646)]
Reward: 142
Iteration 921 Learning Q-Table
best: nothing current state : (0, 2, -24) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -11.491195758465691)]
best: nothing current state : (0, 2, -24) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -11.491195758465691)]
best: move_left current state : (0, 2, -19) -100.0 [('nothing', 0), ('move_left', 199.08648807096978), ('move_right', -27.759)]
best: move_right current state : (0, 1.25, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 922 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 13.447835703380829)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 13.447835703380829)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 105.781703355), ('move_left', -11.172491924096027), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 187.19304066193948), ('move_right', 0)]
Reward: 215
Iteration 923 Learning Q-Table
best: nothing current state : (-1, 0.0, -24) -100.0 [('nothing', 32.82371649416755), ('move_left', -30.0), ('move_right', -28.960180598157905)]
best: nothing current state : (-1, 0.0, -24) -100.0 [('nothing', 32.82371649416755), ('move_left', -30.0), ('move_right', -28.960180598157905)]
best: move_left current state : (-1, 0.25, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, 0.5, -8) -100.0 [('nothing', 35.4), ('move_left', 0), ('move_right', 0)]
Reward: 73
Iteration 924 Learning Q-Table
best: nothing current state : (0, 2, -24) -100.0 [('nothing', 8.725946421290935), ('move_left', -30.0), ('move_right', -11.491195758465691)]
best: nothing current state : (0, 2, -24) -100.0 [('nothing', 8.725946421290935), ('move_left', -30.0), ('move_right', -11.491195758465691)]
best: move_left current state : (0, 2, -19) -100.0 [('nothing', 0), ('move_left', 109.36054164967885), ('move_right', -27.759)]
best: move_right current state : (0, 1.5, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 54.3)]
Reward: -50
Iteration 925 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 12.187815400708686)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 12.187815400708686)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 175.20510454708185), ('move_left', -11.172491924096027), ('move_right', 0)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 90.0)]
Reward: 204
Iteration 926 Learning Q-Table
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 342.77434071155693), ('move_right', 0)]
best: move_right current state : (0, 1.0, -7) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 0)]
Reward: -50
Iteration 927 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', -11.491195758465691)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', -11.491195758465691)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 248.9279953870598), ('move_right', -30.0)]
best: move_left current state : (-2, -2.0, -9) 150 [('nothing', 0), ('move_left', 94.10999999999999)]
Reward: 113
Iteration 928 Learning Q-Table
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 51.832302213467074), ('move_left', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 51.832302213467074), ('move_left', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 0.75, -19) -100.0 [('nothing', 363.8324210521077), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.5, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Loading mission from ghast_survival_mission.xml
Iteration 930 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.22481506063616), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.22481506063616), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 209.94203849808986), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 201.2743037708166), ('move_right', 0)]
Reward: 209
Iteration 931 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 224.68236045996963)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 224.68236045996963)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 396.1053724175193), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 241.1262803429915), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 932 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 171.37980149371438), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 171.37980149371438), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 252.34171807990788), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 213.33084316816522), ('move_right', 0)]
Reward: 215
Iteration 933 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 247.1490834490766)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 247.1490834490766)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 370.9268877292164)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 272.6105794036437)]
Reward: 289
Iteration 934 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 187.65769551922256), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 187.65769551922256), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 265.0311750613016)]
best: move_right current state : (0, 1.5, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 54.0)]
Reward: 152
Iteration 935 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 166.70819587141452), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 166.70819587141452), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 285.6384556063851), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 203.59201263957164), ('move_right', 0)]
Reward: 215
Iteration 936 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 295.56931803917297)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 295.56931803917297)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 394.61164479516094), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 233.28839624009404), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 937 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 173.4270931937478), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 173.4270931937478), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 306.02452271634104), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.01440884770014), ('move_right', 0)]
Reward: 215
Iteration 938 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 255.32224413496064)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 255.32224413496064)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 391.21467022864084), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 277.5274055825506)]
Reward: 215
Iteration 939 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 184.24614145236788), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 184.24614145236788), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 2.0, -17) -15.7875285356 [('nothing', 228.62774078099997), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 205.28765374185), ('move_right', 0)]
Reward: 215
Iteration 940 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 296.32183546781147)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 296.32183546781147)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 402.1084908348138), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 258.7691839077854)]
Reward: 226
Iteration 941 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 171.8243626902808), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 171.8243626902808), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 385.12440059612624), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.58555707851926), ('move_right', 0)]
Reward: 226
Iteration 942 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 267.1297913649068)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 267.1297913649068)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 404.10669875670527), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 227.80187736806585), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 943 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.85419346387653), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.85419346387653), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 379.26274754084415), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.4100861933901), ('move_right', 0)]
Reward: 215
Iteration 944 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 279.26268298428846)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 279.26268298428846)]
best: nothing current state : (1, 0.75, -16) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -3) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 945 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 229.61657908880892), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 229.61657908880892), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 224.68269473647538), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.08706033537308), ('move_right', 0)]
Reward: 215
Iteration 946 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 299.0976514797543)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 299.0976514797543)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 305.9114296089742), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 223.9613141576461), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 947 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 195.96392185901283), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 195.96392185901283), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 321.3214885557488), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.26094223476116), ('move_right', 0)]
Reward: 215
Iteration 948 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.9692929944242)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.9692929944242)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 396.21525234011347), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.27291991035227), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 949 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.61101126987572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.61101126987572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 373.30694913660795), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.0826595643328), ('move_right', 0)]
Reward: 215
Iteration 950 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 278.1829001999731)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 278.1829001999731)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 388.7325526111851), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.3910439372466), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 951 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.04730070579936), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.04730070579936), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 333.6033246594525), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.69465919557774)]
Reward: 215
Iteration 952 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 163.3113861649059)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 163.3113861649059)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 382.9301000090035), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 248.9384287354498)]
Reward: 215
Iteration 953 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 227.2539272937374), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 227.2539272937374), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 370.2396622649254), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.65786169503295), ('move_right', 0)]
Reward: 215
Iteration 954 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 197.02450839403917)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 197.02450839403917)]
best: move_right current state : (1, 1.25, -17) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 283.5978238040749)]
best: move_right current state : (0, -2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 90.0)]
Reward: 300
Iteration 955 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 181.90955878368837), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 181.90955878368837), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 247.48259677094185), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 238.54897028654432), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 956 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 282.38761532517884)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 282.38761532517884)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 387.73259862693743), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 195.49581513255)]
Reward: 215
Iteration 957 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 223.66013225478414), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 223.66013225478414), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 296.15868092417963), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 221.75518305364997)]
Reward: 215
Iteration 958 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 285.03092971754853)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 285.03092971754853)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 375.0615635786212), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.347070592785)]
Reward: 215
Iteration 959 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 216.44951625744488), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 216.44951625744488), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 325.14654856606234), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -7) 150 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 226
Iteration 960 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 283.0799392777124)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 283.0799392777124)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 367.94721568287036), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 218.07373075607262), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 961 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.18946718693593), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.18946718693593), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 2.0, -17) -15.7875285356 [('nothing', 266.625714669255), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 208.20135761929498), ('move_right', 0)]
Reward: 215
Iteration 962 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 276.3676302751638)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 276.3676302751638)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.98517020483104), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.15161152925083), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 963 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.08408287095494), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.08408287095494), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 368.26512209395764), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.06050318652308), ('move_right', 0)]
Reward: 215
Iteration 964 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 187.6329648040019)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 187.6329648040019)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 386.4319952315446)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 230.94009564)]
Reward: 289
Iteration 965 Learning Q-Table
best: move_right current state : (0, 1.25, -25) -100.0 [('nothing', -56.15097886163271), ('move_left', -52.44461834280656), ('move_right', -51.480924945025116)]
best: move_right current state : (0, 1.25, -25) -100.0 [('nothing', -56.15097886163271), ('move_left', -52.44461834280656), ('move_right', -51.480924945025116)]
best: nothing current state : (-1, -0.75, -19) -26.5339353272 [('nothing', 30.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-2, -1.75, -9) 100 [('nothing', 0), ('move_left', 0)]
Reward: 135
Iteration 966 Learning Q-Table
best: nothing current state : (-2, -1.0, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -1.0, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -0.75, -20) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -0.5, -10) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -50
Iteration 967 Learning Q-Table
best: move_left current state : (-2, -1.0, -25) -100.0 [('nothing', -51.0), ('move_left', 0)]
best: move_left current state : (-2, -1.0, -25) -100.0 [('nothing', -51.0), ('move_left', 0)]
best: nothing current state : (-1, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', -19.38), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 227.30128259657852), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 968 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -11.200511623754089)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', -11.200511623754089)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 360.6741710275676), ('move_right', 0)]
best: move_left current state : (-2, -2, -9) 150 [('nothing', 0), ('move_left', 99.77699999999999)]
best: move_left current state : (-1, -2, 4) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 34
Iteration 969 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 37.67438098703407)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 37.67438098703407)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 327.4050197192973), ('move_right', 0)]
best: move_right current state : (-1, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 75.42)]
Reward: 120
Iteration 970 Learning Q-Table
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', -18.67249192409603), ('move_right', -30.0)]
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', -18.67249192409603), ('move_right', -30.0)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 62.8423791547752), ('move_right', -27.759)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 223.61089781760495), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 971 Learning Q-Table
best: nothing current state : (2, 5, -24) -100.0 [('nothing', 15.69541940184211), ('move_right', -30.0)]
best: nothing current state : (2, 5, -24) -100.0 [('nothing', 15.69541940184211), ('move_right', -30.0)]
best: move_right current state : (2, 4, -19) -100.0 [('nothing', -7.609925074841735), ('move_right', 0)]
best: move_right current state : (2, 2, -9) -100.0 [('nothing', 0), ('move_right', 62.91)]
Reward: -300
Iteration 972 Learning Q-Table
best: nothing current state : (1, 4, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -18.309326113902628)]
best: nothing current state : (1, 4, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -18.309326113902628)]
best: move_left current state : (1, 3, -19) -99.6651693285 [('nothing', -7.8302300142270616), ('move_left', 85.1964), ('move_right', 0)]
best: nothing current state : (1, 1.75, -9) -99.6651693285 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 73
Iteration 973 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.89271165590606)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.89271165590606)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 225.7594713), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.50612807047557), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 974 Learning Q-Table
best: move_left current state : (0, 2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -16) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 1.25, -4) -65.6388261835 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 975 Learning Q-Table
best: nothing current state : (0, 1.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.5, -23) -100.0 [('nothing', -45.8590614639144), ('move_left', -25.736258560676706), ('move_right', -4.736258560676707)]
best: nothing current state : (0, 0.0, -16) -99.7101856697 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.5, -6) -36.9518254167 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 97
Iteration 976 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 3.875747654934763), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 3.875747654934763), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.75, -18) -100.0 [('nothing', 0), ('move_left', 367.0037364217273), ('move_right', 0)]
best: move_right current state : (0, 1.0, -6) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -50
Iteration 977 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 2, -19) -37.241639747 [('nothing', 0), ('move_left', 156.0729347536241), ('move_right', -27.759)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.34235223056615), ('move_right', 0)]
Reward: 180
Iteration 978 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.19255895097635)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.19255895097635)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 267.98346833114266), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 194.1542896493329), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 979 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 95.63339200855515)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 95.63339200855515)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 338.50734979921606), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 178.50800275453304), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 980 Learning Q-Table
best: move_right current state : (0, -0.25, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -2, -17) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 30.0)]
best: move_right current state : (-1, -2, -8) 100 [('nothing', -30.0), ('move_left', 0), ('move_right', 0)]
Reward: 146
Iteration 981 Learning Q-Table
best: move_left current state : (-2, -2, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -2, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_right current state : (-1, -1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2.0, -7) 100 [('nothing', 240.31922841), ('move_left', 0), ('move_right', 0)]
Reward: -50
Iteration 982 Learning Q-Table
best: nothing current state : (-2, -2, -23) -100.0 [('nothing', -7.960180598157891), ('move_left', -30.0)]
best: nothing current state : (-2, -2, -23) -100.0 [('nothing', -7.960180598157891), ('move_left', -30.0)]
best: nothing current state : (-2, -2.0, -17) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -0.75, -8) -100.0 [('nothing', -15.0), ('move_left', 0)]
Reward: -250
Iteration 983 Learning Q-Table
best: nothing current state : (-2, -2, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -2, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -2, -19) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_right current state : (-1, 0.75, -9) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 984 Learning Q-Table
best: nothing current state : (0, -1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -0.75, -19) -100.0 [('nothing', 0), ('move_left', 90.00972670084988), ('move_right', 0)]
best: move_left current state : (0, 1.0, -9) -37.241639747 [('nothing', -45.0), ('move_left', -30.0), ('move_right', -75.0)]
Reward: 181
Iteration 985 Learning Q-Table
best: nothing current state : (0, 1.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 344.73072502029004), ('move_right', 0)]
best: move_left current state : (1, 2, -8) -37.241639747 [('nothing', 0), ('move_left', 218.70988995496347), ('move_right', 0)]
Reward: 145
Iteration 986 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 213.26965116686836)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 218.31249333410682)]
best: move_left current state : (1, 1.75, -18) -37.241639747 [('nothing', 0), ('move_left', 290.8347147265997), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 189.45560192817314), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 987 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 139.53539874759554)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 139.53539874759554)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 335.5075456858111), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 171.76675484999998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 988 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 226.90261549520912), ('move_right', 0)]
best: nothing current state : (0, 0.75, -8) 100 [('nothing', 0), ('move_left', -90.0), ('move_right', 0)]
Reward: 181
Iteration 989 Learning Q-Table
best: nothing current state : (0, 2, -23) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -11.172491924096027)]
best: nothing current state : (0, 2, -23) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', -11.172491924096027)]
best: move_left current state : (0, 1.5, -16) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.25, -4) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 62
Iteration 990 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 184.7825038170399)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 184.7825038170399)]
best: move_left current state : (1, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 124.218228), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 171.9189213497212), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 991 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -11.172491924096027)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -11.172491924096027)]
best: nothing current state : (0, 0.5, -17) -26.5339353272 [('nothing', 142.71141732688267), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -6) 150 [('nothing', 65.07), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 992 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 60.11060405040483), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 60.11060405040483), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 0.25, -18) -100.0 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 246.72182254291113)]
best: nothing current state : (0, 0.75, -8) -100.0 [('nothing', 54.3), ('move_left', -90.0), ('move_right', 0)]
Reward: -300
Iteration 993 Learning Q-Table
best: move_left current state : (-2, -2, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: nothing current state : (-2, -2, -24) -100.0 [('nothing', -30.0), ('move_left', -30.0)]
best: move_right current state : (-1, -1.25, -18) -27.8229678311 [('nothing', 0), ('move_left', 0), ('move_right', 84.555)]
best: move_right current state : (0, 1.0, -8) 100 [('nothing', 0), ('move_left', 0), ('move_right', 21.9)]
Reward: -150
Iteration 994 Learning Q-Table
best: move_left current state : (-1, -2.0, -24) -100.0 [('nothing', -60.0), ('move_left', 22.205369601636953), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2.0, -24) -100.0 [('nothing', -60.0), ('move_left', 22.205369601636953), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 204.55105170617284)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 253.68427920058102), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 995 Learning Q-Table
best: move_left current state : (0, -0.25, -23) -100.0 [('nothing', -2.1724919240960268), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -0.25, -23) -100.0 [('nothing', -2.1724919240960268), ('move_left', 0), ('move_right', -30.0)]
best: move_right current state : (0, 1.0, -16) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 215.387897083095)]
best: nothing current state : (0, 3, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 996 Learning Q-Table
best: nothing current state : (0, 0.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -18) -100.0 [('nothing', 0), ('move_left', 295.61669384277513), ('move_right', 0)]
best: move_right current state : (0, 1.25, -8) -26.5339353272 [('nothing', -52.53000000000001), ('move_left', 0), ('move_right', 0)]
Reward: 170
Iteration 997 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 137.65304047377003)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 137.65304047377003)]
best: move_left current state : (1, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 183.52843600491633), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 184.736728395), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 998 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 6.032500253039686)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 6.032500253039686)]
best: nothing current state : (0, 0.5, -17) -26.5339353272 [('nothing', 164.41899212881788), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -6) 150 [('nothing', 113.34899999999999), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 999 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 65.09396959815672), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 65.09396959815672), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 0.0, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 76.5)]
best: move_right current state : (0, 0.5, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 68
Iteration 1000 Learning Q-Table
best: nothing current state : (-2, -2, -24) -100.0 [('nothing', -3.9803903493395545), ('move_left', -60.0)]
best: nothing current state : (-2, -2, -24) -100.0 [('nothing', -3.9803903493395545), ('move_left', -60.0)]
best: move_left current state : (-2, -2, -18) -100.0 [('nothing', -35.71144642430246), ('move_left', -30.0)]
best: move_left current state : (-2, -0.75, -9) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: 62
Iteration 1001 Learning Q-Table
best: move_right current state : (0, -1.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -2, -8) 100 [('nothing', 0), ('move_left', 79.5453)]
Reward: 107
Iteration 1002 Learning Q-Table
best: move_left current state : (-2, -2, -24) -100.0 [('nothing', -62.78627324453769), ('move_left', -60.0)]
best: move_left current state : (-2, -2, -24) -100.0 [('nothing', -62.78627324453769), ('move_left', -60.0)]
best: move_left current state : (0, -0.0, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 3, -6) 150 [('nothing', 45.9), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1003 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 169.3668622309023)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 169.3668622309023)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 188.83183084664637), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 162.94324494480483), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1004 Learning Q-Table
best: nothing current state : (0, 0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.25, -16) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -4) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 1005 Learning Q-Table
best: move_left current state : (-1, -2.0, -24) -100.0 [('nothing', -60.0), ('move_left', 47.94889363483981), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2.0, -24) -100.0 [('nothing', -60.0), ('move_left', 47.94889363483981), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 195.42048328219317), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 174.04188000000002), ('move_right', 0)]
Reward: 215
Iteration 1006 Learning Q-Table
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 58.68500815283254), ('move_right', 0)]
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 58.68500815283254), ('move_right', 0)]
best: move_left current state : (0, 1.5, -19) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.4680475957843), ('move_left', 0), ('move_right', 0)]
Reward: 218
Iteration 1007 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 122.45547853495603)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 122.45547853495603)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 305.4209808870717), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 156.66027146136338), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1008 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 146.24617221746763)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 146.24617221746763)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 265.6040044161447), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 152.26219002295437), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1009 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 17.515778718709704), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 17.515778718709704), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 0.25, -18) -100.0 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 158.9952757800378)]
best: nothing current state : (0, 1.0, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -29.67)]
Reward: -300
Iteration 1010 Learning Q-Table
best: move_left current state : (-2, -2, -23) -100.0 [('nothing', -56.572126418710525), ('move_left', -30.0)]
best: move_left current state : (-2, -2, -23) -100.0 [('nothing', -56.572126418710525), ('move_left', -30.0)]
best: move_left current state : (-1, -1.25, -17) -37.6716305794 [('nothing', 0), ('move_left', 45.0), ('move_right', 0)]
best: nothing current state : (0, 3, -6) 150 [('nothing', 122.13), ('move_left', 0), ('move_right', 0)]
Reward: 288
Iteration 1011 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 146.68998366402275)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 146.68998366402275)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 234.00690229753522), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 182.14899117981253)]
Reward: 215
Iteration 1012 Learning Q-Table
best: move_left current state : (0, -1.25, -24) -100.0 [('nothing', -7.960180598157898), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -1.25, -24) -100.0 [('nothing', -7.960180598157898), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 296.8095138035081), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 243.22762847232346), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1013 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 148.38494864243285)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 148.38494864243285)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 295.75198257659605), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 192.00429382586876)]
Reward: 142
Iteration 1014 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 143.9248786559186)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 24.588267217615247)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 263.44952896221844), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -2, -6) 150 [('nothing', 147.1443), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1015 Learning Q-Table
best: move_left current state : (0, -1.25, -24) -100.0 [('nothing', -7.960180598157898), ('move_left', 56.870362216956394), ('move_right', -30.0)]
best: move_left current state : (0, -1.25, -24) -100.0 [('nothing', -7.960180598157898), ('move_left', 56.870362216956394), ('move_right', -30.0)]
best: move_right current state : (0, 1.25, -18) -26.5339353272 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 103.28768895)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 220.1789954404067), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1016 Learning Q-Table
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 5.715967493934773), ('move_right', 0)]
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 5.715967493934773), ('move_right', 0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 0), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 106.5)]
Reward: 215
Iteration 1017 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 163.6348782245239)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 163.6348782245239)]
best: move_left current state : (1, 2, -19) -47.8784607102 [('nothing', -16.50485056868419), ('move_left', 120.06845281562727), ('move_right', -11.172491924096027)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 195.53512846335764), ('move_right', 0)]
Reward: 120
Iteration 1018 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 78.1238952244276)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 78.1238952244276)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 226.0652550760939), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 171.08353301606806), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1019 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 318.83763156302075), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 163.3785)]
Reward: 211
Iteration 1020 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 115.2014123888069)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 115.2014123888069)]
best: move_left current state : (1, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 228.89092372194142), ('move_right', 0)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 115.197), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1021 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 93.5461225817696)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 93.5461225817696)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 331.38530843506777), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 162.35847311124763), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1022 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 8.95962783710813), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 8.95962783710813), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -18) -100.0 [('nothing', 0), ('move_left', 198.9715050917847), ('move_right', 0)]
best: move_right current state : (0, 0.5, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 20.4)]
Reward: 62
Iteration 1023 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 66.69110887074832), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 66.69110887074832), ('move_right', -30.0)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 317.19989209411455), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 148.293), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1024 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 120.34808519058936)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 120.34808519058936)]
best: move_left current state : (1, 2.0, -18) -37.241639747 [('nothing', 0), ('move_left', 239.782746605359), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 178.15093117787333), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1025 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 135.93769773960116)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 135.93769773960116)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 254.57073845808614), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 167.30565182451133), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1026 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 112.88356323960029), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 112.88356323960029), ('move_right', -30.0)]
best: move_right current state : (0, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', -18.004476749133605), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 168.3051), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1027 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 139.35511803105064)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 139.35511803105064)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 276.6014600981876), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 159.71395627715793), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -4, 2) 200 [('nothing', 0), ('move_left', 0), ('move_right', 64.5)]
Reward: 215
Iteration 1028 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 14.9631910135111), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 14.9631910135111), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -18) -100.0 [('nothing', 0), ('move_left', 115.40005356424929), ('move_right', 0)]
best: nothing current state : (0, 0.5, -6) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -200
Iteration 1029 Learning Q-Table
best: move_right current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', 0)]
best: move_right current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', 0)]
best: move_left current state : (0, 0.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 169.0372827), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 191.14976939401055), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, 4) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 108
Iteration 1030 Learning Q-Table
best: move_right current state : (0, -0.25, -24) -100.0 [('nothing', -5.905750221267443), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, -0.25, -24) -100.0 [('nothing', -5.905750221267443), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 126.65648344342014)]
best: move_left current state : (-2, -2, -6) 150 [('nothing', -30.0), ('move_left', 0)]
Reward: 163
Iteration 1031 Learning Q-Table
best: nothing current state : (-2, -2, -24) -100.0 [('nothing', -62.78627324453769), ('move_left', -67.7362585606767)]
best: nothing current state : (-2, -2, -24) -100.0 [('nothing', -62.78627324453769), ('move_left', -67.7362585606767)]
best: move_left current state : (-2, -2, -17) -100.0 [('nothing', -30.0), ('move_left', 0)]
best: nothing current state : (-2, -0.75, -6) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -250
Loading mission from ghast_survival_mission.xml
Iteration 1033 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.67821403969785), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.67821403969785), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 309.62767595137785), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 204.0396465613963), ('move_right', 0)]
Reward: 209
Iteration 1034 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 124.00599169092422)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 124.00599169092422)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.735102602157), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 177.00300567810814)]
Reward: 215
Iteration 1035 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 220.09844535187221), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 220.09844535187221), ('move_right', -56.22141343812249)]
best: move_right current state : (0, 2, -16) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 63.809999999999995)]
best: nothing current state : (2, 4, -6) 150 [('nothing', 92.78999999999999), ('move_right', 0)]
Reward: 142
Iteration 1036 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 155.40494515083003)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 155.40494515083003)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 177.93224264999998), ('move_right', -20.37)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.4429494149495)]
Reward: 142
Iteration 1037 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.30287201504396), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.30287201504396), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 322.9512671343834), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 205.5277525929774), ('move_right', 0)]
Reward: 215
Iteration 1038 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 168.16454436613617)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 168.16454436613617)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 299.92634879085995), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 178.8048385758074), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1039 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 229.1372099526879), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 229.1372099526879), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 332.7242127719616), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 213.83159021771564), ('move_right', 0)]
Reward: 215
Iteration 1040 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 175.52059376945726)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 175.52059376945726)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 308.5898957263442), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 189.66338700306517), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1041 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.2531302003121), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.2531302003121), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 342.05642600568785), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.36942681508418), ('move_right', 0)]
Reward: 215
Iteration 1042 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 183.26889243242732)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 183.26889243242732)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 326.32639497357576), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 188.4021039746757)]
Reward: 204
Iteration 1043 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.53393834376695), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.53393834376695), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 180.28845026750156), ('move_right', 0)]
best: nothing current state : (2, 4, -9) 150 [('nothing', 64.5), ('move_right', 0)]
Reward: 204
Iteration 1044 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 194.0136512706758)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 194.0136512706758)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 317.9119431093605), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 193.08147278227298)]
Reward: 204
Iteration 1045 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.59675370783933), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.59675370783933), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 286.5352089518787), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.7896448772448)]
Reward: 204
Iteration 1046 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 199.0106468981852)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 199.0106468981852)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 329.94910767390576), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 197.26437090214563), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1047 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 61.81414428497252), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 61.81414428497252), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 325.67725783792173), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -8) -100.0 [('nothing', -75.0), ('move_left', 0), ('move_right', -45.0)]
Reward: -300
Iteration 1048 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 148.35652872709568)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 148.35652872709568)]
best: nothing current state : (0, 1.5, -17) -15.7875285356 [('nothing', 0), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 171.9157098765), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1049 Learning Q-Table
best: nothing current state : (-1, 0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, 0.25, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, 0.25, -19) -100.0 [('nothing', 113.19038477897355), ('move_left', -19.38), ('move_right', 0)]
best: move_left current state : (-2, -0.5, -8) -52.5241823792 [('nothing', -30.0), ('move_left', 0)]
Reward: -100
Iteration 1050 Learning Q-Table
best: move_left current state : (-2, -0.75, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -0.75, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 126.18)]
Reward: 204
Iteration 1051 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 78.11331154829027)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 78.11331154829027)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 81.29669304602645)]
best: move_left current state : (-2, -2, -8) 150 [('nothing', 0), ('move_left', 87.78171)]
Reward: 204
Iteration 1052 Learning Q-Table
best: nothing current state : (-2, -0.75, -24) -100.0 [('nothing', 0), ('move_left', -32.17249192409603)]
best: nothing current state : (-2, -0.75, -24) -100.0 [('nothing', 0), ('move_left', -32.17249192409603)]
best: move_left current state : (-2, -0.25, -18) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, 0.75, -8) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: 62
Iteration 1053 Learning Q-Table
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 94.43233786505925), ('move_left', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 94.43233786505925), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 346.95032624850677), ('move_right', 0)]
best: move_left current state : (0, 0.75, -9) -100.0 [('nothing', -75.0), ('move_left', 0), ('move_right', 0)]
Reward: -200
Iteration 1054 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 50.10814539945323)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 50.10814539945323)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 212.86522837395475), ('move_right', 0)]
best: nothing current state : (-1, -1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1055 Learning Q-Table
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 119.1877343800935), ('move_left', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 119.1877343800935), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 194.00565986176832), ('move_right', 0)]
best: move_right current state : (0, 0.75, -8) -100.0 [('nothing', -51.99000000000001), ('move_left', -90.0), ('move_right', 0)]
Reward: -50
Iteration 1056 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 69.97508969364577)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 69.97508969364577)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 105.80396190323783), ('move_right', 0)]
best: move_left current state : (-2, -3, -8) 150 [('nothing', 0), ('move_left', 93.12)]
Reward: 142
Iteration 1057 Learning Q-Table
best: move_right current state : (0, 1.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -1.0, -17) -26.5339353272 [('nothing', 0), ('move_left', 0)]
best: move_right current state : (-1, -0.0, -6) -59.544922575 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 1058 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 88.2864651428383)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 88.2864651428383)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 146.99877333226647), ('move_right', 0)]
best: move_left current state : (-1, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1059 Learning Q-Table
best: nothing current state : (0, 1.0, -23) -100.0 [('nothing', 0), ('move_left', -7.960180598157898), ('move_right', -30.0)]
best: nothing current state : (0, 1.0, -23) -100.0 [('nothing', 0), ('move_left', -7.960180598157898), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 147.89914133258654), ('move_right', 0)]
best: move_left current state : (0, 1.0, -8) -100.0 [('nothing', -90.0), ('move_left', 0), ('move_right', -29.67)]
Reward: 84
Iteration 1060 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 73.72766567557072)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 73.72766567557072)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 311.5278244658802), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -2, -7) 150 [('nothing', 0), ('move_left', 42.6), ('move_right', 0)]
Reward: 215
Iteration 1061 Learning Q-Table
best: move_left current state : (-2, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -0.75, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, 0.5, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 199.7252968082847), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1062 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 116.10753271450567)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 116.10753271450567)]
best: move_right current state : (0, 1.25, -18) -37.241639747 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 183.355080897122)]
best: nothing current state : (-1, -1.5, -8) 150 [('nothing', 0), ('move_left', -7.529999999999994), ('move_right', 0)]
Reward: 226
Iteration 1063 Learning Q-Table
best: move_left current state : (-2, -0.75, -22) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -0.75, -22) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, 0.5, -16) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 100 [('nothing', 153.223459887), ('move_left', 0), ('move_right', 0)]
Reward: 118
Iteration 1064 Learning Q-Table
best: nothing current state : (0, 1.0, -23) -100.0 [('nothing', -6.630257600224038), ('move_left', -7.960180598157898), ('move_right', -30.0)]
best: nothing current state : (0, 1.0, -23) -100.0 [('nothing', -6.630257600224038), ('move_left', -7.960180598157898), ('move_right', -30.0)]
best: move_left current state : (0, 0.75, -18) -100.0 [('nothing', 0), ('move_left', 273.3912124680137), ('move_right', 0)]
best: move_left current state : (0, 0.75, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -45.0)]
Reward: 62
Iteration 1065 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 104.10930524519455)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 104.10930524519455)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 73.52939893281058), ('move_right', 0)]
best: move_left current state : (-1, -2, -7) 150 [('nothing', 0), ('move_left', 94.32), ('move_right', 0)]
Reward: 152
Iteration 1066 Learning Q-Table
best: nothing current state : (0, 1.0, -23) -100.0 [('nothing', 26.376183420247273), ('move_left', -7.960180598157898), ('move_right', -30.0)]
best: nothing current state : (0, 1.0, -23) -100.0 [('nothing', 26.376183420247273), ('move_left', -7.960180598157898), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 124.7665792529674), ('move_right', 0)]
best: move_left current state : (0, 1.0, -8) -100.0 [('nothing', -90.0), ('move_left', 25.2), ('move_right', -29.67)]
Reward: 73
Iteration 1067 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 62.76284142738333)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 62.76284142738333)]
best: move_right current state : (0, 1.25, -18) -37.241639747 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 173.3485566279854)]
best: nothing current state : (-2, -2, -7) 150 [('nothing', 40.5), ('move_left', 0)]
Reward: 213
Iteration 1068 Learning Q-Table
best: nothing current state : (-2, -0.75, -23) -100.0 [('nothing', 0), ('move_left', -28.960180598157898)]
best: nothing current state : (-2, -0.75, -23) -100.0 [('nothing', 0), ('move_left', -28.960180598157898)]
best: nothing current state : (-2, -0.5, -17) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -0.0, -8) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -300
Iteration 1069 Learning Q-Table
best: move_left current state : (-2, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -32.17249192409603)]
best: move_left current state : (-2, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -32.17249192409603)]
best: move_left current state : (-1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 186.329316), ('move_right', 0)]
Reward: 289
Iteration 1070 Learning Q-Table
best: nothing current state : (0, 3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 265.89617040236715)]
best: move_right current state : (0, -0.5, -8) -26.5339353272 [('nothing', 0), ('move_left', -90.0), ('move_right', 15.299999999999999)]
Reward: 192
Iteration 1071 Learning Q-Table
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 90.63311202459595), ('move_left', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 90.63311202459595), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 64.89660547707717), ('move_right', 0)]
best: move_right current state : (0, 0.75, -8) -100.0 [('nothing', -51.99000000000001), ('move_left', -90.0), ('move_right', -15.0)]
Reward: 62
Iteration 1072 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 51.76357075836549)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 51.76357075836549)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 128.2421981322185)]
best: move_left current state : (-2, -2, -9) 150 [('nothing', 0), ('move_left', 99.84389999999999)]
Reward: 204
Iteration 1073 Learning Q-Table
best: nothing current state : (-2, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -51.48092494502511)]
best: nothing current state : (-2, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', -51.48092494502511)]
best: nothing current state : (-2, -0.5, -18) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, 0.0, -9) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -300
Iteration 1074 Learning Q-Table
best: move_left current state : (-2, -0.75, -24) -100.0 [('nothing', -86.7), ('move_left', -51.48092494502511)]
best: move_left current state : (-2, -0.75, -24) -100.0 [('nothing', -86.7), ('move_left', -51.48092494502511)]
best: nothing current state : (-1, 0.75, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 217.1305212), ('move_right', 0)]
Reward: 215
Iteration 1075 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 45.7469783723635)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 45.7469783723635)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 10.927623833954023), ('move_right', 0)]
best: move_left current state : (-2, -3, -8) 150 [('nothing', 0), ('move_left', 107.784)]
Reward: 142
Iteration 1076 Learning Q-Table
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 31.912160060340316), ('move_left', 0), ('move_right', -28.960180598157898)]
best: nothing current state : (0, 1.0, -24) -100.0 [('nothing', 31.912160060340316), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -18) -100.0 [('nothing', 0), ('move_left', 84.9845366837678), ('move_right', 0)]
best: move_right current state : (0, 1.25, -8) -100.0 [('nothing', -52.53000000000001), ('move_left', 0), ('move_right', 51.0)]
Reward: 73
Iteration 1077 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 6.340991412682756)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 6.340991412682756)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 161.37384872760958), ('move_right', 0)]
best: move_right current state : (-1, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 88.794)]
Reward: 142
Iteration 1078 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 50.05831366956231), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 50.05831366956231), ('move_right', -30.0)]
best: nothing current state : (0, 1.5, -17) -26.5339353272 [('nothing', 96.57471296294999), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 45.6), ('move_right', 0)]
Reward: 226
Iteration 1079 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 23.890668009002894)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 23.890668009002894)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 44.78917567863746), ('move_right', 0)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 123.2379), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1080 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 1.2000397117353696)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 1.2000397117353696)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 197.97408048654523), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -2, -8) 150 [('nothing', -30.0), ('move_left', 0), ('move_right', 43.8)]
Reward: 224
Iteration 1081 Learning Q-Table
best: move_left current state : (-2, -1.25, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -1.25, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, 0.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 204.30770776579928), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1082 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 31.272071346020432)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 31.272071346020432)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 306.71153972948855), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -3, -8) 150 [('nothing', 0), ('move_left', 118.0488)]
Reward: 215
Iteration 1083 Learning Q-Table
best: nothing current state : (-2, -1.25, -24) -100.0 [('nothing', 0), ('move_left', -28.96018059815789)]
best: move_left current state : (-2, -1.25, -23) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -0.75, -17) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, 1.0, -6) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 107
Iteration 1084 Learning Q-Table
best: move_right current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', 21.7510042118421)]
best: move_right current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', 21.7510042118421)]
best: move_left current state : (-2, -1.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -1.25, -8) 100 [('nothing', -45.0), ('move_left', 0)]
Reward: -150
Iteration 1085 Learning Q-Table
best: nothing current state : (-1, -0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -0.0, -17) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.5, -8) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 83.4)]
Reward: 34
Iteration 1086 Learning Q-Table
best: move_left current state : (-1, -0.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -0.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 184.5998941093267), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 100 [('nothing', 256.9593399306264), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 1087 Learning Q-Table
best: move_right current state : (0, 2.0, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 63.76606406346792)]
best: move_right current state : (0, 2.0, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 63.76606406346792)]
best: move_right current state : (0, 1.25, -18) -37.241639747 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 178.49398963958978)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 202.58505963150193), ('move_left', 0), ('move_right', 0)]
Reward: 267
Iteration 1088 Learning Q-Table
best: move_left current state : (-2, -1.25, -24) -100.0 [('nothing', -30.0), ('move_left', -28.96018059815789)]
best: move_left current state : (-2, -1.25, -24) -100.0 [('nothing', -30.0), ('move_left', -28.96018059815789)]
best: move_left current state : (-1, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', -18.153611270406966)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 207.5153954360595), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1089 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 81.73141993696484)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 81.73141993696484)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 113.32379297504622), ('move_right', 0)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 128.86653), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1090 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 62.24895125023136)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 62.24895125023136)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 236.30772785571662), ('move_right', 0)]
best: move_left current state : (-1, -1.75, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1091 Learning Q-Table
best: move_right current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', -13.734477649868428)]
best: move_right current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', -13.734477649868428)]
best: move_left current state : (-1, -0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 30.0), ('move_right', 0)]
best: move_left current state : (-2, -1.0, -8) 100 [('nothing', -90.0), ('move_left', 0)]
Reward: -200
Iteration 1092 Learning Q-Table
best: nothing current state : (-1, -0.5, -24) -100.0 [('nothing', 47.41978763464011), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (-1, -0.5, -24) -100.0 [('nothing', 47.41978763464011), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (-1, -0.0, -17) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 17.059819401842102)]
best: nothing current state : (-1, 0.5, -8) -100.0 [('nothing', 46.68), ('move_left', 0), ('move_right', 0)]
Reward: -200
Iteration 1093 Learning Q-Table
best: nothing current state : (-2, -1.25, -22) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -1.25, -22) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -0.75, -16) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-1, 1.0, -5) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 1094 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 66.01194981220846)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 66.01194981220846)]
best: move_left current state : (0, 0.75, -18) -68.6546849676 [('nothing', 0), ('move_left', 210.41540949900164), ('move_right', 0)]
best: move_left current state : (-2, -3, -7) 150 [('nothing', 0), ('move_left', 0)]
Reward: 152
Iteration 1095 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 35.05305285942072), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 35.05305285942072), ('move_right', -30.0)]
best: nothing current state : (0, 1.5, -17) -26.5339353272 [('nothing', 126.28229907406498), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 99.72), ('move_right', 0)]
Reward: 215
Iteration 1096 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 67.73658222797548)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 67.73658222797548)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 275.84947712611614), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -6) 150 [('nothing', 167.50100999999998), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1097 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 33.4616461256561), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 33.4616461256561), ('move_right', -30.0)]
best: move_left current state : (0, 1.5, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 231.96077680524164), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1098 Learning Q-Table
best: move_right current state : (1, 4, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 4, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 182.75713868349914)]
best: move_left current state : (0, -1.5, -7) 100 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 1099 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 101.21027009925979)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 101.21027009925979)]
best: move_left current state : (0, 0.0, -18) -37.241639747 [('nothing', 0), ('move_left', 50.78003749497451), ('move_right', 0)]
best: nothing current state : (-2, -2, -7) 150 [('nothing', 92.25), ('move_left', 0)]
Reward: 131
Iteration 1100 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', -8.749339636136755), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', -8.749339636136755), ('move_right', -30.0)]
best: nothing current state : (0, 1.5, -17) -26.5339353272 [('nothing', 163.31360935184549), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 142.6564219209), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1101 Learning Q-Table
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 53.908708393878186)]
best: move_right current state : (0, 2, -23) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', 53.908708393878186)]
best: move_right current state : (0, 1.25, -18) -37.241639747 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 230.72131063716344)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 132.80657100000002), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1102 Learning Q-Table
best: nothing current state : (-2, -1.25, -23) -100.0 [('nothing', 0), ('move_left', -30.0)]
best: nothing current state : (-2, -1.25, -23) -100.0 [('nothing', 0), ('move_left', -30.0)]
best: move_left current state : (-2, -0.75, -17) -100.0 [('nothing', -7.960180598157891), ('move_left', 0)]
best: move_left current state : (-2, 0.0, -7) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -150
Iteration 1103 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 13.909364462100022), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 13.909364462100022), ('move_right', -30.0)]
best: move_left current state : (0, 1.5, -18) -37.241639747 [('nothing', 0), ('move_left', 114.58823304157248), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 245.77254376366915), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1104 Learning Q-Table
best: nothing current state : (2, 5, -23) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 5, -23) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -18) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 1.5, -7) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: -300
Iteration 1105 Learning Q-Table
best: move_right current state : (2, 5, -24) -100.0 [('nothing', -40.013206418710524), ('move_right', -30.0)]
best: move_right current state : (2, 5, -24) -100.0 [('nothing', -40.013206418710524), ('move_right', -30.0)]
best: move_left current state : (1, 3, -19) -37.241639747 [('nothing', -7.8302300142270616), ('move_left', 29.737929201450825), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.90954174205135), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1106 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 49.768851120710146)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 49.768851120710146)]
best: move_left current state : (0, 0.75, -18) -15.7875285356 [('nothing', 0), ('move_left', 192.29078664930114), ('move_right', 0)]
best: move_right current state : (0, -2.0, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 238.75690011481487)]
Reward: 163
Iteration 1107 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 85.50640363371903)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 85.50640363371903)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 251.23062068895524), ('move_right', 0)]
best: nothing current state : (-1, -1.75, -8) 150 [('nothing', 45.6), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1108 Learning Q-Table
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', -32.786626279003926)]
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', -24.959003352403553), ('move_right', -32.786626279003926)]
best: move_right current state : (0, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 157.9299970784494)]
best: nothing current state : (0, 3, -6) 150 [('nothing', 171.891), ('move_left', 0), ('move_right', 0)]
Reward: 163
Iteration 1109 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 106.263488152132)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 106.263488152132)]
best: move_left current state : (0, 1.5, -18) -68.6546849676 [('nothing', 0), ('move_left', 198.94352625820147), ('move_right', 0)]
best: move_right current state : (-1, -2, -8) 150 [('nothing', -30.0), ('move_left', 0), ('move_right', 97.85999999999999)]
Reward: 142
Iteration 1110 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 76.12682497043404), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 76.12682497043404), ('move_right', -30.0)]
best: nothing current state : (0, 2, -17) -15.7875285356 [('nothing', 294.098407554267), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 216.49136484000002), ('move_right', 0)]
Reward: 226
Iteration 1111 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 66.78917321861074)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 66.78917321861074)]
best: move_left current state : (0, 2.0, -19) -37.241639747 [('nothing', 0), ('move_left', 218.5537599967067), ('move_right', -27.759)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 197.93667921943594), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1112 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 92.4710940936819)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 92.4710940936819)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 196.72185634058167), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -2, -8) 150 [('nothing', -30.0), ('move_left', 0), ('move_right', 111.10199999999999)]
Reward: 215
Iteration 1113 Learning Q-Table
best: move_right current state : (-1, -0.5, -24) -100.0 [('nothing', -12.688202835199288), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (-1, -0.5, -24) -100.0 [('nothing', -12.688202835199288), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (-2, -1.0, -19) -64.129134 [('nothing', -35.572126418710525), ('move_left', -7.960180598157884)]
best: move_left current state : (-2, -0.25, -8) -64.129134 [('nothing', 0), ('move_left', 0)]
Reward: -50
Loading mission from ghast_survival_mission.xml
Iteration 1115 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 147.47565318563383), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 147.47565318563383), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 291.9525839962436), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 205.424665539)]
Reward: 208
Iteration 1116 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.11969320680535)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.11969320680535)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 335.1436866423777), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 181.15567545360517), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1117 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 182.3057983569551), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 182.3057983569551), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 162.98661408253236), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.35859877055893), ('move_right', 0)]
Reward: 215
Iteration 1118 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.65439931338102)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.65439931338102)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 355.5154735249423), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 191.30897281752362), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1119 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 147.54986247647037), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 147.54986247647037), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 325.7349482041527), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.9862614369044)]
Reward: 215
Iteration 1120 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.55254097869152)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.55254097869152)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 333.9472832857459), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.35703094759108)]
Reward: 204
Iteration 1121 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 168.83289627067904), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 168.83289627067904), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.0225145752399), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.75101913939125), ('move_right', 0)]
Reward: 204
Iteration 1122 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.59847174671182)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.59847174671182)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 384.78442535408124)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 198.41628097226655), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1123 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 169.40897825576837), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 136.69449264699026), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 216.03589943840717), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 255.4407806345684), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1124 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 129.990642476485)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 129.990642476485)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 164.72270869255294)]
best: move_left current state : (0, -1.25, -9) 150 [('nothing', 0), ('move_left', 32.1), ('move_right', 0)]
Reward: 278
Iteration 1125 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 63.23018993088793), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 63.23018993088793), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 42.834316766498894), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 234.1715379514385), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1126 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 111.45008174314748)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 111.45008174314748)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 169.93589608478706)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 225.59139668058657), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1127 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 24.938936057475196), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 24.938936057475196), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 307.0352128341102), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 247.32007656600695), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1128 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 100.03564544748144)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 100.03564544748144)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 334.1206719536792), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 244.6139776764106), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1129 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.9296011638894), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.9296011638894), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 222.19820948894034), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.72862813755498)]
Reward: 226
Iteration 1130 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.09407723076475)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.09407723076475)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 351.2535233127167), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.82978437348743), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1131 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 161.85855183065888), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 161.85855183065888), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 266.45733508352475), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 196.59692296847442), ('move_right', 0)]
Reward: 215
Iteration 1132 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.98173045719244)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.98173045719244)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 355.02640163094793), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 198.64992166331376)]
Reward: 204
Iteration 1133 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 175.55000306324678), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 175.55000306324678), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.8410659444853), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.42571339757387), ('move_right', 0)]
Reward: 204
Iteration 1134 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.1349512111612)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.1349512111612)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 325.4628020112342), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 188.14099691355), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1135 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 201.87714132946044), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 201.87714132946044), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 295.112717810642), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 217.7903830058331)]
Reward: 215
Iteration 1136 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 228.89666782775868)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 228.89666782775868)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 353.11345764065766), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.1808490614412), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1137 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.67532234971887), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.67532234971887), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.7164601804119), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.7979993783017), ('move_right', 0)]
Reward: 204
Iteration 1138 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.2608145270871)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.2608145270871)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 337.6702075842995), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.25494516431962)]
Reward: 204
Iteration 1139 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 217.3274831007689), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 217.3274831007689), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.1409219397788), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 206.6585995648112), ('move_right', 0)]
Reward: 204
Iteration 1140 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.01114052015478)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.01114052015478)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 341.4456288583055), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.37846161502372)]
Reward: 215
Iteration 1141 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.91133415431398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.91133415431398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 290.49921144900964), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 205.86101969536784), ('move_right', 0)]
Reward: 215
Iteration 1142 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.86899509750398)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.86899509750398)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 356.4336750668927), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.12659434300883), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1143 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.82751674456478), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.82751674456478), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 338.71034217397823), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.18211315240094), ('move_right', 0)]
Reward: 215
Iteration 1144 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.77821849016271)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.77821849016271)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 329.26626048192895), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.4649231305166)]
Reward: 204
Iteration 1145 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.31987244929277), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.31987244929277), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.39622522728854), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.60271378675748), ('move_right', 0)]
Reward: 204
Iteration 1146 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.25213916359658)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.25213916359658)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.8415508497275), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.28861604010618), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1147 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.8825976845336), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.8825976845336), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 234.54143448226867), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.22189965073022), ('move_right', 0)]
Reward: 215
Iteration 1148 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.46878207127799)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.46878207127799)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.1756704068411), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.02544619136162)]
Reward: 215
Iteration 1149 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.82006812569622), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.82006812569622), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 190.5519151872511), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 216.95326810408318)]
Reward: 215
Iteration 1150 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.92066797378902)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.92066797378902)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.93060314219724), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.10203122807434), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1151 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 165.8760840311147), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 165.8760840311147), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 346.351873467505), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 216.36728767285823)]
Reward: 215
Iteration 1152 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.3634679261536)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.3634679261536)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.48203156796035), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.67142185965204), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1153 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.84632893793577), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.84632893793577), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 352.35649772911097), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.55532975551117), ('move_right', 0)]
Reward: 215
Iteration 1154 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 233.98921284753234)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 233.98921284753234)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.73884865546785), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 216.0298300803704)]
Reward: 215
Iteration 1155 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.02688765119228), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.02688765119228), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 354.51614733703104), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.95710137100076)]
Reward: 215
Iteration 1156 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.23885642053773)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.23885642053773)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.32614308293864), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.06999530175642), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1157 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 217.70117363284788), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 217.70117363284788), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 243.47232106230072), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.42747920668066), ('move_right', 0)]
Reward: 215
Iteration 1158 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.1048618211001)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.1048618211001)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 373.8739820395368)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 248.35806694800002)]
Reward: 300
Iteration 1159 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 129.59463257313493), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 129.59463257313493), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 289.80250882562257), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 243.30854644419787), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1160 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.7993393259544)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.7993393259544)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 271.3455740328071), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.3489967112295), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1161 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 141.30097280118287)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 141.30097280118287)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.26866367049865), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 192.64429769786065), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1162 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 190.06897964863572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 190.06897964863572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 310.1077539229171), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 221.61003969628848)]
Reward: 238
Iteration 1163 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 239.90302913985232)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 239.90302913985232)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.849298748584), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 177.45100838850246), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1164 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.12043133276222), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.12043133276222), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 357.94843354722195), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.66997095970052)]
Reward: 215
Iteration 1165 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.82672942431392)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.82672942431392)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 352.22981164055955), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 188.7157058719517), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1166 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.1963400730041), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.1963400730041), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 328.5584396549285), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.1887308288578), ('move_right', 0)]
Reward: 215
Iteration 1167 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.18747349102972)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 243.0539229917551)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 348.1755799099772), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 196.6009941103662), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1168 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.84478934942354), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.84478934942354), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.4581717951292), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.33211158020046), ('move_right', 0)]
Reward: 204
Iteration 1169 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.04740834124732)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.04740834124732)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 347.7032041700939), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 198.82069587725636), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1170 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.76862348497735), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.76862348497735), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 338.3475270071073), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.59923544467645), ('move_right', 0)]
Reward: 215
Iteration 1171 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 227.9839664917434)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 227.9839664917434)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 344.42547868532097), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.01781233395315)]
Reward: 204
Iteration 1172 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.78211394345846), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.78211394345846), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 207.11829795491457)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.83247810614031), ('move_right', 0)]
Reward: 142
Iteration 1173 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 175.6310994638197)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 175.6310994638197)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 108.22102624648215), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 203.67448711407945), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1174 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.5227885487374), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.5227885487374), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.26489477096555), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 189.48273467429823), ('move_right', 0)]
Reward: 215
Iteration 1175 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.74392822572062)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.74392822572062)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 348.0384516822426), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 188.1721409798556), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1176 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 214.17292849130982), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 214.17292849130982), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 299.2466008363338), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 197.13791427200877), ('move_right', 0)]
Reward: 215
Iteration 1177 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.97210466451932)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.97210466451932)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 337.12585927650525), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.8124686337672)]
Reward: 204
Iteration 1178 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 210.73484959665913), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 210.73484959665913), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.6203537306506), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 202.49653999040615), ('move_right', 0)]
Reward: 204
Iteration 1179 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 234.84573912401908)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 234.84573912401908)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 345.07855847152655), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 196.198697839485), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1180 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.4403202386987), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.4403202386987), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 346.22303953837803), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 202.9475779932843), ('move_right', 0)]
Reward: 215
Iteration 1181 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.95540433011342)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.95540433011342)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 345.4146002819141), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 196.22049868589892), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1182 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.4149554304446), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.4149554304446), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 354.03024674196536), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 206.56330459529903), ('move_right', 0)]
Reward: 215
Iteration 1183 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.93298251749573)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.93298251749573)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 345.65636980310956), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 201.85434908012925), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1184 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.42705089980478), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.42705089980478), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 354.79016409796543), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.0943132167093), ('move_right', 0)]
Reward: 215
Iteration 1185 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.08981810502198)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.08981810502198)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 305.7927680593592), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 201.8390884876395), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1186 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 126.44789690046055)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 126.44789690046055)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 231.6325462635269)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 205.7980443560905), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1187 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 80.60763849230781), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 80.60763849230781), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 264.2910199544953)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 219.343955388), ('move_right', 0)]
Reward: 142
Iteration 1188 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 145.4845035247852), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 145.4845035247852), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -47.8784607102 [('nothing', 0), ('move_left', 313.6139948670363), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 253.71598251093852), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1189 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.64052249316526)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.64052249316526)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 348.5031787799106), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.75863104926333), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1190 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.46349293515695), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.46349293515695), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 356.0814088335886), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.8660192516965), ('move_right', 0)]
Reward: 215
Iteration 1191 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.92682745509285)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.92682745509285)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 347.5157635862155), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 263.8506468636)]
Reward: 226
Iteration 1192 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.97637578059042), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.97637578059042), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 348.2404010748499), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 226.52702778740195)]
Reward: 226
Iteration 1193 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.44332769627175)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.44332769627175)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 343.03184208368384), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.96872804363704)]
Reward: 215
Iteration 1194 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.59540277071036), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.59540277071036), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 340.64459116020697), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.10621347618755), ('move_right', 0)]
Reward: 215
Iteration 1195 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 239.04739008839937)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 239.04739008839937)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.4162285694308), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 226.03104173448432), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1196 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.14997868940145), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.14997868940145), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 347.08307785500114), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.46897967179035)]
Reward: 215
Iteration 1197 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.5978610345509)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.5978610345509)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.0006725189469), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.72172921413903), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1198 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.76972784092345), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.76972784092345), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 316.9160173691993), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.32828577025325)]
Reward: 215
Iteration 1199 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 263.4179281431257)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 263.4179281431257)]
best: move_right current state : (1, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 270.51847666285244)]
best: nothing current state : (0, -2, -6) 150 [('nothing', 185.050707), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1200 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 160.55981271441252), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 160.55981271441252), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.5988484000379), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 264.301187757657), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1201 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.0585238817118)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.0585238817118)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.8169895275045), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.67810963054592)]
Reward: 204
Iteration 1202 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.64112277531018), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.64112277531018), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 357.516791959021), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.97434943333127), ('move_right', 0)]
Reward: 204
Iteration 1203 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.5258829772917)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.5258829772917)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.17532555841694), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 220.4052104498973), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1204 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.0313316063274), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.0313316063274), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 310.99420845907053), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 177.66495)]
Reward: 215
Iteration 1205 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.2605351534714)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.2605351534714)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.14429102586104), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.78364731492812), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1206 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.36001406399245), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.36001406399245), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.7263890886155), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.71946481127353), ('move_right', 0)]
Reward: 215
Iteration 1207 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.46548131703037)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.46548131703037)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.3360979125812), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 217.6485531204497), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1208 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.7097459732215), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.7097459732215), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 359.1540592013141), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.28204460333188), ('move_right', 0)]
Reward: 215
Iteration 1209 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.0664856975377)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.0664856975377)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 346.9129078716698), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 216.85398718431478), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1210 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.07054801755325), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.07054801755325), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 371.10955020732365), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.6974312223323), ('move_right', 0)]
Reward: 215
Iteration 1211 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.5479204256813)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.5479204256813)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.12983447494173), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.29779102902035), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1212 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.22206807632648), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 161.0656948824226), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 359.1243118054129), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 210.24095033350648), ('move_right', 0)]
Reward: 215
Iteration 1213 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.16231404230155)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.16231404230155)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.5802214411653), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.90845372031424), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1214 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 195.57515611815532), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 195.57515611815532), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.45930336384095), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 216.227633317049), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1215 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.5275056638028)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.5275056638028)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.07869112491), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 215.63591760421997), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1216 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.78021969370312), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.78021969370312), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.48980234980337), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.68820185563263), ('move_right', 0)]
Reward: 215
Iteration 1217 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.03268070397706)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.03268070397706)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.645859068703), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.44514232295398), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1218 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.5329138923753), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.5329138923753), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 368.28591451182626), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.38174129894284), ('move_right', 0)]
Reward: 215
Iteration 1219 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 236.58791210088583)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 236.58791210088583)]
best: move_right current state : (1, 1.0, -17) -26.5339353272 [('nothing', -14.363538213047999), ('move_left', 0), ('move_right', 154.76167688727588)]
best: move_right current state : (0, -2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 153.0)]
Reward: 289
Iteration 1220 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 189.21134282194225), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 189.21134282194225), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 320.85432011119514), ('move_right', -30.0)]
best: move_right current state : (0, 1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 113.76599999999999)]
Reward: 278
Iteration 1221 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.95645361523697)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 183.07986093864494)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 366.28564404497826), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.3115996260678), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1222 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.8986334800527), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.8986334800527), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.8493222015521), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 226.36891945118137)]
Reward: 226
Iteration 1223 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.49347581225936)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.49347581225936)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 352.89523166546326), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 61.199999999999996), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 204
Iteration 1224 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.62365949834464), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.62365949834464), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.4832096085773), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.86721890925998), ('move_right', 0)]
Reward: 204
Iteration 1225 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.44151064412452)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.44151064412452)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 310.3866621658243), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.21811973824745), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1226 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.02134393325653), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.02134393325653), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 359.49245482191947), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.90705323648197), ('move_right', 0)]
Reward: 215
Iteration 1227 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 216.65256417653845)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 216.65256417653845)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.99343071930514), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.15268381677322), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1228 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.79018527575937), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.79018527575937), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 331.4396978895155), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.1349372655374), ('move_right', 0)]
Reward: 215
Iteration 1229 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.49464354121056)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.49464354121056)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.7412066485456), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 64.5)]
Reward: 204
Iteration 1230 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.21254713579017), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.21254713579017), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -17) -26.5339353272 [('nothing', 0), ('move_left', 108.21745286977786), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 206.1972658773)]
Reward: 204
Iteration 1231 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.5084318752532)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 226.8691039464489)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 320.3688446539819), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.10687867174124), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1232 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 174.45383825782858), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 174.45383825782858), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 366.81466254796123), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.99445608587618), ('move_right', 0)]
Reward: 215
Iteration 1233 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 47.13775558651456)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 47.13775558651456)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 240.43342889682734)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.07481507021888), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1234 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 45.514005789894505), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 45.514005789894505), ('move_right', -49.9601805981579)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 181.85706450676133), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 268.4108314303599), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1235 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 76.1662769814505)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 76.1662769814505)]
best: nothing current state : (1, 1.0, -19) -37.241639747 [('nothing', 30.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 237.25237054915323), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1236 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', -2.9970819897450354), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', -2.9970819897450354), ('move_right', -15.460180598157898)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 268.882195691296)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.5961192601133), ('move_right', 0)]
Reward: 142
Iteration 1237 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 89.97307835085729), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 89.97307835085729), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 272.8573637972555), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.0, -8) -100.0 [('nothing', -75.0), ('move_left', -90.0), ('move_right', -45.0)]
Reward: -300
Iteration 1238 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 93.83836398477675), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 93.83836398477675), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -19) -100.0 [('nothing', 0), ('move_left', 303.7278240778366), ('move_right', -30.0)]
best: move_left current state : (0, -0.25, -9) -100.0 [('nothing', -75.0), ('move_left', 0), ('move_right', -90.0)]
Reward: -150
Iteration 1239 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 30.14390196291932)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 30.14390196291932)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 277.8258447488448)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.57665938440726), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1240 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -44.161874366706186), ('move_right', -57.68726494502512)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', -44.161874366706186), ('move_right', -57.68726494502512)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 252.82319458384092), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 274.5875820012519), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1241 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 75.48830420053908)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 75.48830420053908)]
best: nothing current state : (1, 1.0, -19) -37.241639747 [('nothing', 137.17571116474596), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.27467674138214)]
Reward: 204
Iteration 1242 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 49.60652071640937), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 49.60652071640937), ('move_right', -15.460180598157898)]
best: move_right current state : (0, 0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 23.550000000000004)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.22980003917726)]
Reward: 131
Iteration 1243 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 105.8052020126947), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 105.8052020126947), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -19) -100.0 [('nothing', 0), ('move_left', 182.60947685448562), ('move_right', -30.0)]
best: move_right current state : (0, 0.25, -8) -100.0 [('nothing', -100.5), ('move_left', -58.349999999999994), ('move_right', -46.5)]
Reward: -100
Iteration 1244 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 61.82203436570512)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 61.82203436570512)]
best: nothing current state : (1, 1.0, -19) -37.241639747 [('nothing', 203.20540083773682), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 186.41006459046466)]
Reward: 215
Iteration 1245 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 9.617072577390534), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 9.617072577390534), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 231.18545467948485), ('move_right', -20.37)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 202.1178460779321), ('move_right', 0)]
Reward: 233
Iteration 1246 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 72.0645523832186)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 72.0645523832186)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 308.65108913951354)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 251.40366156908507), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1247 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 57.45674280679666), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 57.45674280679666), ('move_right', -49.9601805981579)]
best: move_right current state : (0, -0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 132.82096860000001)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 256.52405359620485), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1248 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 43.915095283922795), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 43.915095283922795), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.25, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 192.11728348207933), ('move_right', 0)]
Reward: 215
Iteration 1249 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 114.08033281194919)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 114.08033281194919)]
best: move_left current state : (1, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 270.5051513873623), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 262.68256309835954), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1250 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 77.84648446523198), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 77.84648446523198), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 147.50015465807888), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.25, -8) -100.0 [('nothing', -100.5), ('move_left', -58.349999999999994), ('move_right', -62.55)]
Reward: -300
Iteration 1251 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 47.74258552308605), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 47.74258552308605), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 55.74510826065523), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.25, -8) -100.0 [('nothing', -100.5), ('move_left', -130.845), ('move_right', -62.55)]
Reward: -300
Iteration 1252 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -0.8566576556431968), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -0.8566576556431968), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_right current state : (0, 0.25, -18) -100.0 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 297.2963727619412)]
best: move_right current state : (0, -0.5, -8) -100.0 [('nothing', 0), ('move_left', -90.0), ('move_right', 68.31)]
Reward: 84
Iteration 1253 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', -4.622971514302048), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', -4.622971514302048), ('move_right', -15.460180598157898)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 198.60046093335885)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.96086002742408)]
Reward: 142
Iteration 1254 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 37.589251469632124), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 37.589251469632124), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -18) -100.0 [('nothing', -9.743424217541346), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.0, -8) -100.0 [('nothing', -75.0), ('move_left', -90.0), ('move_right', -121.5)]
Reward: -50
Iteration 1255 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 132.04759778641522)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 132.04759778641522)]
best: nothing current state : (1, 1.0, -19) -37.241639747 [('nothing', 243.16679996355518), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.98704521332525)]
Reward: 215
Iteration 1256 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 27.383877621838323), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 27.383877621838323), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 267.465172099019), ('move_right', -20.37)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 211.38249225455246), ('move_right', 0)]
Reward: 228
Iteration 1257 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 133.21086651546116)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 133.21086651546116)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 336.476860868385)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 226.4777941688517), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1258 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 47.893518620661645), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 47.893518620661645), ('move_right', -49.9601805981579)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 273.5579602735529), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 1.5, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 68.58000000000001)]
Reward: 215
Iteration 1259 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -24.687523971257512), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -24.687523971257512), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -19) -100.0 [('nothing', 0), ('move_left', 83.87663379813995), ('move_right', -30.0)]
best: move_right current state : (0, -0.25, -8) -100.0 [('nothing', -106.5), ('move_left', -90.0), ('move_right', -75.0)]
Reward: -300
Iteration 1260 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 165.23048422318044)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 165.23048422318044)]
best: move_right current state : (1, 0.75, -18) -26.8431610474 [('nothing', 0), ('move_left', 0), ('move_right', 348.477140858525)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.99093164932768)]
Reward: 288
Iteration 1261 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', 15.973465720300055), ('move_right', -57.68726494502512)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', 15.973465720300055), ('move_right', -57.68726494502512)]
best: move_right current state : (0, -0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 214.93189409886145)]
best: nothing current state : (0, 1.75, -9) 150 [('nothing', 121.41), ('move_left', 0), ('move_right', 0)]
Reward: 120
Iteration 1262 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 196.5317440846221), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 196.5317440846221), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 226.25824361582696)]
Reward: 142
Iteration 1263 Learning Q-Table
best: move_right current state : (0, -0.25, -24) -100.0 [('nothing', -5.905750221267443), ('move_left', -30.0), ('move_right', 9.036764434868147)]
best: move_right current state : (0, -0.25, -24) -100.0 [('nothing', -5.905750221267443), ('move_left', -30.0), ('move_right', 9.036764434868147)]
best: move_left current state : (0, -1.25, -18) -26.5339353272 [('nothing', -7.960180598157904), ('move_left', 23.41014), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 245.23445591819618), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1264 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 108.61204026107757), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 108.61204026107757), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 241.0085806615784)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 175.57260201919686)]
Reward: 131
Iteration 1265 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', -5.905750221267443), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', -5.905750221267443), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: nothing current state : (0, -0.25, -18) -100.0 [('nothing', 257.06457219148706), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, -0.75, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 54.3)]
Reward: -250
Iteration 1266 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 21.98534650255891), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 21.98534650255891), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: move_right current state : (0, -0.5, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 295.8069005845467)]
best: move_left current state : (0, -1.0, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -90.0)]
Reward: 73
Iteration 1267 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 119.37082178306991), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 119.37082178306991), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 112.87747308474808)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.98077053107886)]
Reward: 142
Iteration 1268 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 53.13181272715525), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 53.13181272715525), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: move_right current state : (0, -0.25, -19) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 231.875325869203)]
best: move_left current state : (0, -0.25, -9) -100.0 [('nothing', -75.0), ('move_left', -45.0), ('move_right', -90.0)]
Reward: -250
Iteration 1269 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 67.2357740408965), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 67.2357740408965), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.25, -19) -37.6537001689 [('nothing', 0), ('move_left', 295.6403681456791), ('move_right', -20.37)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 162.2008214134378)]
Reward: 231
Iteration 1270 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 191.1515328995571)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 191.1515328995571)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 349.2312780957658)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.26411914273731), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1271 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 86.63267051837113), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 86.63267051837113), ('move_right', -49.9601805981579)]
best: move_right current state : (0, -0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 126.05394001175316)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 222.1668375173434), ('move_left', 0), ('move_right', 0)]
Reward: 120
Iteration 1272 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 103.46104222165465), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 103.46104222165465), ('move_right', -15.460180598157898)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 184.3084623186473)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 182.84057498940646)]
Reward: 152
Iteration 1273 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -43.118276640438275), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', -43.118276640438275), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.75, -18) -100.0 [('nothing', 0), ('move_left', 365.6686006093357), ('move_right', 0)]
best: move_right current state : (0, 0.5, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 32.879999999999995)]
Reward: 67
Iteration 1274 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 209.61527586026182)]
best: move_right current state : (2, 2, -23) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 304.3525108090642), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 236.68488339991612), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1275 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 55.75486666976958), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 55.75486666976958), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: move_right current state : (0, -0.5, -18) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 177.06483040918272)]
best: move_left current state : (0, -1.0, -8) -100.0 [('nothing', 0), ('move_left', 21.9), ('move_right', -90.0)]
Reward: -50
Iteration 1276 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 88.46263657541546), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 88.46263657541546), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -17) -15.7875285356 [('nothing', 194.0979944901725), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -7) 150 [('nothing', 0), ('move_left', 112.94999999999999), ('move_right', 0)]
Reward: 226
Iteration 1277 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 116.73069310218328)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 116.73069310218328)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 329.0522225863198), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.09365215452937)]
Reward: 131
Iteration 1278 Learning Q-Table
best: move_right current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -21.39292586946527), ('move_right', -19.960180598157898)]
best: move_right current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -21.39292586946527), ('move_right', -19.960180598157898)]
best: move_right current state : (0, -1.75, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.7208810562593)]
Reward: 289
Iteration 1279 Learning Q-Table
best: move_left current state : (-2, -4, -24) -100.0 [('nothing', -60.0), ('move_left', -35.7927)]
best: move_left current state : (-2, -4, -24) -100.0 [('nothing', -60.0), ('move_left', -35.7927)]
best: move_left current state : (0, -1.25, -18) -26.5339353272 [('nothing', -7.960180598157904), ('move_left', 134.95743477545886), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 164.35949534462998), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1280 Learning Q-Table
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -21.39292586946527), ('move_right', -42.93230701686843)]
best: move_left current state : (0, 0.75, -23) -100.0 [('nothing', -30.0), ('move_left', -21.39292586946527), ('move_right', -42.93230701686843)]
best: move_left current state : (1, 1.5, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -7) 100 [('nothing', 0), ('move_right', 69.52199999999999)]
Reward: 114
Iteration 1281 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 151.46697134926632)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 151.46697134926632)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 353.74113040985725)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 208.2794183799413), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1282 Learning Q-Table
best: move_left current state : (0, -1.5, -23) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -1.5, -23) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.0)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 266.37778706886394)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 198.45164674124098), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1283 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 98.75508765259454), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 98.75508765259454), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.25, -19) -47.8784607102 [('nothing', 0), ('move_left', 300.60850412600666), ('move_right', -20.37)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 216.36774457818672), ('move_right', 0)]
Reward: 225
Iteration 1284 Learning Q-Table
best: move_right current state : (2, 2, -23) -100.0 [('nothing', 0), ('move_right', 83.34557264456136)]
best: move_right current state : (2, 2, -23) -100.0 [('nothing', 0), ('move_right', 83.34557264456136)]
best: move_right current state : (1, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 355.10261680088246)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 237.7046167393815)]
Reward: 289
Iteration 1285 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 66.28655944228971), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 66.28655944228971), ('move_right', -49.9601805981579)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 166.23520053404093), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 163.0362)]
Reward: 215
Iteration 1286 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 28.517786534493922), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 28.517786534493922), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_right current state : (0, 0.5, -18) -100.0 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 228.86809611987505)]
best: nothing current state : (0, -0.0, -7) -100.0 [('nothing', 0), ('move_left', -90.0), ('move_right', 0)]
Reward: -200
Loading mission from ghast_survival_mission.xml
Iteration 1288 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 203.20190494671047), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 203.20190494671047), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 235.83202042653502), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 205.53808611411)]
Reward: 209
Iteration 1289 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 246.9588455605509)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 246.9588455605509)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 381.2192075120758)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 229.1955928659589), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1290 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 94.41698538916586), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 94.41698538916586), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 340.64826970232207), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 191.51678626214039), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1291 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 12.822216535594055), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 12.822216535594055), ('move_right', -16.5)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 187.70845550994636), ('move_right', -11.172491924096027)]
best: nothing current state : (2, 2, -8) 100 [('nothing', 96.2844), ('move_right', 0)]
Reward: 118
Iteration 1292 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 258.2767735478505)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 258.2767735478505)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 380.61212311824073)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 253.09323171756705)]
Reward: 289
Iteration 1293 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 152.53673408625744), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 152.53673408625744), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 271.7438401328075), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 195.26175038349828), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1294 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 262.80488649487154)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 262.80488649487154)]
best: move_left current state : (1, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 313.15837490066144), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 247.13691500617122), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1295 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 129.04311111122254)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 129.04311111122254)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 320.33627626166066), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.59584050431985), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1296 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 184.03075899249993), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 184.03075899249993), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 366.20520137644087), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.9574212047307), ('move_right', 0)]
Reward: 216
Iteration 1297 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 208.51663349661192)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 208.51663349661192)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 333.7902548593097), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 196.5170883530239), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1298 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.51059978358617), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.51059978358617), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 293.79921320801475), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 139.05)]
Reward: 215
Iteration 1299 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 217.13853930726336)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 245.7384410925125)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 387.35645569803864)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 263.86526220229695)]
Reward: 278
Iteration 1300 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 132.9228324700647), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 159.33868530206456), ('move_right', -53.7146573472915)]
best: move_right current state : (0, 0.5, -18) -37.241639747 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 130.20766728391254)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 181.51615271886868), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1301 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 203.73700321275686), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 203.73700321275686), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 2.0, -17) -15.7875285356 [('nothing', 315.8162947399869), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -6) 150 [('nothing', 107.553), ('move_right', 0)]
Reward: 204
Iteration 1302 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.7185098428381)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.7185098428381)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 202.06196184711672), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1303 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 33.11559630380371), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 33.11559630380371), ('move_right', -16.5)]
best: nothing current state : (2, 3, -18) -26.5339353272 [('nothing', 41.79), ('move_right', 0)]
best: move_right current state : (2, 2, -7) 100 [('nothing', 0), ('move_right', 82.8654)]
Reward: 108
Iteration 1304 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 277.05135355007434)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 277.05135355007434)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 337.608304907424), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 187.0433732929817), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1305 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 211.62453211024916), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 211.62453211024916), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 292.3744492456103), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 198.98209843745553), ('move_right', 0)]
Reward: 215
Iteration 1306 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 104.83046496589066)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 104.83046496589066)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 105.61858855413502), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 195.4303613050872), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1307 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 154.25856873225794)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 154.25856873225794)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 333.91414553445844), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 179.40125291356102), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1308 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.88932665269962), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.88932665269962), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 359.9168343462882), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 163.41357), ('move_left', 0), ('move_right', 0)]
Reward: 216
Iteration 1309 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 266.2582583591213)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 266.2582583591213)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 358.17981446071644), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 268.10568354160785)]
Reward: 215
Iteration 1310 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.8373983626183), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.8373983626183), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 367.03086732492784), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.0701948433115), ('move_right', 0)]
Reward: 215
Iteration 1311 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.6622332655038)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.6622332655038)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 395.30909764931613)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 168.1808770394927), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1312 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 110.84758831966465), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 110.84758831966465), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 340.90882467026756), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 220.08322526844879), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1313 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 6.757736814504707), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 6.757736814504707), ('move_right', -16.5)]
best: move_left current state : (1, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 266.2932019771133), ('move_right', 0)]
best: nothing current state : (2, 2, -8) 100 [('nothing', 102.79908), ('move_right', 0)]
Reward: 118
Iteration 1314 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 272.7961119824896)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 272.7961119824896)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 372.1706314663691)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 204.4266139276449), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1315 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 144.5024210117975), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 144.5024210117975), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 6.213643658697961), ('move_right', -30.0)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 215.25825768791415), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1316 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 270.43597590355745)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 270.43597590355745)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 337.4388254230913), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 226.49862974935144), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1317 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.62294712721513), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.62294712721513), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 367.34266558044294), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 203.78746890621886), ('move_right', 0)]
Reward: 215
Iteration 1318 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 72.89441011826794)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 72.89441011826794)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 376.15757518498384), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.2922737189675)]
Reward: 215
Iteration 1319 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.47868206502557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.47868206502557), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 309.3567440031639), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 217.14913639031806), ('move_right', 0)]
Reward: 215
Iteration 1320 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 131.7008677141867)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 131.7008677141867)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 370.1979847451789), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 158.35500000000002), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1321 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 209.31078803522365), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 209.31078803522365), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -47.8784607102 [('nothing', 288.3449369882813), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 188.865465)]
Reward: 204
Iteration 1322 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 171.07751089938836)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 171.07751089938836)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 349.15676672096936), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 223.049040824546), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1323 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.68192004830917), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.68192004830917), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 345.96585504240176), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 161.835)]
Reward: 215
Iteration 1324 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.54110704770477)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.54110704770477)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 356.32444895204236), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 220.6343285771822), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1325 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.59460862244092), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.59460862244092), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 2.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 257.3686357635255), ('move_right', -27.759)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.85275141407135)]
Reward: 204
Iteration 1326 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.60361769491004)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 258.3643388353216)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 366.84742620475186)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.64403000402754), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1327 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 74.05560720770976), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 74.05560720770976), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 190.60021291439938)]
best: move_right current state : (0, 1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 178.62534)]
Reward: 142
Iteration 1328 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.8666361666084), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.8666361666084), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 335.72659852968127), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.80362536789147), ('move_right', 0)]
Reward: 215
Iteration 1329 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 279.7367731220546)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 279.7367731220546)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 351.6450893216253), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 234.3508210028193), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1330 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 221.46444427737237), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 221.46444427737237), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.2761065781757), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.1512282343532), ('move_right', 0)]
Reward: 215
Iteration 1331 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.6318340370335)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.6318340370335)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 361.4568088259835), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.90459160327725)]
Reward: 215
Iteration 1332 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.04776236945548), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.04776236945548), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 326.69446171931014), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.50585976404724), ('move_right', 0)]
Reward: 215
Iteration 1333 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 265.9457297688778)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 265.9457297688778)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.6174128395843), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 228.5455747019735), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1334 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.581591576254), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.581591576254), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -15.7875285356 [('nothing', 0), ('move_left', 359.3984123987821), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 211.66866523345453), ('move_right', 0)]
best: nothing current state : (2, 3, 5) 200 [('nothing', 0), ('move_right', 0)]
Reward: 215
Iteration 1335 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 216.41914587556062)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 216.41914587556062)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 365.99586139830103), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 224.48190229138146), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1336 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.59037926233572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.59037926233572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.43864307502895), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.8593433219343), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1337 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 265.3870540919319)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 265.3870540919319)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 366.48640734453454)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 252.17397847912548)]
Reward: 278
Iteration 1338 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 80.05880832155876), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 80.05880832155876), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -17) -26.5339353272 [('nothing', 214.75359614312075), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 196.1407687716), ('move_right', 0)]
Reward: 226
Iteration 1339 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 179.1950611747602)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 179.1950611747602)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 332.5602777481892), ('move_right', -20.37)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 172.87458992435035), ('move_right', 0)]
best: move_left current state : (0, -2, 2) 150 [('nothing', 0), ('move_left', 51.0), ('move_right', 0)]
Reward: 34
Iteration 1340 Learning Q-Table
best: move_left current state : (0, 1.5, -23) -100.0 [('nothing', -45.8590614639144), ('move_left', -25.736258560676706), ('move_right', -33.228436693388375)]
best: move_left current state : (0, 1.5, -23) -100.0 [('nothing', -45.8590614639144), ('move_left', -25.736258560676706), ('move_right', -33.228436693388375)]
best: nothing current state : (2, 3, -17) -37.241639747 [('nothing', 9.58096994512246), ('move_right', 0)]
best: nothing current state : (2, 2, -8) -2.51953643687 [('nothing', 107.359356), ('move_right', 0)]
Reward: 97
Iteration 1341 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.11966860828673)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.11966860828673)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.69114365917164), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 172.04850000000002), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1342 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.38467780798578), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.38467780798578), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 362.76485314910053), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.86253775752402), ('move_right', 0)]
Reward: 204
Iteration 1343 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.41861919945617)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.41861919945617)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 368.54167366622517), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 181.31221294704525), ('move_right', 0)]
Reward: 215
Iteration 1344 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.62623848622417), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.62623848622417), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 344.4497065811443), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.89692598984993)]
Reward: 215
Iteration 1345 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.88304361539085)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.88304361539085)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 326.83609943755124), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 259.92178493538785)]
Reward: 215
Iteration 1346 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.00078699060418), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.00078699060418), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 336.5378811327313), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.15410183483306), ('move_right', 0)]
Reward: 215
Iteration 1347 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 266.7566794695548)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 266.7566794695548)]
best: move_right current state : (1, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 289.8781457639967)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 246.4452494547715)]
Reward: 278
Iteration 1348 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 91.50706406986946), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 91.50706406986946), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 343.92274734336183), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 278.91130740087635), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1349 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.40542214899097)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.40542214899097)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 351.7618050869022), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.63733160396703), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1350 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.38942330914628), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.38942330914628), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 347.283872403756), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 207.22784819289495)]
Reward: 215
Iteration 1351 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.5487988173163)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.5487988173163)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 349.09835056142015), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.73321412229407)]
best: move_right current state : (0, -4, 2) 200 [('nothing', 0), ('move_left', 0), ('move_right', 109.65)]
Reward: 288
Iteration 1352 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 138.27158845375928), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 138.27158845375928), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 369.41931536061617), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 281.93791518061346), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1353 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.04117241645145)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 236.04117241645145)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 377.1926786849118)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 198.26555650817056)]
Reward: 289
Iteration 1354 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 175.4434146017203), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 175.4434146017203), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -47.8784607102 [('nothing', 0), ('move_left', 388.1748953066153), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 237.38078038153992), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1355 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.65036573631284)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.65036573631284)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.3728354504712), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.64613212277692), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1356 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.8975774393713), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 197.65749450809295), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 350.26706514049766), ('move_right', 0)]
best: move_left current state : (1, 3, -6) 150 [('nothing', 0), ('move_left', 151.72860000000003), ('move_right', 0)]
Reward: 226
Iteration 1357 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.10692605240246)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.10692605240246)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 357.7244630420216), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 255.91167461834004)]
Reward: 215
Iteration 1358 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 200.7255525599878), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 200.7255525599878), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 335.70552559834834), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 173.58840249258452)]
Reward: 215
Iteration 1359 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 244.73293875972948)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 244.73293875972948)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 368.51454203188945)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 243.63817223283803)]
Reward: 278
Iteration 1360 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 139.42688797252293), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 139.42688797252293), ('move_right', -53.7146573472915)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 232.00775104007957)]
best: move_right current state : (0, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 86.7)]
Reward: 152
Iteration 1361 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.85600625844796), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.85600625844796), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 332.0703886666192), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 211.6037764302668), ('move_right', 0)]
Reward: 215
Iteration 1362 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.7196952251922)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.7196952251922)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.0548244521629), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.25229248594385), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1363 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 211.5478290568033), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 211.5478290568033), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.39415853162757), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.30787128438314), ('move_right', 0)]
Reward: 215
Iteration 1364 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 249.69492781728144)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 249.69492781728144)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.21406486229716), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 253.94672056298663)]
Reward: 215
Iteration 1365 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.1415473010927), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.1415473010927), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 387.9366608290927), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 216.50439547322264), ('move_right', 0)]
Reward: 215
Iteration 1366 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.9600533951255)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.9600533951255)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 375.433861572504), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 225.48588955571938)]
Reward: 226
Iteration 1367 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 232.26787377371832), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 232.26787377371832), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -37.241639747 [('nothing', 303.50109539179687), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -7) 150 [('nothing', 112.296), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1368 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.5420152501812)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.5420152501812)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 352.5888096296823), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 225.64012268900356)]
Reward: 215
Iteration 1369 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.90758943539666), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.90758943539666), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.06827235745425), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 183.2865393717552)]
Reward: 226
Iteration 1370 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 254.79048833262826)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 254.79048833262826)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 319.6066641878433), ('move_right', -4.736258560676714)]
best: move_right current state : (0, -2.0, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 242.26270439409063)]
Reward: 142
Iteration 1371 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 196.244445548631)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 196.244445548631)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 290.9999449705771)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 191.41854906293167), ('move_right', 0)]
Reward: 278
Iteration 1372 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 106.75247233280618), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 106.75247233280618), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -0.5, -19) -26.5339353272 [('nothing', 190.91065499999996), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 134.304), ('move_right', 0)]
Reward: 226
Iteration 1373 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.69561371385603), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.69561371385603), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 349.66114484972195), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 209.55949373502648)]
Reward: 205
Iteration 1374 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.2958729658736)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.2958729658736)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.5042035474787), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 252.49545280452)]
Reward: 226
Iteration 1375 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.21278113051977), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.21278113051977), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 340.93040499571345), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 216.05307683125585), ('move_right', 0)]
Reward: 226
Iteration 1376 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 245.27516049103488)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 245.27516049103488)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 376.05163109217403)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.18389307586344)]
Reward: 289
Iteration 1377 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 203.89932060014078), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 203.89932060014078), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 233.4154257280557)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 284.0565406264294), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1378 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 221.46534833504586), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 221.46534833504586), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.13375246174456), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.1155098990682), ('move_right', 0)]
Reward: 215
Iteration 1379 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.5858802162591)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.5858802162591)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 375.4494699674686), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 240.40824988560584)]
Reward: 226
Iteration 1380 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.85557636598185), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.85557636598185), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.8282796929417), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.10057756022863)]
Reward: 226
Iteration 1381 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.47246521752595)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.47246521752595)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 379.93710394290974), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.2766047401607), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1382 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 232.30568897489758), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 232.30568897489758), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 348.4672065463762), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.68085692934773), ('move_right', 0)]
Reward: 215
Iteration 1383 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 252.3356097472806)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 252.3356097472806)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 371.89130968728085)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.5936233181125), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1384 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 183.79397154035738), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 183.79397154035738), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 293.6077601975678)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 172.66130690320807), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1385 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 8.596906763798213), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 8.596906763798213), ('move_right', 0)]
best: move_left current state : (0, 2, -19) -37.241639747 [('nothing', 0), ('move_left', 286.3138704586893), ('move_right', -27.759)]
best: nothing current state : (2, 4, -10) 150 [('nothing', 0), ('move_right', 0)]
Reward: 215
Iteration 1386 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -51.48092494502511)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -51.48092494502511)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 190.28123885696246), ('move_right', -11.172491924096027)]
best: move_left current state : (0, -1.25, -9) 150 [('nothing', 0), ('move_left', 105.87), ('move_right', 0)]
Reward: 142
Iteration 1387 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 80.14605732794351)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 80.14605732794351)]
best: move_left current state : (0, 1.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 109.64041427873529), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 236.0857749199241)]
Reward: 152
Iteration 1388 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 59.739503948169514), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 59.739503948169514), ('move_right', 0)]
best: move_left current state : (0, 2, -20) -26.5339353272 [('nothing', 0), ('move_left', 76.5), ('move_right', 0)]
best: nothing current state : (1, 3, -7) 150 [('nothing', 143.1072), ('move_left', 0), ('move_right', 0)]
Reward: 216
Iteration 1389 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -7.912456402586727)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -7.912456402586727)]
best: move_right current state : (1, 2, -20) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 45.0)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 113.283), ('move_right', 0)]
Reward: 289
Iteration 1390 Learning Q-Table
best: nothing current state : (0, 0.75, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 353.03130166126766), ('move_right', 0)]
best: nothing current state : (0, 2, -8) -26.5339353272 [('nothing', 244.43957843850058), ('move_left', 0), ('move_right', 0)]
Reward: 181
Iteration 1391 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 60.03418381502315)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 60.03418381502315)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 306.12552619828347)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 235.2287251531044)]
Reward: 289
Iteration 1392 Learning Q-Table
best: nothing current state : (-2, -1.75, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -1.75, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -1.25, -20) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -0.25, -9) -100.0 [('nothing', 0), ('move_left', -60.0)]
Reward: -300
Iteration 1393 Learning Q-Table
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -51.0), ('move_left', 0)]
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -51.0), ('move_left', 0)]
best: move_left current state : (-1, -0.5, -20) -58.3854585078 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 252.86654626707795), ('move_left', 0), ('move_right', 0)]
Reward: 267
Iteration 1394 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 71.40171257348453)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 71.40171257348453)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 279.7588685056147), ('move_right', 0)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 60.0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -2, 2) 150 [('nothing', 0), ('move_left', 45.9), ('move_right', 0)]
Reward: 108
Iteration 1395 Learning Q-Table
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', -23.17821119859256), ('move_right', -30.0)]
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', -23.17821119859256), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -47.8784607102 [('nothing', 90.58949999999999), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 257.1065823869546), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1396 Learning Q-Table
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', -18.309326113902628)]
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', -18.309326113902628)]
best: move_left current state : (0, 2, -20) -26.5339353272 [('nothing', 0), ('move_left', 141.48216000000002), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 106.35)]
Reward: 142
Iteration 1397 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 101.73636742902755)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 101.73636742902755)]
best: move_right current state : (0, 0.75, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 60.19324491528718)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 104.03999999999999), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 289
Iteration 1398 Learning Q-Table
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -51.0), ('move_left', -38.51563755233668)]
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -51.0), ('move_left', -38.51563755233668)]
best: nothing current state : (-1, -0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 241.1746076708682), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1399 Learning Q-Table
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', -24.411436052062804), ('move_right', -30.0)]
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', -24.411436052062804), ('move_right', -30.0)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 245.4197093210825), ('move_right', -27.759)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.07040429216005)]
Reward: 254
Iteration 1400 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -20.998900079968596)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -20.998900079968596)]
best: move_right current state : (1, 2, -20) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 110.4849)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 159.528), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 289
Iteration 1401 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 75.90939049838029), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 75.90939049838029), ('move_right', 0)]
best: move_left current state : (0, 1.75, -20) -26.5339353272 [('nothing', 0), ('move_left', 172.67930690563395), ('move_right', 0)]
best: move_right current state : (0, 2, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1402 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -10.513940654135908)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', -10.513940654135908)]
best: move_right current state : (1, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 170.19783)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 165.9981), ('move_right', 0)]
Reward: 278
Iteration 1403 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 75.98018482239848), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 75.98018482239848), ('move_right', 0)]
best: move_left current state : (0, 1.75, -20) -47.8784607102 [('nothing', 0), ('move_left', 165.87551483394375), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 225.4077049069504), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1404 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 11.527098618008836)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 11.527098618008836)]
best: move_right current state : (1, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 213.937911)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 183.88736194134765), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1405 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 67.58524561281405), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 67.58524561281405), ('move_right', 0)]
best: move_left current state : (0, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 175.94251200000002), ('move_right', 0)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 149.526)]
Reward: 289
Iteration 1406 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 40.07785040851016)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 40.07785040851016)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 209.95786719987373), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 238.31553632267875), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1407 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 104.90140593184336)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 104.90140593184336)]
best: move_left current state : (0, 1.5, -19) -37.241639747 [('nothing', 0), ('move_left', 192.57402247109195), ('move_right', 0)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 100.77000000000001), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1408 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 35.80747216556076), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 35.80747216556076), ('move_right', 0)]
best: move_left current state : (0, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 213.0175584), ('move_right', 0)]
best: move_left current state : (1, 3, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 216
Iteration 1409 Learning Q-Table
best: nothing current state : (2, 4, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -19) -100.0 [('nothing', 0), ('move_right', -18.206399346916342)]
best: move_right current state : (2, 1.25, -8) -100.0 [('nothing', -75.0), ('move_right', -30.0)]
Reward: -300
Iteration 1410 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 0)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 0)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 263.46516793671526), ('move_right', -11.172491924096027)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 217.39298434405217), ('move_right', 0)]
Reward: 142
Iteration 1411 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 32.13282154646273)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 32.13282154646273)]
best: move_right current state : (0, 1.5, -21) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.86004244394687)]
Reward: 289
Iteration 1412 Learning Q-Table
best: nothing current state : (-1, -1.0, -25) -100.0 [('nothing', 5.539819401842102), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (-1, -1.0, -25) -100.0 [('nothing', 5.539819401842102), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (-1, -0.5, -21) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, 0.25, -9) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 62
Iteration 1413 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 67.91993360487382), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 67.91993360487382), ('move_right', 0)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 194.64357318295728), ('move_left', -11.172491924096027), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 233.32222536960774), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1414 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 99.03069896952191)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 99.03069896952191)]
best: move_right current state : (0, 1.5, -20) -37.241639747 [('nothing', -1.9356898321665312), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 116.13900000000001), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1415 Learning Q-Table
best: move_right current state : (-1, -1.0, -25) -100.0 [('nothing', -47.12212641871052), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (-1, -1.0, -25) -100.0 [('nothing', -47.12212641871052), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (-2, -1.5, -19) -62.0595487579 [('nothing', -3.994010338520173), ('move_left', 0)]
best: nothing current state : (-2, -0.5, -9) -62.0595487579 [('nothing', 0), ('move_left', 0)]
Reward: -150
Iteration 1416 Learning Q-Table
best: move_left current state : (0, -0.0, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.0, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 258.8312079539303), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 205.09853814011998), ('move_right', 0)]
Reward: 289
Iteration 1417 Learning Q-Table
best: move_left current state : (1, 4, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 4, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -19) -58.3854585078 [('nothing', -39.0), ('move_right', -18.206399346916342)]
best: move_right current state : (2, 1.75, -9) -58.3854585078 [('nothing', -90.0), ('move_right', 43.8)]
Reward: -250
Iteration 1418 Learning Q-Table
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', 0.6679391221102691)]
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', 0.6679391221102691)]
best: move_left current state : (0, 2, -20) -47.5651126246 [('nothing', 0), ('move_left', 194.11229088000002), ('move_right', 0)]
best: move_left current state : (0, -1.0, -9) 150 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 142
Iteration 1419 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 94.78614216959394)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 94.78614216959394)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 353.60996905312777), ('move_right', 0)]
best: move_right current state : (0, -2.0, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 251.36010760717306)]
Reward: 152
Iteration 1420 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 76.97684488014096), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 76.97684488014096), ('move_right', 0)]
best: move_right current state : (0, 1.5, -20) -37.241639747 [('nothing', -1.9356898321665312), ('move_left', 0), ('move_right', 79.8417)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 191.3682)]
Reward: 142
Iteration 1421 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 53.90989246185744)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 53.90989246185744)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 287.7114070097872), ('move_right', 0)]
best: nothing current state : (0, -2.0, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1422 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 37.62287941010826), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 37.62287941010826), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -19) -100.0 [('nothing', 0), ('move_left', 113.92702786746281), ('move_right', -30.0)]
best: move_right current state : (0, -0.0, -9) -100.0 [('nothing', -90.0), ('move_left', -90.0), ('move_right', -45.0)]
Reward: -300
Iteration 1423 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 140.26079831055807)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 140.26079831055807)]
best: move_right current state : (0, 0.5, -18) -37.6443745166 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 302.3238242092599)]
best: move_left current state : (0, -1.75, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1424 Learning Q-Table
best: move_left current state : (-2, -1.75, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -1.75, -24) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_right current state : (-1, -0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 45.0)]
best: nothing current state : (0, 2, -9) 100 [('nothing', 227.8255577587254), ('move_left', 0), ('move_right', 0)]
Reward: 23
Iteration 1425 Learning Q-Table
best: nothing current state : (-2, -1.75, -25) -100.0 [('nothing', -51.0), ('move_left', -55.921126884793566)]
best: nothing current state : (-2, -1.75, -25) -100.0 [('nothing', -51.0), ('move_left', -55.921126884793566)]
best: nothing current state : (-2, -1.25, -19) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -0.25, -9) -100.0 [('nothing', -90.0), ('move_left', -60.0)]
Reward: -250
Iteration 1426 Learning Q-Table
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -55.921126884793566)]
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -55.921126884793566)]
best: move_left current state : (-1, -0.25, -20) -47.8784607102 [('nothing', 0), ('move_left', 37.739999999999995), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 166.3778904311078), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1427 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 156.58639372517868)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 156.58639372517868)]
best: move_right current state : (0, 0.75, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 118.34727144070102)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 194.77508904083652), ('move_right', 0)]
Reward: 278
Iteration 1428 Learning Q-Table
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -63.1863270324035)]
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -63.1863270324035)]
best: move_left current state : (-1, -0.25, -20) -37.241639747 [('nothing', 0), ('move_left', 121.33136712933234), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 203.16452330177546), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 4, 3) 250 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 323
Iteration 1429 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 91.87785490214034)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 91.87785490214034)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 352.6306495153133), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 198.3696), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 215
Iteration 1430 Learning Q-Table
best: move_left current state : (0, -0.0, -25) -100.0 [('nothing', 0), ('move_left', 45.476870462083056), ('move_right', 0)]
best: move_left current state : (0, -0.0, -25) -100.0 [('nothing', 0), ('move_left', 45.476870462083056), ('move_right', 0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 312.4936040962796), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 217.21516631124283), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1431 Learning Q-Table
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', 23.43171086210281)]
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', 23.43171086210281)]
best: move_left current state : (0, 2.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 278.3149178124058), ('move_right', -27.759)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 181.63395000000003), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -4, 2) 150 [('nothing', 0), ('move_left', 0), ('move_right', 163.155)]
Reward: 108
Iteration 1432 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 141.14351268793433)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 141.14351268793433)]
best: move_right current state : (0, 0.5, -18) -37.241639747 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 256.62667694648195)]
best: move_left current state : (0, -1.75, -7) 150 [('nothing', 0), ('move_left', 83.39999999999999), ('move_right', 0)]
Reward: 267
Iteration 1433 Learning Q-Table
best: nothing current state : (-2, -1.75, -24) -100.0 [('nothing', 2.3275080759039795), ('move_left', -30.0)]
best: nothing current state : (-2, -1.75, -24) -100.0 [('nothing', 2.3275080759039795), ('move_left', -30.0)]
best: move_left current state : (-2, -1.25, -19) -100.0 [('nothing', -48.0), ('move_left', 0)]
best: nothing current state : (-2, -0.25, -9) -100.0 [('nothing', -90.0), ('move_left', -117.0)]
Reward: -100
Iteration 1434 Learning Q-Table
best: move_left current state : (0, -0.0, -25) -100.0 [('nothing', 0), ('move_left', 96.62170995418413), ('move_right', 0)]
best: move_left current state : (0, -0.0, -25) -100.0 [('nothing', 0), ('move_left', 96.62170995418413), ('move_right', 0)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 251.2471688389524), ('move_left', -11.172491924096027), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 235.45061641786998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1435 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 143.6159700414026)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 143.6159700414026)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 36.248919507223974), ('move_right', -30.0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 234.3020297107628)]
Reward: 142
Iteration 1436 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 56.79800611179651), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 56.79800611179651), ('move_right', 0)]
best: move_left current state : (0, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 200.22860361600002), ('move_right', 0)]
best: move_right current state : (0, 2, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 86.7)]
Reward: 246
Iteration 1437 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 58.869363521823225)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 58.869363521823225)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 294.6435128589163), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 203.35872), ('move_left', 0), ('move_right', -26.285999999999973)]
best: nothing current state : (0, -4, 4) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 108
Iteration 1438 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', -9.679516841572116)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', -9.679516841572116)]
best: move_left current state : (0, 1.5, -19) -37.241639747 [('nothing', 0), ('move_left', 210.03281572976437), ('move_right', 0)]
best: move_left current state : (0, -0.75, -9) 150 [('nothing', -90.0), ('move_left', 22.406294741519055), ('move_right', -54.3)]
Reward: 142
Iteration 1439 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 67.65469343896154), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 67.65469343896154), ('move_right', 0)]
best: move_left current state : (0, 2, -19) -37.241639747 [('nothing', 0), ('move_left', 294.31062746868406), ('move_right', -27.759)]
best: nothing current state : (2, 4, -9) 150 [('nothing', 106.35), ('move_right', 0)]
best: nothing current state : (2, 3, 3) 200 [('nothing', 0), ('move_right', 0)]
Reward: 205
Iteration 1440 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 50.07936978285669)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 50.07936978285669)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 312.2580750012414), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 187.351104), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 152
Iteration 1441 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 24.061691005732797)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 24.061691005732797)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 76.95), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 176.7457728), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 215
Iteration 1442 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 45.66380949200264), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 45.66380949200264), ('move_right', 0)]
best: move_left current state : (0, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 228.73517185584575), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 229.315431492509), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1443 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 100.64142772479326)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 100.64142772479326)]
best: move_right current state : (1, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 249.92274628240432)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 199.59867), ('move_right', 0)]
best: move_left current state : (0, -6, 2) 250 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 250
Iteration 1444 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 14.649388501991204), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 14.649388501991204), ('move_right', 0)]
best: move_left current state : (0, 2, -19) -37.241639747 [('nothing', 0), ('move_left', 282.9224392280789), ('move_right', -27.759)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.74928300451202)]
Reward: 216
Iteration 1445 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 113.25333136798056)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 113.25333136798056)]
best: nothing current state : (1, 3, -20) -47.8784607102 [('nothing', 45.0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -5, 3) 200 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1446 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 9.514123947314626), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 9.514123947314626), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -19) -100.0 [('nothing', 351.3523346607193), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.75, -7) -100.0 [('nothing', 0), ('move_left', 18.599999999999998), ('move_right', -45.0)]
Reward: -300
Iteration 1447 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 68.41272627705956), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 68.41272627705956), ('move_right', 0)]
best: nothing current state : (0, 1.75, -21) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 134.49)]
best: nothing current state : (0, 3, 2) 200 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1448 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 62.95881179572148), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 62.95881179572148), ('move_right', 0)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 308.97049236100884), ('move_right', -27.759)]
best: nothing current state : (2, 4, -9) 150 [('nothing', 134.445), ('move_right', 0)]
Reward: 209
Iteration 1449 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 99.7728007502142)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 99.7728007502142)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 319.785983700869), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 209.42087542587512), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1450 Learning Q-Table
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 10.968003105855061)]
best: move_right current state : (0, 3, -25) -100.0 [('nothing', -51.0), ('move_left', -49.232307016868425), ('move_right', 10.968003105855061)]
best: move_right current state : (0, 1.5, -20) -26.5339353272 [('nothing', -1.9356898321665312), ('move_left', 0), ('move_right', 158.29964999999999)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 164.6973), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1451 Learning Q-Table
best: move_left current state : (-1, -1.0, -25) -100.0 [('nothing', -47.12212641871052), ('move_left', -30.0), ('move_right', -39.617864627356184)]
best: move_left current state : (-1, -1.0, -25) -100.0 [('nothing', -47.12212641871052), ('move_left', -30.0), ('move_right', -39.617864627356184)]
best: move_right current state : (0, 0.5, -20) -26.5339353272 [('nothing', -13.71), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 176.55774)]
Reward: 142
Iteration 1452 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 15.716416469845669), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 15.716416469845669), ('move_right', 0)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 291.50820311262765), ('move_left', -11.172491924096027), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 154.03109999999998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1453 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 37.14899735456932)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 37.14899735456932)]
best: move_left current state : (0, 1.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 198.74485943329077), ('move_right', 0)]
best: move_right current state : (0, -1.25, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1454 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 107.80213536714979), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 107.80213536714979), ('move_right', 0)]
best: move_left current state : (0, 2, -19) -37.241639747 [('nothing', 0), ('move_left', 301.6128446527062), ('move_right', -27.759)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.601540325354), ('move_left', 0), ('move_right', 0)]
Reward: 216
Iteration 1455 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 57.41379374453839)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 57.41379374453839)]
best: move_right current state : (1, 2, -20) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 279.825523397683)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 124.19999999999999)]
best: move_left current state : (0, -6, 2) 250 [('nothing', 0), ('move_left', 75.0), ('move_right', 0)]
Reward: 397
Iteration 1456 Learning Q-Table
best: move_right current state : (-1, -1.0, -25) -100.0 [('nothing', -47.12212641871052), ('move_left', -49.9601805981579), ('move_right', -39.617864627356184)]
best: move_right current state : (-1, -1.0, -25) -100.0 [('nothing', -47.12212641871052), ('move_left', -49.9601805981579), ('move_right', -39.617864627356184)]
best: nothing current state : (-2, -1.5, -20) -61.3741781674 [('nothing', 0), ('move_left', 0)]
best: nothing current state : (-2, -1.0, -10) -61.3741781674 [('nothing', 0), ('move_left', 0)]
Reward: 38
Iteration 1457 Learning Q-Table
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -40.00351070797875)]
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -40.00351070797875)]
best: nothing current state : (-1, -0.5, -21) -37.241639747 [('nothing', 0), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 243.9208020447563), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1458 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 133.77285622872068), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 133.77285622872068), ('move_right', 0)]
best: nothing current state : (0, 1.25, -19) -47.8784607102 [('nothing', 151.88873184), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 172.32177), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1459 Learning Q-Table
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', 70.9364923490358)]
best: move_right current state : (1, 4, -25) -100.0 [('nothing', -25.34063079854917), ('move_left', -30.0), ('move_right', 70.9364923490358)]
best: move_left current state : (0, 2, -20) -47.8784607102 [('nothing', 0), ('move_left', 211.1700225312), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 221.09026500000002), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -4, 2) 150 [('nothing', 0), ('move_left', 0), ('move_right', 146.6085)]
Reward: 108
Iteration 1460 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 82.4456742829911)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 82.4456742829911)]
best: move_right current state : (0, 0.75, -20) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 186.27561672074165)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 219.74256232858556), ('move_right', 0)]
Reward: 289
Iteration 1461 Learning Q-Table
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -60.17494941968114)]
best: move_left current state : (-2, -1.75, -25) -100.0 [('nothing', -86.7), ('move_left', -60.17494941968114)]
best: move_left current state : (-1, -0.25, -20) -37.241639747 [('nothing', 0), ('move_left', 190.88131398106526), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 235.2445614313294), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1462 Learning Q-Table
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 84.63447641615838)]
best: move_right current state : (0, 2, -25) -100.0 [('nothing', -58.5), ('move_left', -49.9601805981579), ('move_right', 84.63447641615838)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 221.5266342625035), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 221.55207532502115)]
Reward: 215
Iteration 1463 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.7872067659119), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.7872067659119), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 328.91007276076857), ('move_right', 0)]
best: nothing current state : (0, 3, -6) 150 [('nothing', 169.2237), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1464 Learning Q-Table
best: move_left current state : (1, 3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -20) -61.3741762696 [('nothing', 0), ('move_right', -19.65085448425526)]
best: nothing current state : (2, 1.75, -8) -61.3741762696 [('nothing', 0), ('move_right', -15.0)]
Reward: -50
Iteration 1465 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 95.17713204232388)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 95.17713204232388)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 331.67645121837086), ('move_right', -11.172491924096027)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 240.5197936300099), ('move_right', 0)]
Reward: 152
Iteration 1466 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 56.667575380027856)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 56.667575380027856)]
best: move_left current state : (0, 1.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 184.12140160330353), ('move_right', 0)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 201.98811), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1467 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 103.47898172378227), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 103.47898172378227), ('move_right', 0)]
best: move_left current state : (0, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 259.14609527184), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.7210782277478), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, 3) 200 [('nothing', 61.5), ('move_right', 0)]
Reward: 216
Iteration 1468 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 133.95443587104194)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 133.95443587104194)]
best: move_right current state : (1, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 278.13786637837813)]
best: move_right current state : (0, -1.25, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -5, 2) 250 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 397
Iteration 1469 Learning Q-Table
best: move_left current state : (-1, -0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -0.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 140.66485256828562), ('move_right', -30.0)]
best: nothing current state : (0, 2, -7) 100 [('nothing', 166.46291483224564), ('move_left', 0), ('move_right', 0)]
Reward: 170
Iteration 1470 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 118.00662386410357), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 118.00662386410357), ('move_right', 0)]
best: move_right current state : (0, 2, -21) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -10) 150 [('nothing', 0), ('move_left', 63.3), ('move_right', 0)]
Reward: 142
Iteration 1471 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 65.94354264885266)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 65.94354264885266)]
best: move_right current state : (0, 1.25, -18) -37.241639747 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 246.34688874601443)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 188.22204096), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 278
Iteration 1472 Learning Q-Table
best: nothing current state : (-1, -0.75, -24) -100.0 [('nothing', 34.23927517232779), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (-1, -0.75, -24) -100.0 [('nothing', 34.23927517232779), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (-1, -0.5, -19) -100.0 [('nothing', 0), ('move_left', 51.0), ('move_right', 0)]
best: nothing current state : (-1, 0.25, -9) -100.0 [('nothing', 18.599999999999998), ('move_left', 0), ('move_right', 0)]
Reward: -50
Iteration 1473 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 61.06558716133604), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 61.06558716133604), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 1.0, -19) -100.0 [('nothing', 0), ('move_left', 326.004160932538), ('move_right', 0)]
best: move_left current state : (0, 1.0, -8) -100.0 [('nothing', -90.0), ('move_left', 39.54), ('move_right', -29.67)]
Reward: -50
Iteration 1474 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 50.432144780776476), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 50.432144780776476), ('move_right', 0)]
best: move_right current state : (0, 2, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 252.9325520002823)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 212.62264350118676), ('move_right', 0)]
Reward: 142
Iteration 1475 Learning Q-Table
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 87.89205455390515)]
best: move_right current state : (0, 3, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', 87.89205455390515)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 329.85648588472975)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.61142079753398)]
Reward: 278
Iteration 1476 Learning Q-Table
best: move_left current state : (-2, -1.75, -24) -100.0 [('nothing', -49.37074434686721), ('move_left', -30.0)]
best: move_left current state : (-2, -1.75, -24) -100.0 [('nothing', -49.37074434686721), ('move_left', -30.0)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 249.65867386253737)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 166.190418)]
Reward: 163
Iteration 1477 Learning Q-Table
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 69.49377186452236), ('move_right', 0)]
best: move_left current state : (0, 0.75, -25) -100.0 [('nothing', -30.0), ('move_left', 69.49377186452236), ('move_right', 0)]
best: move_right current state : (0, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 285.83957945055363)]
best: nothing current state : (0, 3, -6) 150 [('nothing', 205.15659), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 1478 Learning Q-Table
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 82.22208634847033), ('move_right', 0)]
best: move_left current state : (0, 1.5, -25) -100.0 [('nothing', -30.0), ('move_left', 82.22208634847033), ('move_right', 0)]
best: move_left current state : (0, 3, -20) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 206.576660279877)]
Reward: 202
Iteration 1479 Learning Q-Table
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 145.0369730991468)]
best: move_right current state : (2, 4, -25) -100.0 [('nothing', -86.7), ('move_right', 145.0369730991468)]
best: move_right current state : (1, 2, -20) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 239.69650646486468)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 186.991677), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1480 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 89.54715929269662), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 89.54715929269662), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.75, -18) -100.0 [('nothing', 0), ('move_left', 381.5069812223317), ('move_right', 0)]
best: move_left current state : (0, 0.75, -6) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -100
Loading mission from ghast_survival_mission.xml
Iteration 1482 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 231.79060603329316), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 231.79060603329316), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -16) -26.5339353272 [('nothing', 119.727), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 193.4058255)]
Reward: 208
Iteration 1483 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 256.02982780518465)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 256.02982780518465)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 370.30200377653034)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.5864527275148)]
Reward: 278
Iteration 1484 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 187.77792753936262), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 187.77792753936262), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 237.05488685563222), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 244.4853934348653), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1485 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.0516762369832)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.0516762369832)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 372.4015783245911), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 228.02799455827378)]
Reward: 204
Iteration 1486 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.65157464027286), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.65157464027286), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 284.2840388294021), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 205.2036621959139)]
Reward: 204
Iteration 1487 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.3512999984305)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.3512999984305)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 376.138954182085), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 189.1946127981126), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1488 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 221.5688219729156), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 221.5688219729156), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 2, -17) -15.7875285356 [('nothing', 298.33730631799085), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 191.43585045083074), ('move_right', 0)]
Reward: 215
Iteration 1489 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.18415493916956)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.18415493916956)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.0556517668933), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 196.9362289586788), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1490 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 169.21134362514732), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 169.21134362514732), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 367.93501061934137), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 208.16806566341816), ('move_right', 0)]
Reward: 215
Iteration 1491 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.58542338932875)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.58542338932875)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 374.0895031946959), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 202.35536027107517), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1492 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.86310871576146), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.86310871576146), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 365.0049271325644), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.0765998505434), ('move_right', 0)]
Reward: 215
Iteration 1493 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.3641554068429)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 266.82741565536895)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.61982492442894), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 206.14875218975263), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1494 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 199.86826312524764), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 199.86826312524764), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 291.1395667742578), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -6) 150 [('nothing', 0), ('move_left', 174.01002000000003), ('move_right', 0)]
Reward: 215
Iteration 1495 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.2031334814007)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.2031334814007)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 358.578503104026), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 222.4480858823025)]
Reward: 215
Iteration 1496 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 198.28947362179278), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 198.28947362179278), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 210.06491265277663), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 219.03715378187908), ('move_right', 0)]
Reward: 226
Iteration 1497 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.6555637700304)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.6555637700304)]
best: move_right current state : (1, 1.0, -17) -15.7875285356 [('nothing', -14.363538213047999), ('move_left', 0), ('move_right', 199.23317382109312)]
best: nothing current state : (0, -4, -6) 200 [('nothing', 150.69), ('move_left', 0), ('move_right', 0)]
Reward: 310
Iteration 1498 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 67.31097117165719), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 67.31097117165719), ('move_right', -49.9601805981579)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 305.5599258393556), ('move_right', 0)]
best: move_left current state : (0, 2, -5) 150 [('nothing', 0), ('move_left', 126.18), ('move_right', 0)]
Reward: 289
Iteration 1499 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 205.2925882246725)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 205.2925882246725)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.73937793750895), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 237.11051690926035)]
Reward: 215
Iteration 1500 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.74547364264444), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.74547364264444), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 296.7459480875489), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 221.12600764731536), ('move_right', 0)]
Reward: 226
Iteration 1501 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.56644454036552)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.56644454036552)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 367.5692603176097), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.81959619079163)]
Reward: 215
Iteration 1502 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.6854353779579), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.6854353779579), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 319.05996595547884), ('move_right', 0)]
best: move_right current state : (2, 2, -7) 150 [('nothing', 0), ('move_right', 90.40578)]
Reward: 215
Iteration 1503 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.80710867538087)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.80710867538087)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.05071962903435), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.10412653282685), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1504 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.3376139530563), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.3376139530563), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 266.5342665812588), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 222.58820535312074), ('move_right', 0)]
Reward: 215
Iteration 1505 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.520011363319)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.520011363319)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.6667417001721), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.9728885729788), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1506 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.12411781742102), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 204.12411781742102), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.7264289479581), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 186.01188174480916)]
Reward: 215
Iteration 1507 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.30384986621704)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.30384986621704)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.25858576201415), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.58102200108516), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1508 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.34463055842426), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.34463055842426), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.1120647870134), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 198.5050953155815), ('move_right', 0)]
Reward: 215
Iteration 1509 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.63009003679826)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.63009003679826)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 370.0873384618257)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.00671540075962), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1510 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 173.6008347360856), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 173.6008347360856), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 295.4637101688352), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 254.5397754044057), ('move_left', 0), ('move_right', 0)]
Reward: 267
Iteration 1511 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.59477264021046)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.59477264021046)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 365.45531663373544), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 212.12115335894336), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1512 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.21468022884312), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.21468022884312), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 315.99543092134934), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 220.31174374718452), ('move_right', 0)]
Reward: 215
Iteration 1513 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.8804439141719)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.8804439141719)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 368.2631515435059)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 236.50470078053172), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1514 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 181.19951676775258), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 181.19951676775258), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 178.40427124747362), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 251.37119300193058), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1515 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.4350756048142)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.4350756048142)]
best: move_right current state : (1, 1.25, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 321.84827687122913)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 255.5532905463722), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1516 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 148.18845118757287), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 148.18845118757287), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 269.61819710377614)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 258.277842783084), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 1517 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 169.6496134069919), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 169.6496134069919), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 328.18652973950634), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 210.21764596439272), ('move_right', 0)]
Reward: 204
Iteration 1518 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 286.7049578379291)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 286.7049578379291)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 364.45506765129784), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 230.47736183648226)]
Reward: 215
Iteration 1519 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.57641351249896), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.57641351249896), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -17) -15.7875285356 [('nothing', 0), ('move_left', 182.61139677203448), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 204.8425635371397)]
Reward: 215
Iteration 1520 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.22277742406195)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.22277742406195)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 372.18062651491715), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 213.96385554100692), ('move_right', 0)]
Reward: 226
Iteration 1521 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.6506499296829), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.6506499296829), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 257.75658499150734), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 229.45475475942345), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1522 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.3499515531606)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.3499515531606)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 373.73561631461365)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 265.58730338246056), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1523 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 155.65719436427594), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 155.65719436427594), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 245.2943477738107), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 262.6598351013514), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1524 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.1054703834386)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.1054703834386)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 368.5443610795643), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.21366011761177)]
Reward: 226
Iteration 1525 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 176.5099385241342), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 176.5099385241342), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.82997394558384), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 207.8897944759978)]
Reward: 226
Iteration 1526 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.8769569941184)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.8769569941184)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 369.71559522274407), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 272.6111123677224), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1527 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 200.74576855241122), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 200.74576855241122), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 337.79586460697226), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.35361989538038), ('move_right', 0)]
Reward: 215
Iteration 1528 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.2560565386101)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.2560565386101)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 369.2617559068532), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 255.32777865740567), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1529 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 212.90061677062164), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 212.90061677062164), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 345.76319119349466), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.71822062302917), ('move_right', 0)]
Reward: 215
Iteration 1530 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 281.06981018378184)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 281.06981018378184)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 380.08156273201894), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 243.22944506018396), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1531 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.79920849932566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.79920849932566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 294.2660359218822), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.54753392676628), ('move_right', 0)]
Reward: 215
Iteration 1532 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.1975857509251)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.1975857509251)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 385.5842503662376), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 217.57469887870485), ('move_right', 0)]
Reward: 215
Iteration 1533 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 185.0381963826502), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 185.0381963826502), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.64970002235503), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.68327374873638), ('move_right', 0)]
Reward: 215
Iteration 1534 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 278.60084402415697)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 278.60084402415697)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 386.29112243496775)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 234.76061154212877), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1535 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 138.24096629463202), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 138.24096629463202), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 332.2903247690999), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 106.29)]
Reward: 215
Iteration 1536 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 195.71091477705693)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 195.71091477705693)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 343.46465145678263), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 221.94956208232824)]
Reward: 142
Iteration 1537 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 212.76676480199657), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 212.76676480199657), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.25977214026943), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.7083172213664)]
Reward: 216
Iteration 1538 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.45340453736094)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.45340453736094)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 384.0259274304684), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 216.8022892150934), ('move_right', 0)]
Reward: 226
Iteration 1539 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 206.36146687640377), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 206.36146687640377), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 352.7943356645985), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 179.18949899999998), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1540 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 278.3649808071353)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 278.3649808071353)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 378.8588359658559), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 251.03242807949013), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1541 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.85448640532053), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.85448640532053), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 345.71288466521895), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.77829162411547), ('move_right', 0)]
Reward: 215
Iteration 1542 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 279.5529567565936)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 279.5529567565936)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 385.5109135999462), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 240.22269965564308), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1543 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.55182528513217), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.55182528513217), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 355.04792010470806), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.84480413688084), ('move_right', 0)]
Reward: 215
Iteration 1544 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 282.38016321144147)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 282.38016321144147)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 385.8319691671161)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.96469345762978)]
Reward: 300
Iteration 1545 Learning Q-Table
best: move_right current state : (0, -0.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -0.5, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-1, -2, -19) -26.5339353272 [('nothing', 0), ('move_left', 14.520272786567677), ('move_right', 0)]
best: nothing current state : (-2, -2, -7) 100 [('nothing', 103.875), ('move_left', 0)]
Reward: 34
Iteration 1546 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 0), ('move_right', -30.0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 241.3157004030948)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 226.6944899481588), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1547 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.04047313284704), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.04047313284704), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.9869853143599), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 217.60275443612042), ('move_right', 0)]
Reward: 225
Iteration 1548 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 284.45552439998596)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 284.45552439998596)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 177.56212037942066), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 219.56160245056537), ('move_right', 0)]
Reward: 142
Iteration 1549 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 211.07685518281676)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 211.07685518281676)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 337.882966358571)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 225.83415328553758)]
Reward: 289
Iteration 1550 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 103.03974653480643), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 103.03974653480643), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -0.5, -19) -47.8784607102 [('nothing', 218.92865849999995), ('move_left', 0), ('move_right', -30.0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 230.26897669808397), ('move_right', 0)]
Reward: 215
Iteration 1551 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.164246189143), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.164246189143), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 315.3504853233474), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 219.8219281052843), ('move_right', 0)]
Reward: 216
Iteration 1552 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.21501126972035)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.21501126972035)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 369.04515079097854), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 232.65588975895017), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1553 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.44762600530828), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.44762600530828), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 331.6919181579285), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.8913628958166), ('move_right', 0)]
Reward: 215
Iteration 1554 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.9038725279399)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.9038725279399)]
best: move_left current state : (1, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 107.45682622773657), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 227.35912283126513), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1555 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 220.15850793738514)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 220.15850793738514)]
best: move_left current state : (0, -0.75, -19) -15.7875285356 [('nothing', 0), ('move_left', 145.23548312198076), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 201.7513859818856), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 1556 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.36073305293644), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.36073305293644), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 246.39798490685104), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.09582205495647)]
Reward: 227
Iteration 1557 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 165.19726671378288)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 165.19726671378288)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 374.4717864542702)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 187.12597018731992), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1558 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 153.5881597889785), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 153.5881597889785), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 298.3504482128174), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 204.28614296371117), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1559 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 171.9453419320871)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 171.9453419320871)]
best: move_left current state : (0, -0.75, -18) -15.7875285356 [('nothing', 0), ('move_left', 349.3813538787073), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.68817913112395), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 1560 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.4994166850148), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.4994166850148), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 341.6517515792949), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 208.3523521750749), ('move_right', 0)]
Reward: 226
Iteration 1561 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.80713071183305)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.80713071183305)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 380.18138491997775), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 198.28172539178675), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1562 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.08493655514093), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.08493655514093), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 306.63468261538753)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 213.32285613319846)]
Reward: 153
Iteration 1563 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 199.43988695539645)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 199.43988695539645)]
best: move_left current state : (0, 0.25, -19) -47.8784607102 [('nothing', 0), ('move_left', 329.6545714010376), ('move_right', -20.37)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 176.3645997), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1564 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.9136018125382), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 218.9136018125382), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 346.6619317580289), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 208.19164561451854)]
Reward: 204
Iteration 1565 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.15922637611857)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.15922637611857)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 370.61148706152045), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 203.29720777425072), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1566 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.06560887208937), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.06560887208937), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 281.92933726661397)]
best: nothing current state : (1, 1.75, -9) 150 [('nothing', 21.9), ('move_left', 0), ('move_right', 0)]
Reward: -100
Iteration 1567 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 203.14075407604076)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 203.14075407604076)]
best: move_right current state : (0, 0.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 199.88780926343023)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 244.546816963164)]
Reward: 300
Iteration 1568 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 39.59304739457371)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 39.59304739457371)]
best: move_left current state : (0, -0.75, -19) -26.5339353272 [('nothing', 0), ('move_left', 207.19025397995222), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 167.52404038257194), ('move_left', 0), ('move_right', 0)]
Reward: 310
Iteration 1569 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 173.2046900340997)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 173.2046900340997)]
best: move_left current state : (0, 0.25, -20) -47.8784607102 [('nothing', 0), ('move_left', 102.63518504462378), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 206.8080454419755), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1570 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 209.95223546635071), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 209.95223546635071), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 295.2650721788394), ('move_left', -11.172491924096027), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.92395402707163), ('move_right', 0)]
Reward: 199
Iteration 1571 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 234.52241265764312)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 234.52241265764312)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 386.92444941665525), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 244.78390729987632)]
Reward: 215
Iteration 1572 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.58590588193942), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 206.58590588193942), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 350.1208459149758), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.86707543846953)]
Reward: 215
Iteration 1573 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.07053176125072)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.07053176125072)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 235.16196500076407), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 235.84873510991343)]
Reward: 152
Iteration 1574 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 116.67030032420892)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 116.67030032420892)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 328.6675798907263), ('move_right', -20.37)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 196.29312171539576), ('move_right', 0)]
Reward: 142
Iteration 1575 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 220.68620729369243), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 220.68620729369243), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 277.8073360512827), ('move_right', 0)]
best: move_left current state : (1, 2, -7) 150 [('nothing', 0), ('move_left', 146.86499999999998), ('move_right', 0)]
Reward: 216
Iteration 1576 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.0254698090087)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.0254698090087)]
best: move_left current state : (1, 1.5, -20) -26.5339353272 [('nothing', 0), ('move_left', 188.42751520879517), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.07371733355413)]
Reward: 142
Iteration 1577 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 148.09699227006809)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 148.09699227006809)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 333.95524243812713), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 190.36563180938285), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 1578 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.65005399687348), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.65005399687348), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 248.9205360866298)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.14676781895014), ('move_right', 0)]
Reward: 142
Iteration 1579 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 174.8942867223279)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 174.8942867223279)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 295.5039939720729), ('move_right', -30.0)]
best: nothing current state : (0, -1.25, -8) 150 [('nothing', 0.6900000000000119), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1580 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 186.45870669970435), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 186.45870669970435), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 316.1627367333091), ('move_left', -11.172491924096027), ('move_right', 0)]
best: move_right current state : (2, 2, -7) 150 [('nothing', 0), ('move_right', 127.78404599999999)]
Reward: 194
Iteration 1581 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 175.98590283078676)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 175.98590283078676)]
best: nothing current state : (1, 1.5, -19) -15.7875285356 [('nothing', 373.12837248137004), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 117.045)]
Reward: 226
Iteration 1582 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.40973511162787), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 196.40973511162787), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 352.74471477202394), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.70695280692865)]
Reward: 226
Iteration 1583 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 209.39238516528502)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 209.39238516528502)]
best: nothing current state : (1, 1.5, -19) -15.7875285356 [('nothing', 341.303360736959), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 228.57528542034083)]
Reward: 226
Iteration 1584 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 211.13773708565066), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 211.13773708565066), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 283.5246352358979), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 228.41832833159643), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1585 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.2294192761105)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.2294192761105)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 352.48493814197354), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 243.74573550000002), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1586 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 200.6813146066288), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 200.6813146066288), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 311.9927431646075), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 189.7027374732651), ('move_right', 0)]
Reward: 215
Iteration 1587 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.0458943377115)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.0458943377115)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 365.41720327533955), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 195.95160213348788)]
Reward: 215
Iteration 1588 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 115.78204118490721), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 115.78204118490721), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 355.13338618249537), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 195.2259992932389)]
Reward: 215
Iteration 1589 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 136.81657503725273)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 136.81657503725273)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 349.32945394186254), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 172.555942266568), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1590 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 109.75111882678738)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 109.75111882678738)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.8717160508881), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 163.3891595865976), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1591 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 126.13510587158714), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 126.13510587158714), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_right current state : (0, 0.25, -18) -100.0 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 349.268322436661)]
best: move_left current state : (0, -0.25, -8) -100.0 [('nothing', -106.5), ('move_left', -90.0), ('move_right', -142.5)]
Reward: -150
Iteration 1592 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 198.71120496097438), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 198.71120496097438), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 346.62694911160094), ('move_right', 0)]
best: nothing current state : (0, 3, -6) 150 [('nothing', 189.509613), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1593 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 168.39794678453967)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 168.39794678453967)]
best: move_left current state : (1, 2, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 341.29740043927416), ('move_right', -11.172491924096027)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 261.1827718742148)]
Reward: 163
Iteration 1594 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 156.1271173958597)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 156.1271173958597)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 210.27550037382866), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 156.97241171061833), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1595 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 210.9134362820663), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 210.9134362820663), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 203.018643288), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 267.261884570946), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1596 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 143.4114516910925)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 143.4114516910925)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 239.28457377486555), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.6941145769394)]
Reward: 215
Iteration 1597 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 176.37250645975038), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 176.37250645975038), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 1.25, -18) -26.5339353272 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 273.9094344102101)]
best: move_right current state : (0, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 138.90300000000002)]
Reward: 174
Iteration 1598 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 142.0750708411093), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 11.940533111845728), ('move_right', -30.0)]
best: move_right current state : (0, 0.25, -18) -100.0 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 187.4878257056627)]
best: move_left current state : (0, 1.25, -6) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 1599 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 103.84408069905648), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 103.84408069905648), ('move_right', 0)]
best: move_left current state : (0, 2, -19) -37.241639747 [('nothing', 0), ('move_left', 320.80945335450053), ('move_right', -27.759)]
best: nothing current state : (2, 2, -8) 150 [('nothing', 104.2515492), ('move_right', 0)]
Reward: 153
Iteration 1600 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 191.30760228280212)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 191.30760228280212)]
best: move_left current state : (1, 2.0, -19) -26.5339353272 [('nothing', -16.50485056868419), ('move_left', 362.2630118697563), ('move_right', -11.172491924096027)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 174.38068819743285), ('move_left', 0), ('move_right', 0)]
Reward: 163
Iteration 1601 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 143.2132077180665)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 143.2132077180665)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 344.49174827812067), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 170.966481738203), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1602 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 73.03470952233023), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 73.03470952233023), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -17) -100.0 [('nothing', 254.16974793166452), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.25, -6) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 1603 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 76.37522104513052), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 76.37522104513052), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -19) -98.7954412122 [('nothing', 0), ('move_left', 252.05979578045105), ('move_right', -30.0)]
best: nothing current state : (0, 0.0, -9) -98.7954412122 [('nothing', -90.0), ('move_left', -90.0), ('move_right', -121.5)]
Reward: 63
Iteration 1604 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 171.42427796198672)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 171.42427796198672)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 351.4325067528879), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 212.98480735126034), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1605 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 78.44196110206514), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 78.44196110206514), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_right current state : (0, 0.25, -18) -100.0 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 120.06898606986786)]
best: nothing current state : (0, -0.25, -9) -100.0 [('nothing', -75.0), ('move_left', -106.5), ('move_right', -90.0)]
Reward: -250
Iteration 1606 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 176.6734042467304), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 176.6734042467304), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 267.2916156728838), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 165.2332926)]
Reward: 215
Iteration 1607 Learning Q-Table
best: move_right current state : (1, 3, -24) -100.0 [('nothing', -18.412252880888047), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (1, 3, -24) -100.0 [('nothing', -18.412252880888047), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 0.5, -18) -37.241639747 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 311.2160908075685)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 162.2765372167421), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1608 Learning Q-Table
best: nothing current state : (-1, -1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (-1, -1.75, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -1.5, -18) -100.0 [('nothing', 88.10079123254998), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -1.5, -7) -32.7478711194 [('nothing', 0), ('move_left', 0)]
Reward: -50
Iteration 1609 Learning Q-Table
best: move_left current state : (-2, -2, -24) -100.0 [('nothing', -94.95039127117637), ('move_left', -67.7362585606767)]
best: move_left current state : (-2, -2, -24) -100.0 [('nothing', -94.95039127117637), ('move_left', -67.7362585606767)]
best: move_right current state : (-1, -1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 102.09576852299999)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 207.50030007459782), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 1610 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 123.94757438157018), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 123.94757438157018), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.5, -19) -47.8784607102 [('nothing', 0), ('move_left', 119.80322468265422), ('move_right', -30.0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 225.68828368865877), ('move_right', 0)]
Reward: 289
Iteration 1611 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 213.6340445607305)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 213.6340445607305)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 281.6741187510187), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 200.29357605171947), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1612 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 39.93006859240595), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 39.93006859240595), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_right current state : (0, 0.5, -18) -100.0 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 311.5342247303206)]
best: nothing current state : (0, 0.0, -9) -100.0 [('nothing', -44.1), ('move_left', -90.0), ('move_right', -121.5)]
Reward: -150
Iteration 1613 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 87.34073125884738), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 87.34073125884738), ('move_right', -15.460180598157898)]
best: move_right current state : (0, 1.25, -18) -26.5339353272 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 278.40750408714706)]
best: move_right current state : (0, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 149.43210000000002)]
Reward: 131
Iteration 1614 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 70.41131543378035), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 70.41131543378035), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.75, -18) -100.0 [('nothing', 0), ('move_left', 354.8981969323996), ('move_right', 0)]
best: move_right current state : (0, 0.5, -8) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 43.116)]
Reward: -200
Iteration 1615 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 196.46656600109918)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 196.46656600109918)]
best: nothing current state : (0, 0.75, -19) -26.8720394501 [('nothing', 315.13115663808554), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 204.70550323620364), ('move_left', 0), ('move_right', 0)]
Reward: 225
Iteration 1616 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 174.89868707641853), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 174.89868707641853), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 1.25, -18) -26.5339353272 [('nothing', -4.317623790000006), ('move_left', -30.0), ('move_right', 284.71488286100293)]
best: move_right current state : (0, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 143.90247000000002)]
Reward: 153
Iteration 1617 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 104.75737988336613), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 104.75737988336613), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.5, -19) -100.0 [('nothing', 0), ('move_left', 196.56874238445556), ('move_right', -30.0)]
best: nothing current state : (0, -0.25, -8) -100.0 [('nothing', -106.5), ('move_left', -108.0), ('move_right', -142.5)]
Reward: -250
Iteration 1618 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 203.0043313571633)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 203.0043313571633)]
best: move_left current state : (0, 1.0, -19) -26.8308021127 [('nothing', 0), ('move_left', 352.16117011571845), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 180.00518520077702), ('move_right', 0)]
Reward: 141
Iteration 1619 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 81.30078863369296), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 81.30078863369296), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_right current state : (0, 0.5, -18) -100.0 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 174.84395731122441)]
best: nothing current state : (0, 0.25, -8) -100.0 [('nothing', -100.5), ('move_left', -130.845), ('move_right', -133.785)]
Reward: -150
Iteration 1620 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 178.88336521363595), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 178.88336521363595), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 302.2599559412289), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 251.58331919966218), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1621 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 218.7021423509323)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 218.7021423509323)]
best: nothing current state : (0, -0.25, -18) -15.7875285356 [('nothing', 275.7074360154877), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.9858802038576)]
Reward: 226
Iteration 1622 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 115.7005825091794), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 115.7005825091794), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 1.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 234.48141412231246), ('move_right', 0)]
best: move_right current state : (0, 3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 180.16330482)]
Reward: 289
Iteration 1623 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 205.08588621965907)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 205.08588621965907)]
best: move_left current state : (0, 1.5, -19) -37.241639747 [('nothing', 0), ('move_left', 263.18598133161873), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.66612149344152)]
Reward: 142
Iteration 1624 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 136.76120057159366), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 136.76120057159366), ('move_right', 0)]
best: move_left current state : (1, 2, -18) -15.7875285356 [('nothing', 0), ('move_left', 247.24496538397932), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 100 [('nothing', 197.29191623128557), ('move_right', 0)]
Reward: 138
Iteration 1625 Learning Q-Table
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 190.34342282915094)]
best: move_right current state : (2, 4, -24) -100.0 [('nothing', -51.0), ('move_right', 190.34342282915094)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 350.89831476805927), ('move_right', -11.172491924096027)]
best: move_left current state : (0, -3, -6) 150 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 153
Iteration 1626 Learning Q-Table
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 210.0674718896222)]
best: move_right current state : (0, 2, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 210.0674718896222)]
best: move_left current state : (0, -0.0, -18) -15.7875285356 [('nothing', 0), ('move_left', 352.0101246444463), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.79385226534254), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 1627 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 58.3637392369524), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 58.3637392369524), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -19) -100.0 [('nothing', 327.003460617521), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.75, -8) -100.0 [('nothing', -51.99000000000001), ('move_left', -90.0), ('move_right', 8.099999999999998)]
Reward: -300
Iteration 1628 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 87.95565565112298), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 87.95565565112298), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_right current state : (0, 0.5, -18) -99.023457906 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', 62.240770117857096)]
best: nothing current state : (0, 0.25, -8) -99.023457906 [('nothing', -115.35), ('move_left', -130.845), ('move_right', -133.785)]
Reward: -150
Loading mission from ghast_survival_mission.xml
Iteration 1630 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 218.11883558876616), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 218.11883558876616), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 231.36353785267974), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.675349673699), ('move_right', 0)]
Reward: 209
Iteration 1631 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 281.9477469492423)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 281.9477469492423)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 389.28228678162156), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 216.1901161427003)]
Reward: 215
Iteration 1632 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 189.9197543438442), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 189.9197543438442), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 337.43416831614536), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 213.64664652255243), ('move_right', 0)]
Reward: 215
Iteration 1633 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.58479509490388)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 240.58479509490388)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 364.8631773493815), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 193.4556965857398), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1634 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.72385050781782), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 183.72385050781782), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 345.51437464123603), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 203.45356672090705), ('move_right', 0)]
Reward: 215
Iteration 1635 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.69581784715115)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.69581784715115)]
best: nothing current state : (1, 1.5, -18) -15.7875285356 [('nothing', 382.3546355899452), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 183.76628504540906)]
Reward: 215
Iteration 1636 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 205.21389793737666), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 205.21389793737666), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 345.2979117780675), ('move_right', 0)]
best: nothing current state : (1, 3, -7) 150 [('nothing', 164.97504), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1637 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.95720460931267)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.95720460931267)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 358.440933120289), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 199.91898761001784), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1638 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 215.06661016548787), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 215.06661016548787), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 272.55708139898553), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 214.0526525657867), ('move_right', 0)]
Reward: 215
Iteration 1639 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.2421425644477)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 285.18792830079815)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.77813042658437), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 204.44329132701247), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1640 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 200.08851582374723), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 200.14125961144114), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 336.20105024464726), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 193.2326493), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1641 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.42587828535284)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.42587828535284)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.7776786967128), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 207.61030392890873), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1642 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 170.1043389600554), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 170.1043389600554), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 300.0057527490259), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.29486696485006)]
Reward: 215
Iteration 1643 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.07123781060295)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.07123781060295)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 280.36799603350886), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 209.82721275023613), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1644 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 178.90470697315538)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 55.65819576512939), ('move_right', -16.5)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 31.54829024890752)]
best: move_right current state : (0, -0.5, -8) -65.6388261835 [('nothing', 0), ('move_left', -90.0), ('move_right', 73.017)]
Reward: -300
Iteration 1645 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 180.11458249858865), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 180.11458249858865), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.9772822029 [('nothing', 0), ('move_left', 360.07948824918384), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 201.15819950526725)]
Reward: 200
Iteration 1646 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 302.00480834037614)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 302.00480834037614)]
best: move_right current state : (1, 1.25, -17) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 346.95978097377207)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 231.72794031195036)]
Reward: 300
Iteration 1647 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 164.28328191287636), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 164.28328191287636), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 319.5924870137731), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 191.15021005221848), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1648 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.8877733533787)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.8877733533787)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 363.26804157418513)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 189.4790489251653), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1649 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 164.84435439203412), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 164.84435439203412), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 75.6481196691189), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 237.30832343976354), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1650 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 289.75504156971823)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 289.75504156971823)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 356.1313437794792)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.8330812998902)]
Reward: 289
Iteration 1651 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 109.12530337700166), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 109.12530337700166), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 326.0598039253067), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 223.80514703655294), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1652 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.4416732214627)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.4416732214627)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 359.0418650356025)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 252.20955821836526)]
Reward: 278
Iteration 1653 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 145.24547294333527), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 145.24547294333527), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 340.3834068586806), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 240.06360292558705), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1654 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.74923884160862)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.74923884160862)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 355.88434946720764), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.6353342476157), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1655 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.01086956290794), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.01086956290794), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 201.3324224322647), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 177.7845)]
Reward: 215
Iteration 1656 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.8172801051923)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.8172801051923)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 361.9274662663716), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 237.78315690992315)]
Reward: 215
Iteration 1657 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 229.78670487730693), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 229.78670487730693), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 338.3105299612531), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 179.5043413618999), ('move_right', 0)]
Reward: 215
Iteration 1658 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.0778440294501)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.0778440294501)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 360.90964490133007), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 230.9482098369462)]
Reward: 215
Iteration 1659 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 171.73484349961893), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 171.73484349961893), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 355.28746567875254), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 190.1530389533299), ('move_right', 0)]
Reward: 215
Iteration 1660 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.8638460779661)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.8638460779661)]
best: nothing current state : (1, 1.5, -18) -15.7875285356 [('nothing', 369.68417345943703), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 259.94669075285566)]
Reward: 226
Iteration 1661 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.84044955520113), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.84044955520113), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 335.66867338144715), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.77274477158932), ('move_right', 0)]
Reward: 226
Iteration 1662 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 280.70775163448866)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 280.70775163448866)]
best: move_right current state : (1, 1.0, -17) -15.7875285356 [('nothing', -14.363538213047999), ('move_left', 0), ('move_right', 244.67022167476517)]
best: move_left current state : (0, -3, -6) 150 [('nothing', 0), ('move_left', 91.05), ('move_right', 0)]
Reward: 300
Iteration 1663 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 171.61436119384283), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 171.61436119384283), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 169.14618080031227), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 258.04452204791096), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1664 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.27368573173067)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.27368573173067)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 371.9921729904313)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 220.344733973331), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1665 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 181.9158628449875), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 181.9158628449875), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 350.74713766112575), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 210.26682826780035), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1666 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.72905131118296)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.72905131118296)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 371.49794128530124)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 226.16374688586234)]
Reward: 289
Iteration 1667 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 138.70141515168763), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 138.70141515168763), ('move_right', -56.92696867322963)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 97.96732199999998)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 249.51582640783448), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1668 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 210.22873610491703), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 210.22873610491703), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -37.241639747 [('nothing', 301.0007027419805), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.84092134011252), ('move_right', 0)]
Reward: 215
Iteration 1669 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 244.1602340858949)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 244.1602340858949)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 341.4034762497175), ('move_right', -4.736258560676714)]
best: move_right current state : (0, -2.0, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 245.01462282010363)]
Reward: 142
Iteration 1670 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 111.93075361074759)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 111.93075361074759)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.87340145443227), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.11023597407254)]
Reward: 163
Iteration 1671 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.28783417194003), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 205.28783417194003), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 0.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 258.2855115733504)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.62449810315843)]
Reward: 163
Iteration 1672 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 155.85336736569508)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 155.85336736569508)]
best: move_left current state : (0, 0.25, -20) -37.241639747 [('nothing', 0), ('move_left', 178.8870431638293), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 193.13639953178634)]
best: nothing current state : (0, -3, 3) 100 [('nothing', 51.0), ('move_left', 0), ('move_right', 0)]
Reward: 149
Iteration 1673 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 94.30869528208531), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 94.30869528208531), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -47.8784607102 [('nothing', 0), ('move_left', 240.81568317459187), ('move_right', -30.0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 185.125239), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 5, 2) 250 [('nothing', 0), ('move_right', 0)]
Reward: 301
Iteration 1674 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.39953770526057)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.39953770526057)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 381.7629286474626), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 198.77716518185076)]
Reward: 215
Iteration 1675 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 230.17136047839475), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 230.17136047839475), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -16) -26.5339353272 [('nothing', 186.83064765), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 197.78407785)]
Reward: 215
Iteration 1676 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 272.0483743897633)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 272.0483743897633)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 366.9212143820149), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 235.12201485000003), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1677 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 185.82359917931515), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 185.82359917931515), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 239.26804570258528), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 197.60712726733095), ('move_right', 0)]
Reward: 204
Iteration 1678 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 244.37302613688377)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 244.37302613688377)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.86719960777907), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 203.64401562729554)]
Reward: 215
Iteration 1679 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.68444121220017), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 169.68444121220017), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.60304484312815), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 199.52498908713167), ('move_right', 0)]
Reward: 215
Iteration 1680 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.5500457892809)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.5500457892809)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.400244413634), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.0508109391069)]
Reward: 215
Iteration 1681 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 195.89984170332067), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 195.89984170332067), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.3796281163292), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.20640687539503)]
Reward: 215
Iteration 1682 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.04492477842894)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.04492477842894)]
best: nothing current state : (1, 1.5, -18) -15.7875285356 [('nothing', 363.59541437127587), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 180.49547967225044)]
Reward: 226
Iteration 1683 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 188.20896603171843), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 188.20896603171843), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 309.49022733836995), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 199.76285450999998), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1684 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 273.0738130956063)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 273.0738130956063)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 353.6654339615682), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 244.24131378133168), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1685 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.88359702906533), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 213.88359702906533), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -15.7875285356 [('nothing', 321.3527683214201), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -7) 150 [('nothing', 179.982528), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1686 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.07880743129886)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.07880743129886)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 372.3814545224104), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 235.4689196469322), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1687 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 220.38808985609506), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 220.38808985609506), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 344.6998947984898), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.1444848127765)]
Reward: 215
Iteration 1688 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.0971096345363)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 253.66109757999448)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 365.83819790749726), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 229.32824375285253), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1689 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.7214507406556), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.7214507406556), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 347.89613226513734), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.10113936894356)]
Reward: 215
Iteration 1690 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.66630601817377)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.66630601817377)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 369.8852116611038), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 225.02977062699676), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1691 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 195.63316382555598), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 195.63316382555598), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 321.572015489859), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 214.33685679605068), ('move_right', 0)]
Reward: 215
Iteration 1692 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.1717971128949)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.1717971128949)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.4285793508717), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.02083943889772), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1693 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.51367459984223), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.51367459984223), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 323.9416962249941), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 2, -6) 150 [('nothing', 204.333998157), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1694 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.38865118613003)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.38865118613003)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.6062573772795), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.9145876072284), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1695 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.0819004892299), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 233.0819004892299), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.22766174404893), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 204.16749236099218), ('move_right', 0)]
Reward: 215
Iteration 1696 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 276.1417357541493)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 276.1417357541493)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 376.30769405976696), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.43556765737483)]
Reward: 215
Iteration 1697 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 204.45463872668898), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 204.45463872668898), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.75, -16) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 214.53579975723548), ('move_right', 0)]
Reward: 215
Iteration 1698 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 274.01903132173857)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 274.01903132173857)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.0987564462642), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.1048973601624)]
Reward: 215
Iteration 1699 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.0654482675177), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.0654482675177), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 353.0576343962792), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 206.91749670463494), ('move_right', 0)]
Reward: 215
Iteration 1700 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.893752445317)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.893752445317)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.10059872043365), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.4402113250599), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1701 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.4906121820501), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.4906121820501), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 354.2155930887859), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.41724465269454), ('move_right', 0)]
Reward: 215
Iteration 1702 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.3956257296941)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.3956257296941)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.2024825018215), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.40814792754193), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1703 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.8356145299748), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 243.8356145299748), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 350.8332718027758), ('move_right', 0)]
best: nothing current state : (2, 4, -6) 150 [('nothing', 136.4871), ('move_right', 0)]
Reward: 215
Iteration 1704 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 274.18276826093836)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 274.18276826093836)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 372.8976829654696)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 249.76268352699896)]
Reward: 289
Iteration 1705 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 102.89725343678927), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 102.89725343678927), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 331.5294202619431), ('move_right', 0)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 161.8128), ('move_right', 0)]
Reward: 278
Iteration 1706 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.8775021631744)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.8775021631744)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.9641821295376), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.80269979423858)]
Reward: 215
Iteration 1707 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.9747311136572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.9747311136572), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 325.6144341833602), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 217.68864493807877), ('move_right', 0)]
Reward: 226
Iteration 1708 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.5433255549255)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.5433255549255)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 380.9571831339284)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 223.961889855967)]
Reward: 300
Iteration 1709 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 139.31441156023936), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 139.31441156023936), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 334.4014678817165), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 233.88677978746026), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1710 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 130.59097818103933)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 130.59097818103933)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.64445181032437), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.68570354927937), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1711 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 117.38198854800558), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 117.38198854800558), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 333.0593868045959), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 220.18205145665513), ('move_right', 0)]
Reward: 215
Iteration 1712 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 275.83122426794966)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 275.83122426794966)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.9157374289479), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 191.68936514588225), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1713 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.6064614364102), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.6064614364102), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 2.0, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 323.6411346707308)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.0707975582605)]
Reward: 153
Iteration 1714 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 169.74683967166695)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 169.74683967166695)]
best: move_left current state : (0, 0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.6452429307152), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 168.3036296405439), ('move_right', 0)]
Reward: 152
Iteration 1715 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.48060484602968), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 240.48060484602968), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.40310162600883), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 200.81073965368708)]
Reward: 205
Iteration 1716 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 271.62475074820173)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 271.62475074820173)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.1478257440282), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 194.27999248449555), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1717 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 153.12502742682477), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 153.12502742682477), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.75, -16) -15.7875285356 [('nothing', 109.36073992717066), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 202.94885449499998)]
Reward: 215
Iteration 1718 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 269.8214926487918)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 269.8214926487918)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 378.85859515054)]
best: nothing current state : (0, -4, -4) 150 [('nothing', 71.1), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1719 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 168.8803478585246), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 168.8803478585246), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 269.1085499222143), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 217.26107848548415), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1720 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 275.39639761809127)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 275.39639761809127)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 356.78747576616837), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 246.7733228991769)]
Reward: 226
Iteration 1721 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 114.25948261625182), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 114.25948261625182), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 344.1961862002137), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -6) 150 [('nothing', 0), ('move_left', 186.307014), ('move_right', 0)]
Reward: 226
Iteration 1722 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 270.8535404643565)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 270.8535404643565)]
best: move_right current state : (1, 1.25, -17) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 357.3902287752256)]
best: move_left current state : (0, -3, -6) 150 [('nothing', 0), ('move_left', 153.73499999999999), ('move_right', 0)]
Reward: 300
Iteration 1723 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 106.61316564787069), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.5, -23) -100.0 [('nothing', -30.0), ('move_left', 50.95315552250129), ('move_right', -30.0)]
best: move_right current state : (0, -0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 118.8127281084421)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 228.22074585122218), ('move_left', 0), ('move_right', 0)]
Reward: 163
Iteration 1724 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.59717328186554), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.59717328186554), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 338.23669740977573), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.6274360196586), ('move_right', 0)]
Reward: 236
Iteration 1725 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4510087445692)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.4510087445692)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 331.531016605378)]
best: nothing current state : (0, -3, -5) 150 [('nothing', 71.1), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1726 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 166.77631655353548), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 166.77631655353548), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 271.769770172009), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 208.65452209585553), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1727 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 40.465043512104934), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 40.465043512104934), ('move_right', -16.5)]
best: nothing current state : (2, 3, -17) -26.5339353272 [('nothing', 38.15862483052394), ('move_right', 0)]
best: move_right current state : (2, 2.0, -7) 100 [('nothing', 0), ('move_right', 147.6488322)]
Reward: 107
Iteration 1728 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.3025191787158)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.3025191787158)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 359.57752293278406), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 184.44)]
Reward: 215
Iteration 1729 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.1288499220807), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 154.28031309328247), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 341.8294345401496), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -7) 150 [('nothing', 164.9682), ('move_right', 0)]
Reward: 215
Iteration 1730 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 270.3601314752202)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 270.3601314752202)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.7832299060709), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 200.49599473914688), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1731 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 202.58486892918472), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 202.58486892918472), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 347.3539189927406), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.69207125688618), ('move_right', 0)]
Reward: 215
Iteration 1732 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.1248397067784)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.1248397067784)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.2970593559937), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 204.84719631740282), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1733 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.87428887344123), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 187.87428887344123), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 351.05536467198425), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.28444987982033), ('move_right', 0)]
Reward: 215
Iteration 1734 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.9163250033851)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.9163250033851)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 371.2460561390493), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.1468357705753)]
Reward: 215
Iteration 1735 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 213.84309202415545), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 213.84309202415545), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.1240902343351), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 227.6928298321175), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1736 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.74275241998834)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.74275241998834)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.76210044441643), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.27342815211367)]
Reward: 226
Iteration 1737 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.86843101484624), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 207.86843101484624), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.1947121136698), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 223.83920521376103), ('move_right', 0)]
Reward: 226
Iteration 1738 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 270.92688040631754)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 270.92688040631754)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.2154987567256), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 193.8)]
Reward: 226
Iteration 1739 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 226.96721088905144), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 226.96721088905144), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 349.2470614534396), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -5) 150 [('nothing', 0), ('move_right', 206.5641981465)]
Reward: 226
Iteration 1740 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.0883762291589)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.0883762291589)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 363.1162900285071), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 207.89303742218198), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1741 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 224.90613474633543), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 224.90613474633543), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 364.9880600436972), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 224.48744364963272), ('move_right', 0)]
Reward: 215
Iteration 1742 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 269.05328531328206)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 269.05328531328206)]
best: move_right current state : (1, 1.25, -17) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 341.2936601426579)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 216.39139970647958)]
Reward: 289
Iteration 1743 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 169.31417204091963), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 169.31417204091963), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -17) -26.5339353272 [('nothing', 147.91882355216518), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2.0, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 146.631729)]
Reward: 226
Iteration 1744 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 196.25618005122354)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 196.25618005122354)]
best: move_left current state : (0, 0.0, -18) -37.241639747 [('nothing', 0), ('move_left', 343.74275894366383), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.40278503940272)]
Reward: 152
Iteration 1745 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.75822041144792), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 234.75822041144792), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 355.4253930343123), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.39911491587424), ('move_right', 0)]
Reward: 205
Iteration 1746 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 258.55290583799876)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 258.55290583799876)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 298.4017116237646)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.02512619552738), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1747 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 133.9353868961354), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 133.9353868961354), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -17) -26.5339353272 [('nothing', 192.53269518651564), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 270.63116543353766), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1748 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 144.17007145463265), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 144.17007145463265), ('move_right', 0)]
best: nothing current state : (2, 3, -18) -26.5339353272 [('nothing', 84.11261999999999), ('move_right', 0)]
best: nothing current state : (2, 2, -8) -13.6563854592 [('nothing', 118.87608444), ('move_right', 0)]
Reward: 86
Iteration 1749 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.73656977080543)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.73656977080543)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 355.9908491297079), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 238.1739797945357)]
Reward: 226
Iteration 1750 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 234.69098546021), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 234.69098546021), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -16) -37.241639747 [('nothing', 235.11667671), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 221.6412105547429), ('move_right', 0)]
Reward: 204
Iteration 1751 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 241.5473669755706)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 241.5473669755706)]
best: move_left current state : (1, 1.25, -16) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -3, -6) 150 [('nothing', 0), ('move_left', 197.6145), ('move_right', 0)]
Reward: 142
Iteration 1752 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 208.3296617948596)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 208.3296617948596)]
best: nothing current state : (0, -0.5, -19) -37.241639747 [('nothing', 267.3307539594252), ('move_left', 0), ('move_right', -30.0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 185.8819495275819)]
Reward: 215
Iteration 1753 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 59.91516261025986), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 59.91516261025986), ('move_right', -49.9601805981579)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 355.6096109291319), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 257.24181580347636), ('move_left', 0), ('move_right', 0)]
Reward: 300
Iteration 1754 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.75267298031827)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 136.9106649588034)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 365.64578832915623), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.41758833686916), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1755 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.99819160014934), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.99819160014934), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 367.83787512547786), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 216.34884738832005), ('move_right', 0)]
Reward: 215
Iteration 1756 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 194.30007057386382)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 194.30007057386382)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 370.0773283314701), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 225.79231183580842), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1757 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.57760473365187), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.57760473365187), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 297.83519574916295), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.17938044111196), ('move_right', 0)]
Reward: 215
Iteration 1758 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.0730673029878)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.0730673029878)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 361.5493142466095), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.55461828506589), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1759 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.48239011420915), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 230.48239011420915), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 351.4422024613577), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.62556630877836), ('move_right', 0)]
Reward: 215
Iteration 1760 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.15576078791642)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.15576078791642)]
best: move_left current state : (1, 1.75, -18) -37.241639747 [('nothing', 0), ('move_left', 357.48682022083335), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 166.05521979000002), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1761 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 193.85749752013325)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 193.85749752013325)]
best: move_left current state : (0, 0.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 220.67102870820315), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 234.521785856175)]
Reward: 131
Iteration 1762 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.81015322019582), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 202.64620091105098), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.75, -17) -26.5339353272 [('nothing', 0), ('move_left', 234.28074680156604), ('move_right', 0)]
best: move_left current state : (1, 2, -7) 150 [('nothing', 0), ('move_left', 167.60549999999998), ('move_right', 0)]
Reward: 205
Iteration 1763 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.58258669369548)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.58258669369548)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 316.8887359952934)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 220.2882327995461), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1764 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 203.60506469167106), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 203.60506469167106), ('move_right', -53.7146573472915)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 371.09927239143525), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 213.85816546709887), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1765 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.20193956007884)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.20193956007884)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 364.8509054581464), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 225.785410395), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1766 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.26096752745235), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 197.26096752745235), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 354.49721161558386), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 202.06751775758096)]
Reward: 215
Iteration 1767 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.7241374054031)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 194.3587100458132)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 332.9085850365692)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 240.9017629596823), ('move_left', 0), ('move_right', 0)]
Reward: 267
Iteration 1768 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 122.55439878509159), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 122.55439878509159), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 368.9269403141343), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 270.0692710624335), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1769 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 194.71450919752613)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 194.71450919752613)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 352.03626605294886), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 198.6825556021176), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1770 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 212.25934882979578), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 212.25934882979578), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 333.7710641781047), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.63789641614486), ('move_right', 0)]
Reward: 215
Iteration 1771 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.95085565599504)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 212.95085565599504)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 371.79182338277155), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 203.4652500993225)]
Reward: 215
Iteration 1772 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.75268283613056), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.75268283613056), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 355.1760885579585), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.3465274913014), ('move_right', 0)]
best: nothing current state : (2, 3, 3) 200 [('nothing', 107.85), ('move_right', 0)]
Reward: 215
Iteration 1773 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.6429653758701)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.6429653758701)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.29385139773683), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 248.7312340717776), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1774 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.2072126285829), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 228.2072126285829), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 320.30574145720476), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 241.69756924391098), ('move_right', 0)]
Reward: 215
Iteration 1775 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 224.75118061894398)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 224.75118061894398)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 350.3065384135031)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.92567506952577)]
Reward: 300
Iteration 1776 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 221.6808350775043), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 221.6808350775043), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.75, -17) -26.5339353272 [('nothing', 353.76830345818297), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 233.1007158269692), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1777 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 172.94137627839632)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 172.94137627839632)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 24.297255319179794)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 238.61186385024433), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1778 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 102.44288191131648), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 102.44288191131648), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 100.51538128642791)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 230.97050107887844), ('move_left', 0), ('move_right', 0)]
Reward: 163
Iteration 1779 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 232.34689499355), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 232.34689499355), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.5, -17) -26.5339353272 [('nothing', 260.96223626062226), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 196.66896), ('move_right', 0)]
Reward: 215
Iteration 1780 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 97.19265542008496), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 97.19265542008496), ('move_right', 0)]
best: move_right current state : (2, 2, -17) -26.5339353272 [('nothing', -23.104703249775486), ('move_right', 0)]
best: move_right current state : (2, 1.75, -8) -13.9986687242 [('nothing', -15.0), ('move_right', -15.0)]
Reward: -300
Iteration 1781 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.07805058427223)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.07805058427223)]
best: move_left current state : (1, 1.75, -18) -37.6608654694 [('nothing', 0), ('move_left', 345.05734009158334), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 250.42830469517102), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 1782 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 96.17564806653533)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 96.17564806653533)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.3568273320109), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.5998132866197), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1783 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.66427935307343), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 223.66427935307343), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 367.3911668043305), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.9371486722109)]
Reward: 224
Iteration 1784 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.37357779565303)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.37357779565303)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 368.1312569392025), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.61736466930734)]
Reward: 215
Iteration 1785 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.82216499029266), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.82216499029266), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 384.26963953862406), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.94419317182403), ('move_right', 0)]
Reward: 215
Iteration 1786 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.44070094055996)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.44070094055996)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 376.0250661999491), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 203.46)]
Reward: 226
Iteration 1787 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.79622675663418), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.79622675663418), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 341.7232897932166), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.66093522027683), ('move_right', 0)]
Reward: 226
Iteration 1788 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 233.45760735915383)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 233.45760735915383)]
best: move_right current state : (1, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 348.8229820118044)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 240.54132602942383)]
Reward: 300
Iteration 1789 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 211.97131677551377), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 211.97131677551377), ('move_right', -53.7146573472915)]
best: move_right current state : (0, 1.0, -15) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 2, -4) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 174
Iteration 1790 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.1108074545609), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.1108074545609), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -17) -26.5339353272 [('nothing', 0), ('move_left', 259.27817276109624), ('move_right', 0)]
best: nothing current state : (2, 3, -4) 200 [('nothing', 0), ('move_right', 0)]
Reward: 204
Iteration 1791 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 239.1070391567911)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 239.1070391567911)]
best: move_right current state : (1, 1.0, -17) -26.5339353272 [('nothing', -14.363538213047999), ('move_left', 0), ('move_right', 243.5841551723356)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 234.84797254866803)]
Reward: 300
Iteration 1792 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 119.41974114470175), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 119.41974114470175), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', -9.743424217541346), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: move_left current state : (0, 2, -5) 150 [('nothing', 0), ('move_left', 175.026), ('move_right', 0)]
Reward: 226
Iteration 1793 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 146.4698212480201)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 146.4698212480201)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 133.59163787849914)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 192.8198693006338), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1794 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 60.912028772029366)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 60.912028772029366)]
best: move_left current state : (0, -0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 240.29038990073812), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 275.74848974370343), ('move_left', 0), ('move_right', 0)]
Reward: 310
Iteration 1795 Learning Q-Table
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 39.07467819590158), ('move_right', 0)]
best: move_left current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', 39.07467819590158), ('move_right', 0)]
best: move_right current state : (2, 3, -19) -47.8784607102 [('nothing', -39.0), ('move_right', -17.120117095178113)]
best: nothing current state : (2, 2, -8) -13.6563854633 [('nothing', 109.013259108), ('move_right', 0)]
Reward: -100
Iteration 1796 Learning Q-Table
best: move_left current state : (1, 2, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.53767710377127)]
best: move_left current state : (1, 2, -24) -100.0 [('nothing', -30.0), ('move_left', 0), ('move_right', -30.53767710377127)]
best: move_right current state : (2, 2, -18) -37.241639747 [('nothing', -51.0), ('move_right', -26.62928227816822)]
best: move_right current state : (2, 1.5, -8) -22.3351223369 [('nothing', 0), ('move_right', 0)]
Reward: -300
Iteration 1797 Learning Q-Table
best: nothing current state : (1, 2, -24) -100.0 [('nothing', -30.0), ('move_left', -40.16127660754649), ('move_right', -30.53767710377127)]
best: nothing current state : (1, 2, -23) -100.0 [('nothing', 17.467774696435356), ('move_left', -35.363538213048), ('move_right', -30.0)]
best: move_left current state : (1, 2.0, -18) -100.0 [('nothing', 0), ('move_left', 262.2590506381712), ('move_right', 0)]
best: nothing current state : (1, 0.75, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 1798 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 211.48999336329658)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 211.48999336329658)]
best: nothing current state : (1, 1.5, -18) -47.8784607102 [('nothing', 369.2555463399644), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.222)]
Reward: 226
Iteration 1799 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 204.1763840800476), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 204.1763840800476), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -15.7875285356 [('nothing', 342.43111384951675), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -5) 150 [('nothing', 0), ('move_left', 71.1), ('move_right', 0)]
Reward: 226
Iteration 1800 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.1558299202188)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.1558299202188)]
best: move_left current state : (1, 1.75, -20) -47.8784607102 [('nothing', 0), ('move_left', 304.20576104852705), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 254.3935807840676)]
Reward: 152
Iteration 1801 Learning Q-Table
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 10.812937309472739), ('move_right', -16.5)]
best: move_left current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', 10.812937309472739), ('move_right', -16.5)]
best: nothing current state : (1, 2, -17) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -7) 100 [('nothing', 0), ('move_right', 135.45418253999998)]
Reward: 108
Iteration 1802 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 223.4561210432489)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 223.4561210432489)]
best: move_right current state : (1, 1.25, -18) -15.7875285356 [('nothing', 0), ('move_left', 0), ('move_right', 352.2922794103099)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 223.67550654884732)]
Reward: 300
Iteration 1803 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 51.710610937870925), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 51.710610937870925), ('move_right', -53.7146573472915)]
best: nothing current state : (0, -0.25, -18) -58.3854585078 [('nothing', 301.5909692719987), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 286.0239428205924), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1804 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 113.64618563900592)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 113.64618563900592)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 196.36010730513954)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 246.57285458419312)]
Reward: 289
Iteration 1805 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 82.55304518654597)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 82.55304518654597)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.62972311839354), ('move_right', 0)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 202.168272), ('move_right', 0)]
Reward: 300
Iteration 1806 Learning Q-Table
best: move_right current state : (0, 1.5, -23) -100.0 [('nothing', -45.8590614639144), ('move_left', -47.31358193303298), ('move_right', -33.228436693388375)]
best: move_right current state : (0, 1.5, -23) -100.0 [('nothing', -45.8590614639144), ('move_left', -47.31358193303298), ('move_right', -33.228436693388375)]
best: move_left current state : (0, -0.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 345.7407667723855), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.67390851044365), ('move_left', 0), ('move_right', 0)]
Reward: 153
Iteration 1807 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.70083644836362), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 219.70083644836362), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -47.8784607102 [('nothing', 0), ('move_left', 378.77200562858405), ('move_right', 0)]
best: move_right current state : (2, 2, -5) 150 [('nothing', 0), ('move_right', 0)]
Reward: 205
Iteration 1808 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.30727104566327)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.30727104566327)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.54548243797507), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -3, -4) 200 [('nothing', 0), ('move_left', 86.7), ('move_right', 0)]
Reward: 247
Iteration 1809 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.05864898938174), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.05864898938174), ('move_right', -87.43070932334369)]
best: move_right current state : (0, 0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 291.3872075322928)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.55600407054763)]
Reward: 152
Iteration 1810 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 29.534152619328747), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 29.534152619328747), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: move_left current state : (0, 0.25, -17) -100.0 [('nothing', 0), ('move_left', 269.8262558525947), ('move_right', 0)]
best: move_right current state : (0, -0.5, -7) -100.0 [('nothing', -90.0), ('move_left', 0), ('move_right', 0)]
Reward: -250
Iteration 1811 Learning Q-Table
best: move_right current state : (1, 2, -24) -100.0 [('nothing', -45.759667591069395), ('move_left', -40.16127660754649), ('move_right', -30.53767710377127)]
best: move_right current state : (1, 2, -24) -100.0 [('nothing', -45.759667591069395), ('move_left', -40.16127660754649), ('move_right', -30.53767710377127)]
best: move_left current state : (0, 0.75, -18) -26.9576268051 [('nothing', 0), ('move_left', 310.1404039400088), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 201.07173595731055), ('move_left', 0), ('move_right', 0)]
Reward: 163
Iteration 1812 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 50.621783589308535), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 50.621783589308535), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -17) -100.0 [('nothing', 362.56802716881884), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 0.25, -7) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 1813 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 93.20565666316162), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 93.20565666316162), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -17) -100.0 [('nothing', 223.7976190181732), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.25, -6) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', -75.0)]
Reward: -300
Iteration 1814 Learning Q-Table
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 81.38324536966509), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.75, -24) -100.0 [('nothing', 81.38324536966509), ('move_left', -72.93230701686844), ('move_right', -55.965256352617374)]
best: nothing current state : (0, 0.5, -18) -100.0 [('nothing', 90.68740304772106), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: nothing current state : (0, 0.0, -8) -100.0 [('nothing', -67.5), ('move_left', -90.0), ('move_right', -121.5)]
Reward: -50
Loading mission from ghast_survival_mission.xml
Iteration 1816 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 217.68472462815902), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 217.68472462815902), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 316.53845115674767), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.76265465419377), ('move_right', 0)]
Reward: 208
Iteration 1817 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.11855386519892)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.11855386519892)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 342.59183770658257), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 259.3009982089352)]
Reward: 215
Iteration 1818 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.16835066263957), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 215.16835066263957), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 357.62722023796135), ('move_right', 0)]
best: move_left current state : (1, 3, -10) 150 [('nothing', 0), ('move_left', 86.91), ('move_right', 0)]
Reward: 215
Iteration 1819 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.80035841945613)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.80035841945613)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.6045858572884), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 189.65021517011738), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1820 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.73351961114008), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.73351961114008), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 322.41980354519933), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 233.6882984707377), ('move_right', 0)]
Reward: 215
Iteration 1821 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.58144605264792)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.58144605264792)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 334.26210696918923), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 197.25515061908217), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1822 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 109.50018154068812)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 109.50018154068812)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 335.87835924950383), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 183.67860543335752), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1823 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.77922419319995), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 225.77922419319995), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.7549613646946), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.53385825793563), ('move_right', 0)]
Reward: 216
Iteration 1824 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 236.37070999269048)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 236.37070999269048)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 355.71827465113705), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 171.17502380335026), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1825 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.91176474649046), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.91176474649046), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 321.41205416657294), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 228.0818089295164), ('move_right', 0)]
Reward: 215
Iteration 1826 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.9131524035143)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.9131524035143)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 345.355299396801), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 184.32251666234518), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1827 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 227.5983133594672), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 227.5983133594672), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 332.2057122059815), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.44955829078233)]
Reward: 215
Iteration 1828 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.08561590334241)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.08561590334241)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 361.07708925823397), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.73215526851513)]
Reward: 215
Iteration 1829 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 219.91654445021163), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 219.91654445021163), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.58863043266695), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 214.67505983006484), ('move_right', 0)]
Reward: 215
Iteration 1830 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.622877311652)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.622877311652)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 342.04546457646427), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 193.52576166364162), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1831 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 234.05798964679033), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 234.05798964679033), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.9145592518863), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.67370078055495), ('move_right', 0)]
Reward: 215
Iteration 1832 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.7894728929378)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.7894728929378)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 342.48955370261746), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 199.96803316454913), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1833 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.80804108932546), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 226.80804108932546), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 340.8003520228608), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 224.15726625066148), ('move_right', 0)]
Reward: 215
Iteration 1834 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 240.00248746612843)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 240.00248746612843)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 344.73309754119697), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 246.01069874625463)]
Reward: 215
Iteration 1835 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.04555377122816), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.04555377122816), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 336.4788660314218), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 202.01469080354764)]
best: nothing current state : (2, 3, 2) 200 [('nothing', 42.6), ('move_right', 0)]
Reward: 152
Iteration 1836 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 145.2411429292368)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 145.2411429292368)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 335.21843310465994), ('move_right', -20.37)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 204.4776232151844), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1837 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.20305552519022), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 231.20305552519022), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 341.1396134630595), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 221.41008637546304), ('move_right', 0)]
Reward: 205
Iteration 1838 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.63931653768378)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.63931653768378)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.11637790271425), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 188.73433625062907), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1839 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.01153098245499), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 232.01153098245499), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 350.807426291201), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.19028356248333)]
Reward: 215
Iteration 1840 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.12225434903502)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.12225434903502)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 353.7017654070887), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.01250868796058)]
Reward: 215
Iteration 1841 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 238.6901189769209), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 238.6901189769209), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.4423017104869), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 216.48706046282413), ('move_right', 0)]
Reward: 215
Iteration 1842 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 242.4614898904911)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 242.4614898904911)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 358.70724755187115)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 236.70748912237823)]
Reward: 289
Iteration 1843 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 88.15908088577257), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 88.15908088577257), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 126.65833331272124), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, -6) 150 [('nothing', 0), ('move_left', 0), ('move_right', 170.4422103)]
Reward: 215
Iteration 1844 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 170.0618380577677)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 170.0618380577677)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 340.9961901378173), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 196.61403537544035), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1845 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.45559319883282), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.45559319883282), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 350.22075533678054), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.43319849373833)]
Reward: 204
Iteration 1846 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.33592706829324)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.33592706829324)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.66862947265963), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 203.57778892148232), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1847 Learning Q-Table
best: move_right current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -27.79448209641709), ('move_right', -16.5)]
best: move_right current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -27.79448209641709), ('move_right', -16.5)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 256.4239314888556)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 183.22982476280825), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1848 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 137.31586796794232)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 137.31586796794232)]
best: move_right current state : (0, -0.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 184.65191722416307)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 268.0167599744147), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1849 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 167.5059806456465), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 167.5059806456465), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.8222834725857), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 233.2117319820903), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 5, 2) 250 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 323
Iteration 1850 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.5755571914453)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.5755571914453)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 357.9736090613183), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 258.37892822059666)]
Reward: 215
Iteration 1851 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.1126499161211), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.1126499161211), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 365.05572933618805), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 215.47159054638846), ('move_right', 0)]
Reward: 226
Iteration 1852 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.5224808283112)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.5224808283112)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 354.0949883913503), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.66087733396577), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1853 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.83539314398328), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.83539314398328), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 363.3391180254371), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 188.94915)]
Reward: 215
Iteration 1854 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.13405249906504)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.13405249906504)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 373.0952048091018), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.66261413377603), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1855 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.8140186843234), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.8140186843234), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 338.41298059545596), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.30323894561684)]
best: nothing current state : (2, 3, 3) 200 [('nothing', 139.995), ('move_right', 0)]
Reward: 152
Iteration 1856 Learning Q-Table
best: move_right current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -27.79448209641709), ('move_right', 33.20468752256066)]
best: move_right current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -27.79448209641709), ('move_right', 33.20468752256066)]
best: move_left current state : (0, 0.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 158.87837909681633), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 252.39524238566477)]
Reward: 142
Iteration 1857 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 244.05477993016123), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 244.05477993016123), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 365.1804876992482), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 218.6301133824719), ('move_right', 0)]
Reward: 215
Iteration 1858 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 248.37503659074721)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 248.37503659074721)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 367.10732002302325)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.27666966996534)]
Reward: 289
Iteration 1859 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 194.74069089557037), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 194.74069089557037), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 298.5543084911953), ('move_right', -30.0)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 238.7827549398389), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1860 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.0499062679801)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.0499062679801)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 356.36475507413496), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 245.36524975441768)]
Reward: 215
Iteration 1861 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.02121533356714), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.02121533356714), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 345.2800581005042), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 191.58920284938335)]
Reward: 226
Iteration 1862 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.28418031166865)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.28418031166865)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 368.0649034782198), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.3638298936432), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1863 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.32637623955225), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.32637623955225), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 344.172801525168), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 249.9107672619318)]
Reward: 215
Iteration 1864 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.9582166634761)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.9582166634761)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.6545814028468), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.85468092555024), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1865 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.10781190114093), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.10781190114093), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.8941912461971), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 239.43753708335225)]
Reward: 215
Iteration 1866 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.1069454871294)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.1069454871294)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 369.9654276065041), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.00875608157241)]
Reward: 204
Iteration 1867 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.57123378056176), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.57123378056176), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 366.2153754042153), ('move_right', 0)]
best: nothing current state : (2, 4, -6) 150 [('nothing', 160.04097), ('move_right', 0)]
Reward: 204
Iteration 1868 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.3919981988458)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.3919981988458)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 351.03015291769947), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.19827664788517), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1869 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.5919843435618), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.5919843435618), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 349.3630537829507), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 209.34224769324447), ('move_right', 0)]
Reward: 215
Iteration 1870 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.21095269040586)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.21095269040586)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.81461125965785), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.4387936535196), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1871 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.56312457722058), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.56312457722058), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 369.45719499734366), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 216.04094232397688), ('move_right', 0)]
Reward: 215
Iteration 1872 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 255.03454102227212)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 255.03454102227212)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 367.7581249171059)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.60715555746373), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1873 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 193.71228425016182), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 193.71228425016182), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 325.62284242578835), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 238.2482123874632), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1874 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.53186966302354)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.53186966302354)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.4018659778164), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 233.62500889022462), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1875 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.05885377916147), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.05885377916147), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 368.4323191953336), ('move_right', 0)]
best: move_left current state : (1, 3, -10) 150 [('nothing', 0), ('move_left', 125.33699999999999), ('move_right', 0)]
Reward: 215
Iteration 1876 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 259.89143559256433)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 259.89143559256433)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 370.86880885153886), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 228.03750622315724), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1877 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.0073551909651), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.0073551909651), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 340.50372343673354), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 232.10627595834657)]
Reward: 215
Iteration 1878 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.7326879593035)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.7326879593035)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 366.37842614902456), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.80612925710068)]
Reward: 204
Iteration 1879 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.08377374059958), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.08377374059958), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.5175095987809), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 215.7286596267838), ('move_right', 0)]
Reward: 204
Iteration 1880 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.3539174921238)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.3539174921238)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 354.9805900367552), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.9642904799705)]
Reward: 204
Iteration 1881 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.2537138998961), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.2537138998961), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.9808546071818), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.21006173874866), ('move_right', 0)]
Reward: 204
Iteration 1882 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.0121556461607)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.0121556461607)]
best: move_right current state : (1, 1.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 361.33848521709024)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 240.19366876897573)]
Reward: 278
Iteration 1883 Learning Q-Table
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 67.53636468976114), ('move_right', -53.7146573472915)]
best: move_left current state : (0, -0.75, -23) -100.0 [('nothing', -48.01088564784317), ('move_left', 67.53636468976114), ('move_right', -53.7146573472915)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 13.231182133404744), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 210.5793507552149), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1884 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 189.16965175768652)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 189.16965175768652)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 279.4656994710414)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 185.10445224503763), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1885 Learning Q-Table
best: move_left current state : (-1, -2, -23) -100.0 [('nothing', -0.38537518605001253), ('move_left', 30.725929719799204), ('move_right', 0)]
best: move_left current state : (-1, -2, -23) -100.0 [('nothing', -0.38537518605001253), ('move_left', 30.725929719799204), ('move_right', 0)]
best: move_left current state : (0, -1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 88.120485), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 211.90554552865044), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1886 Learning Q-Table
best: move_right current state : (0, 1.5, -23) -100.0 [('nothing', -45.8590614639144), ('move_left', -47.31358193303298), ('move_right', 51.5021437481859)]
best: move_right current state : (0, 1.5, -23) -100.0 [('nothing', -45.8590614639144), ('move_left', -47.31358193303298), ('move_right', 51.5021437481859)]
best: move_left current state : (0, 0.25, -17) -26.5339353272 [('nothing', 0), ('move_left', 231.9334380834709), ('move_right', 0)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 158.838653853), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1887 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 251.43231166272943), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 251.43231166272943), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 0.75, -17) -37.241639747 [('nothing', 184.79349640890484), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 217.54107936773033), ('move_right', 0)]
Reward: 215
Iteration 1888 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 262.1498739192817)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 262.1498739192817)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 373.0194180630244), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 251.535568138283)]
Reward: 215
Iteration 1889 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 199.26817516248605), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 199.26817516248605), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 306.03177969466174), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -7) 150 [('nothing', 179.97773999999998), ('move_right', 0)]
Reward: 215
Iteration 1890 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.9694273314172)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.9694273314172)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 381.57426308560196), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.37500333597933)]
Reward: 204
Iteration 1891 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 202.33707592398085), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 202.33707592398085), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 356.02212761780595), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 214.77254188104538), ('move_right', 0)]
Reward: 205
Iteration 1892 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.09069745951473)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.09069745951473)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 373.7144851607152), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 224.12625435621007), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1893 Learning Q-Table
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 216.27009950803233), ('move_right', -56.22141343812249)]
best: move_left current state : (0, -0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 216.27009950803233), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 352.3568119560388), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 211.84077931673175), ('move_right', 0)]
Reward: 215
Iteration 1894 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 263.2382452383085)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 263.2382452383085)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 373.83801591936367), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.38837804934704), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1895 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.9116755139239), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.9116755139239), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 352.9844891932174), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 211.03957338527113), ('move_right', 0)]
Reward: 215
Iteration 1896 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.417653171717)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.417653171717)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 373.1031245583587), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.47186463454292), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1897 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.16102769361592), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.16102769361592), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 355.40101445083354), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 226.9743931708426)]
Reward: 215
Iteration 1898 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.56311398955165)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 271.56311398955165)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 372.013746581214), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.96250233518552)]
Reward: 215
Iteration 1899 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.9605317966852), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.9605317966852), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 355.2020021642467), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 223.3820752195898)]
best: nothing current state : (2, 3, 3) 200 [('nothing', 143.5965), ('move_right', 0)]
Reward: 131
Iteration 1900 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 187.2982854735351)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 187.2982854735351)]
best: move_left current state : (0, 0.25, -19) -47.8784607102 [('nothing', 0), ('move_left', 342.68154370910423), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.13030524418005), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1901 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.27279230879574), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.27279230879574), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 361.87302806683624), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 259.4464026537129)]
Reward: 226
Iteration 1902 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 272.73812316889246)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 272.73812316889246)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 366.8128341092132)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.97375163462988)]
Reward: 289
Iteration 1903 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 201.11295977875375), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 201.11295977875375), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 344.4104534142908), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 253.47374867122426), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1904 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 272.0003558528308)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 272.0003558528308)]
best: move_left current state : (1, 1.75, -20) -47.8784607102 [('nothing', 0), ('move_left', 338.16002006415715), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 222.5497872765), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 1905 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 0)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 0)]
best: move_right current state : (0, -0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 311.5378464937692)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 198.29121367092603), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1906 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 72.904451125692), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 72.904451125692), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 358.7912877828755), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 260.83162406985696), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1907 Learning Q-Table
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', 27.577726961722895), ('move_right', -30.0)]
best: move_left current state : (0, 1.75, -25) -100.0 [('nothing', -34.528044119234735), ('move_left', 27.577726961722895), ('move_right', -30.0)]
best: move_right current state : (2, 3, -19) -26.5339353272 [('nothing', -39.0), ('move_right', 16.62298012679175)]
best: nothing current state : (2, 2, -9) -13.3133677951 [('nothing', 0), ('move_right', -45.962999999999994)]
Reward: -250
Iteration 1908 Learning Q-Table
best: move_right current state : (1, 2, -24) -100.0 [('nothing', -45.759667591069395), ('move_left', -40.16127660754649), ('move_right', 42.578459167842524)]
best: move_right current state : (1, 2, -24) -100.0 [('nothing', -45.759667591069395), ('move_left', -40.16127660754649), ('move_right', 42.578459167842524)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 360.65602408084965), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.2038495696482), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1909 Learning Q-Table
best: move_left current state : (0, 1.0, -24) -100.0 [('nothing', -3.166126952631439), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -24) -100.0 [('nothing', -3.166126952631439), ('move_left', 0), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 213.61846838074104), ('move_right', 0)]
best: nothing current state : (2, 2, -8) 150 [('nothing', 46.3092813756), ('move_right', 0)]
Reward: 165
Iteration 1910 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.4847169031807)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.4847169031807)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 355.27570016971976), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 201.14269469875376), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1911 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.68037111211186), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.68037111211186), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.1203717274892), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.74704321712406), ('move_right', 0)]
Reward: 215
Iteration 1912 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.9495199590464)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.9495199590464)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.89837330740545), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 205.29988628912764), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1913 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.85219069856714), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.85219069856714), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 376.14504044289924), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.32293025198683), ('move_right', 0)]
Reward: 215
Iteration 1914 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 264.245684518529)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 264.245684518529)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 363.5067370814474), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 240.5748976967981)]
Reward: 215
Iteration 1915 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.16755369777076), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.16755369777076), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 354.4844882838679), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.42605117639079), ('move_right', 0)]
Reward: 215
Iteration 1916 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.87399536539624)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.87399536539624)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.4188272019221), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 232.2816261442409)]
Reward: 215
Iteration 1917 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 224.92362131833823), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 224.92362131833823), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -37.241639747 [('nothing', 313.2155677862632), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.91244199456835)]
Reward: 215
Iteration 1918 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 258.66046207435653)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 258.66046207435653)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 369.07766688461777), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 208.20992040238934), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1919 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.99014214950387), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.99014214950387), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 1.0, -17) -37.241639747 [('nothing', 324.8246300487547), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.19823582347354), ('move_right', 0)]
Reward: 215
Iteration 1920 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.2772643181961)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.2772643181961)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 354.03579852842995), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.09713830096862)]
Reward: 215
Iteration 1921 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 219.2387133346197), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 219.2387133346197), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 336.3367117811704), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 216.77875555741124), ('move_right', 0)]
Reward: 215
Iteration 1922 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.93233265717026)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.93233265717026)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 365.81734293994924), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 223.46799681067804)]
Reward: 215
Iteration 1923 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.1679965951831), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 245.1679965951831), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 362.80837317437965), ('move_right', 0)]
best: move_left current state : (1, 3, -10) 150 [('nothing', 0), ('move_left', 152.2359), ('move_right', 0)]
Reward: 215
Iteration 1924 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 259.6131315933389)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 259.6131315933389)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 368.1125391011679), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 232.90242838775868)]
Reward: 215
Iteration 1925 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.28761764484602), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.28761764484602), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 371.6984073856255), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 249.412481857599)]
best: move_right current state : (2, 2, 4) 200 [('nothing', 0), ('move_right', 0)]
Reward: 142
Iteration 1926 Learning Q-Table
best: move_right current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -27.79448209641709), ('move_right', 41.946614396679465)]
best: move_right current state : (0, 1.75, -23) -100.0 [('nothing', -30.0), ('move_left', -27.79448209641709), ('move_right', 41.946614396679465)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 296.15732530324027)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.24694428167254), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1927 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 126.49801019875102), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 126.49801019875102), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 295.92781985362774), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 269.2821368488999), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 5, 3) 250 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 323
Iteration 1928 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 198.54972473115782)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 198.54972473115782)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 350.31617216962695), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.57286099717078), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -3, 3) 100 [('nothing', 80.4), ('move_left', 0), ('move_right', 0)]
Reward: 108
Iteration 1929 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.13836264298382), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.13836264298382), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 380.01262972721753), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.7387650764315), ('move_right', 0)]
Reward: 205
Iteration 1930 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.42534381790796)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.42534381790796)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 360.95420046019154), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 193.608)]
best: move_right current state : (0, -4, 5) 200 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1931 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 40.222218196832415), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 40.222218196832415), ('move_right', -30.0)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.6472518967778), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 282.8474957942299), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1932 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 259.9904619215916)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 259.9904619215916)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 372.54950588714513), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.53169987143107)]
Reward: 215
Iteration 1933 Learning Q-Table
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 225.407932270427), ('move_right', -56.22141343812249)]
best: move_left current state : (0, 0.0, -23) -100.0 [('nothing', -72.0), ('move_left', 225.407932270427), ('move_right', -56.22141343812249)]
best: nothing current state : (0, 1.0, -17) -26.5339353272 [('nothing', 345.46932491404266), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -6) 150 [('nothing', 212.78854552171222), ('move_right', 0)]
Reward: 215
Iteration 1934 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.311508886497)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.311508886497)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 355.7503403221341), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.92759776747462)]
Reward: 215
Iteration 1935 Learning Q-Table
best: move_right current state : (0, -0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.25, -18) -26.5339353272 [('nothing', -7.960180598157904), ('move_left', 188.7780529462102), ('move_right', 0)]
best: move_left current state : (-1, -2, -7) 150 [('nothing', 0), ('move_left', 111.624), ('move_right', 0)]
Reward: 142
Iteration 1936 Learning Q-Table
best: move_left current state : (0, -1.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.0, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 359.3931788178901), ('move_right', -20.37)]
best: nothing current state : (0, 1.5, -7) -55.0161685623 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 1937 Learning Q-Table
best: move_right current state : (0, -0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 27.673235285705168)]
best: move_right current state : (0, -0.5, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 27.673235285705168)]
best: move_right current state : (0, -0.5, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 254.66137004923854)]
best: nothing current state : (-1, -3, -7) 150 [('nothing', 76.2), ('move_left', 0), ('move_right', 0)]
Reward: 252
Iteration 1938 Learning Q-Table
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -71.27212641871053), ('move_left', -43.50569128121344)]
best: move_left current state : (-2, -3, -23) -100.0 [('nothing', -71.27212641871053), ('move_left', -43.50569128121344)]
best: nothing current state : (-1, -1.5, -18) -26.5339353272 [('nothing', 51.84619252695135), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 235.0338818700553), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1939 Learning Q-Table
best: move_right current state : (0, -0.25, -22) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -0.25, -22) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.25, -18) -47.8784607102 [('nothing', -7.960180598157904), ('move_left', 210.63183706234716), ('move_right', 0)]
best: move_left current state : (0, -1.0, -8) -55.0161685623 [('nothing', 0), ('move_left', 0.3299999999999983), ('move_right', -90.0)]
Reward: -250
Iteration 1940 Learning Q-Table
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 0.9475161786944355), ('move_right', -32.786626279003926)]
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 0.9475161786944355), ('move_right', -32.786626279003926)]
best: move_left current state : (0, 1.5, -19) -36.9190747541 [('nothing', 0), ('move_left', 289.73002338016556), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.11713555350204), ('move_right', 0)]
Reward: 170
Iteration 1941 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.9706663930921)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.9706663930921)]
best: nothing current state : (1, 1.25, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 195.08485109355001), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -4, 3) 200 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1942 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 106.78954770865812), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 106.78954770865812), ('move_right', -30.0)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 117.4356327199478), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 198.78199488745142), ('move_right', 0)]
Reward: 215
Iteration 1943 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 145.60697455106845)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 145.60697455106845)]
best: nothing current state : (1, 1.25, -19) -26.5339353272 [('nothing', 103.52545532806501), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.14931843723224)]
Reward: 215
Iteration 1944 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 81.02319261388712), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 81.02319261388712), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 356.8669571516248), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 223.88498088248224), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1945 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 104.02233818600952)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 104.02233818600952)]
best: move_left current state : (1, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 242.62137584622286), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 217.90452290606257)]
best: move_left current state : (0, -4, 3) 100 [('nothing', 0), ('move_left', 64.5), ('move_right', 0)]
Reward: 170
Iteration 1946 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 131.60383005111237), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 131.60383005111237), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 361.972364270882), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 203.647396421216), ('move_right', 0)]
Reward: 215
Iteration 1947 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 113.42955755997751)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 113.42955755997751)]
best: nothing current state : (1, 1.25, -19) -26.5339353272 [('nothing', 183.21261426081517), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.52100269801954), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1948 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 168.54189839294722), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 168.54189839294722), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 359.4748739159822), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 234.5887373003193)]
Reward: 204
Iteration 1949 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 105.4042939720709)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 105.4042939720709)]
best: move_left current state : (1, 1.5, -20) -47.8784607102 [('nothing', 0), ('move_left', 280.2063199641748), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 196.55939576548502), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1950 Learning Q-Table
best: move_left current state : (0, 1.25, -24) -100.0 [('nothing', -30.0), ('move_left', 73.41921750608701), ('move_right', 0)]
best: move_left current state : (0, 1.25, -24) -100.0 [('nothing', -30.0), ('move_left', 73.41921750608701), ('move_right', 0)]
best: move_left current state : (1, 2, -19) -37.241639747 [('nothing', -16.50485056868419), ('move_left', 309.9788203376415), ('move_right', -11.172491924096027)]
best: move_right current state : (2, 2, -10) 100 [('nothing', -52.53000000000001), ('move_right', 0)]
Reward: 119
Iteration 1951 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 122.48136355665409)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 122.48136355665409)]
best: nothing current state : (1, 1.25, -19) -37.241639747 [('nothing', 237.9051307919765), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.3647018886137), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1952 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 193.64929912576167), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 193.64929912576167), ('move_right', -30.0)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 380.9073250660134), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 212.22770136968978), ('move_right', 0)]
Reward: 215
Iteration 1953 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 183.1890384692857)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 183.1890384692857)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 364.1611093668382)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 223.77218991000174)]
Reward: 278
Iteration 1954 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 122.37465139496142), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 122.37465139496142), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.25, -20) -37.241639747 [('nothing', 0), ('move_left', 228.1618500742164), ('move_right', 0)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 250.54792845788722), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1955 Learning Q-Table
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 208.52047914039355)]
best: move_right current state : (2, 2, -24) -100.0 [('nothing', -51.0), ('move_right', 208.52047914039355)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 367.0444335297873)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.2552913220296), ('move_left', 0), ('move_right', 0)]
Reward: 267
Iteration 1956 Learning Q-Table
best: move_right current state : (0, -1.0, -23) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 96.64546172127099)]
best: move_right current state : (0, -1.0, -23) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 96.64546172127099)]
best: nothing current state : (-1, -2, -18) -26.5339353272 [('nothing', 99.34546358128947), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (-2, -3, -7) 150 [('nothing', 0), ('move_left', 45.6)]
Reward: 157
Iteration 1957 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 122.55650214665064)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 122.55650214665064)]
best: nothing current state : (-1, -1.5, -18) -26.5339353272 [('nothing', 151.80249932988252), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 229.02371730903872), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 1958 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 41.147855791593514), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 41.147855791593514), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: move_right current state : (0, -0.25, -20) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 108.22534003769239)]
best: nothing current state : (0, 0.25, -8) -100.0 [('nothing', -125.74499999999999), ('move_left', -130.845), ('move_right', -133.785)]
Reward: -250
Iteration 1959 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 145.154461171118), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 145.154461171118), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -0.25, -19) -26.8370748311 [('nothing', 0), ('move_left', 0), ('move_right', 196.63513343127613)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 284.69324705596097), ('move_left', 0), ('move_right', 0)]
Reward: 141
Iteration 1960 Learning Q-Table
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 10.271101065423178), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: nothing current state : (0, -0.25, -24) -100.0 [('nothing', 10.271101065423178), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: move_right current state : (0, 0.0, -20) -100.0 [('nothing', -11.172491924096029), ('move_left', -30.0), ('move_right', 0)]
best: move_right current state : (0, 0.75, -9) -100.0 [('nothing', -75.0), ('move_left', -60.0), ('move_right', 0)]
Reward: -300
Iteration 1961 Learning Q-Table
best: move_left current state : (0, -2.0, -24) -100.0 [('nothing', -56.572126418710525), ('move_left', -27.404751909446077), ('move_right', -30.0)]
best: move_left current state : (0, -2.0, -24) -100.0 [('nothing', -56.572126418710525), ('move_left', -27.404751909446077), ('move_right', -30.0)]
best: nothing current state : (0, -0.25, -18) -26.8397867025 [('nothing', 341.9208613365768), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, 1.75, -9) 150 [('nothing', 120.987), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1962 Learning Q-Table
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 55.506545912901025), ('move_right', -32.786626279003926)]
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 55.506545912901025), ('move_right', -32.786626279003926)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 332.05696491875887), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 206.93415193016298)]
Reward: 162
Iteration 1963 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 124.9360018031548)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 124.9360018031548)]
best: nothing current state : (1, 1.25, -19) -37.241639747 [('nothing', 276.14300212096765), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 180.19157703583952), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1964 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 220.8665263096793), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 220.8665263096793), ('move_right', -30.0)]
best: move_left current state : (0, 1.5, -18) -26.5339353272 [('nothing', 0), ('move_left', 208.42571227919873), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.0531774948512), ('move_right', 0)]
Reward: 204
Iteration 1965 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 138.12560997440264)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 138.12560997440264)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 371.6271852660526), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 195.5256)]
Reward: 215
Iteration 1966 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 188.17410150237723), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 188.17410150237723), ('move_right', -30.0)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 188.43187332235033)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 225.4121161102235)]
Reward: 131
Iteration 1967 Learning Q-Table
best: nothing current state : (0, 1.25, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.25, -23) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 0.75, -18) -100.0 [('nothing', 0), ('move_left', 375.30343795711633), ('move_right', 0)]
best: nothing current state : (0, -0.0, -8) -100.0 [('nothing', -62.25), ('move_left', -90.0), ('move_right', -121.5)]
Reward: -300
Iteration 1968 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 176.0035906378016)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 176.0035906378016)]
best: move_left current state : (0, 0.5, -19) -26.8945265918 [('nothing', 0), ('move_left', 362.12944199137087), ('move_right', -30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.7787039254207), ('move_left', 0), ('move_right', 0)]
Reward: 141
Iteration 1969 Learning Q-Table
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 34.604720889990816), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -23) -100.0 [('nothing', -30.0), ('move_left', 34.604720889990816), ('move_right', -30.0)]
best: move_left current state : (1, 2, -18) -37.241639747 [('nothing', 0), ('move_left', 153.58133544671983), ('move_right', 0)]
best: move_right current state : (2, 2, -7) 100 [('nothing', 0), ('move_right', 127.21792777799999)]
Reward: 142
Iteration 1970 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.77298806634198)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 202.77298806634198)]
best: nothing current state : (1, 1.25, -19) -37.241639747 [('nothing', 292.3575745954292), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 187.33410392508767), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1971 Learning Q-Table
best: move_left current state : (0, -0.25, -23) -100.0 [('nothing', -2.1724919240960268), ('move_left', 38.88011056425178), ('move_right', -30.0)]
best: move_left current state : (0, -0.25, -23) -100.0 [('nothing', -2.1724919240960268), ('move_left', 38.88011056425178), ('move_right', -30.0)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 214.03740656998144), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 206.13722424639585), ('move_right', 0)]
Reward: 215
Iteration 1972 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 197.47587210097214)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 197.47587210097214)]
best: nothing current state : (1, 1.25, -19) -26.5339353272 [('nothing', 305.8505333943267), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.8831660342438)]
Reward: 204
Iteration 1973 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 156.07894112427311), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 156.07894112427311), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -19) -47.8784607102 [('nothing', 0), ('move_left', 367.7242205715858), ('move_right', -30.0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.7960569724771), ('move_right', 0)]
Reward: 204
Iteration 1974 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 201.0280898908206)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 201.0280898908206)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 363.7967096862368), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 240.04053293700122)]
Reward: 215
Iteration 1975 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 158.62726408602578), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 158.62726408602578), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 339.5201210221801), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 221.21948661773757), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1976 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.49513761639747)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 214.49513761639747)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 348.47695022786), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 202.51821622397065)]
Reward: 142
Iteration 1977 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 226.9140091553927)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 226.9140091553927)]
best: move_left current state : (0, 0.25, -20) -47.8784607102 [('nothing', 0), ('move_left', 279.8776735893176), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 203.8450927477945), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 1978 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 183.93494056871418), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 183.93494056871418), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -47.8784607102 [('nothing', 185.54462471608636), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.08848127715646)]
Reward: 215
Iteration 1979 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.51718947574022)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.51718947574022)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 349.6893300266932), ('move_right', 0)]
best: move_left current state : (0, -3, -9) 150 [('nothing', 0), ('move_left', 86.7), ('move_right', 0)]
Reward: 142
Iteration 1980 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 207.43957027252216)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 207.43957027252216)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 244.5259461587123)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.36792)]
Reward: 289
Iteration 1981 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 102.37012070346232)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 102.37012070346232)]
best: nothing current state : (0, -0.5, -19) -26.5339353272 [('nothing', 287.8961126298722), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 241.58527293917268), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1982 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 149.05430759987783), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 149.05430759987783), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 349.02993070084733), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.83870939619786)]
Reward: 215
Iteration 1983 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.4963397169301)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 228.4963397169301)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 256.6673518729058), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 188.29156492345615), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1984 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 186.39299111428318)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 186.39299111428318)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 276.5785383110986)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 195.63387274756138), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1985 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 129.0677376832274)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 129.0677376832274)]
best: move_left current state : (0, -0.5, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 204.5876673), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 1986 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 181.27616334923178)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 181.27616334923178)]
best: move_right current state : (0, -0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 268.0525675186816)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 184.36275135677946)]
best: move_right current state : (-1, -4, 3) 250 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 338
Iteration 1987 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 58.174924454163154)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 58.174924454163154)]
best: move_left current state : (-1, -1.25, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 233.6096910574209), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 1988 Learning Q-Table
best: move_left current state : (0, 1.0, -24) -100.0 [('nothing', -3.166126952631439), ('move_left', 35.12535991606441), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -24) -100.0 [('nothing', -3.166126952631439), ('move_left', 35.12535991606441), ('move_right', -28.960180598157898)]
best: move_right current state : (1, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 268.8850576254053)]
best: move_right current state : (2, 2, -10) 100 [('nothing', -52.53000000000001), ('move_right', 35.699999999999996)]
Reward: -50
Iteration 1989 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 211.90716703860252)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 211.90716703860252)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 235.0703746038389), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 174.40409544641932), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 1990 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 176.87450260607264), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 176.87450260607264), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 348.9045834213347), ('move_right', 0)]
best: move_right current state : (2, 3, -10) 150 [('nothing', 0), ('move_right', 32.4)]
Reward: 188
Iteration 1991 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.9874627655649)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.9874627655649)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 360.3035175557362), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.05392594974563)]
best: move_left current state : (0, -5, 3) 200 [('nothing', 0), ('move_left', 83.39999999999999), ('move_right', 0)]
Reward: 288
Iteration 1992 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 184.2089867454189), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 184.2089867454189), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 367.0090329312833), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 258.78354992052107), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1993 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 178.34890400190883)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 178.34890400190883)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 261.870490856613), ('move_right', -20.37)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.657544)]
Reward: 152
Iteration 1994 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 193.11998863760323), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 193.11998863760323), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 375.1304703319817), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.35723988073397), ('move_right', 0)]
Reward: 215
Iteration 1995 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.5097872785203)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.5097872785203)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 374.04416408243094), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 164.68286681249353), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 1996 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 215.55064122182074), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 215.55064122182074), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 351.0725643094525), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (2, 4, -7) 150 [('nothing', 190.48441799999998), ('move_right', 0)]
Reward: 215
Iteration 1997 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.3099197215356)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.3099197215356)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 358.42864007393905), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 223.64371092329296), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 1998 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 224.03472622401424), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 224.03472622401424), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 369.7985011966074), ('move_right', 0)]
best: move_right current state : (2, 3, -10) 150 [('nothing', 0), ('move_right', 79.08)]
Reward: 204
Iteration 1999 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.17304390316062)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 242.17304390316062)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 371.6698566614661), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 261.5338784688993)]
Reward: 215
Iteration 2000 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 235.59136679169615), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 235.59136679169615), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 327.58295083762516), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 216.24512889018786), ('move_right', 0)]
best: nothing current state : (2, 3, 2) 200 [('nothing', 75.42), ('move_right', 0)]
Reward: 215
Iteration 2001 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.06190713249435)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.06190713249435)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 383.62906320369603), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.85774816482194)]
Reward: 215
Iteration 2002 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 234.22866140731696), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 234.22866140731696), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 339.18160425339397), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 233.9975902231315), ('move_right', 0)]
Reward: 215
Iteration 2003 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.571873355697)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.571873355697)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 315.7925310186852), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 224.00042371537535)]
Reward: 142
Iteration 2004 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 174.4451994601622)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 174.4451994601622)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 365.0457714918532), ('move_right', -30.0)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 217.59417390000002), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 2005 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 236.75436366298217), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 236.75436366298217), ('move_right', -30.0)]
best: move_left current state : (0, 2.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 300.84208210815035), ('move_right', -27.759)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.6500679165138), ('move_right', 0)]
Reward: 194
Iteration 2006 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.36557873049745)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.36557873049745)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 362.9931613287452), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 179.77800676874546), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2007 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 227.02049859837473), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 227.02049859837473), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 347.8961204166168), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 213.05939095878284), ('move_right', 0)]
Reward: 215
Iteration 2008 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.18136158587575)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.18136158587575)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 353.0286149607453), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 199.40029660076274)]
Reward: 215
Iteration 2009 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 234.32300454568946), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 234.32300454568946), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 352.62640004431523), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 205.94726243030667)]
Reward: 215
Iteration 2010 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.37535700017872)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.37535700017872)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 356.2357749014497), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 232.52837305590086)]
Reward: 215
Iteration 2011 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 237.64153127118115), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 237.64153127118115), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 352.4451015792666), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 219.3536406324163), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2012 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.66099044646398)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.66099044646398)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 381.8976686920338), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -11) 150 [('nothing', 42.6), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 2013 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.12242176544888), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.12242176544888), ('move_right', -30.0)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 318.48447785065935), ('move_right', -27.759)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 204.95504754155965), ('move_right', 0)]
Reward: 204
Iteration 2014 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.8595019960389)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.8595019960389)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 351.94011945275054), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 149.73149999999998)]
Reward: 215
Iteration 2015 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 236.77085799285413), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 236.77085799285413), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 234.0077816844074), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 218.0475484426914), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2016 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.1235066348945)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.1235066348945)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 336.2775336169254), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.0802076205339)]
Reward: 215
Iteration 2017 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 203.7694431762241), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 203.7694431762241), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 353.62265876011264), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 204.66853327909175), ('move_right', 0)]
Reward: 215
Iteration 2018 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.90953413134588)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.90953413134588)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 341.61833581800795), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 190.34460473812183), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2019 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 216.55291592729463), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 216.55291592729463), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 274.2197117118926), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 217.13328390988397), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2020 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.8619940391866)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.8619940391866)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.24137730730644), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 216.27311657152634), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2021 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 199.45287914557346)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 199.45287914557346)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 365.81029221429725), ('move_right', -30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 197.74122331668528), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2022 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 201.680462738578), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 201.680462738578), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 353.9364211158064), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.764405)]
Reward: 216
Iteration 2023 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.71562842146466)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.71562842146466)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 341.2362164940421), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 181.0188563216797), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2024 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 215.18475832765048), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 215.18475832765048), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 298.9532083949343), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 202.4619368940095)]
Reward: 215
Iteration 2025 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.01162424508)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.01162424508)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 325.10836808442366), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 227.2698611391306)]
Reward: 215
Iteration 2026 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 208.1428014237396), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 208.1428014237396), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 351.7848162810645), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.76797329536421), ('move_right', 0)]
Reward: 215
Iteration 2027 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.2804667987252)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.2804667987252)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 340.7568160008357), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 191.2131994251758), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2028 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 222.27522528277916), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 222.27522528277916), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 357.5176632952115), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 213.641573671148), ('move_right', 0)]
Reward: 215
Iteration 2029 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.26319096120045)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 244.26319096120045)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 338.17100844233335), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 198.34923959762304), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2030 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 233.88777608835096), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 233.88777608835096), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 353.5797633853544), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.93758130675496), ('move_right', 0)]
Reward: 215
Iteration 2031 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.47535560738243)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.47535560738243)]
best: move_right current state : (1, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 228.9295403377837)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 193.99118160006844), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2032 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 206.8765086770822), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 206.8765086770822), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 360.38957154501367), ('move_right', -30.0)]
best: move_right current state : (0, 1.75, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 167.63773799999998)]
Reward: 278
Iteration 2033 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.93911910240678)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 206.93911910240678)]
best: move_left current state : (1, 1.75, -18) -37.241639747 [('nothing', 0), ('move_left', 361.3508990865724), ('move_right', -4.736258560676714)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 223.58890279739143)]
Reward: 142
Iteration 2034 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 220.3999224680327)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 220.3999224680327)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 315.38421099677)]
best: move_left current state : (0, -1.75, -7) 150 [('nothing', 0), ('move_left', 138.48), ('move_right', 0)]
Reward: 289
Iteration 2035 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 131.5475403998213), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 131.5475403998213), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 226.61136711), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 4, 3) 200 [('nothing', 0), ('move_left', 96.89999999999999), ('move_right', 0)]
Reward: 215
Iteration 2036 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 240.8351916792941), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 240.8351916792941), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 315.00582694465686), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.4563069147285), ('move_right', 0)]
Reward: 216
Iteration 2037 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.09016117356043)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.09016117356043)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 341.22447778892024), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.35614533437374)]
Reward: 215
Iteration 2038 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 230.9138903348069), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 230.9138903348069), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 355.48710876177455), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.81941484030995), ('move_right', 0)]
Reward: 215
Iteration 2039 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.76691794512038)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.76691794512038)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 340.8937310281377), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.64930173406162)]
Reward: 215
Iteration 2040 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 236.11336393880117), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 236.11336393880117), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 302.09378337129004), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.0491015698036), ('move_right', 0)]
Reward: 215
Iteration 2041 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 225.33246994592957)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 225.33246994592957)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 346.5204022399149), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.25451121384313)]
Reward: 215
Iteration 2042 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 223.7349978444518), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 223.7349978444518), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 357.68680058533516), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.47359038821696), ('move_right', 0)]
Reward: 215
Iteration 2043 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.51635771002915)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 229.51635771002915)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 346.0639780525563), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.37815784969018)]
Reward: 215
Iteration 2044 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 231.74804674262077), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 231.74804674262077), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 359.4228375261997), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.93151327175187), ('move_right', 0)]
Reward: 215
Iteration 2045 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.30815188869127)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.30815188869127)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 350.9582319916965), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 222.4938271200479), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2046 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 241.09030337953655), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 241.09030337953655), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 344.6366312220658), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 228.29831315619205), ('move_right', 0)]
Reward: 215
Iteration 2047 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.94299532143495)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.94299532143495)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 365.0223001998181), ('move_right', -4.736258560676714)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 199.112231958174)]
Reward: 142
Iteration 2048 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 216.72271710255785)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 216.72271710255785)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 297.29513864203744)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.9602808)]
Reward: 289
Iteration 2049 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 59.910786355778875), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 59.910786355778875), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -0.5, -19) -26.5339353272 [('nothing', 319.0028607226624), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 250.22678374019463), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2050 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.19402113413742), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.19402113413742), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 320.6803788308441), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 202.5350835)]
Reward: 215
Iteration 2051 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.806606186792)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.806606186792)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 333.2548988276923), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.16471049478312)]
Reward: 152
Iteration 2052 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 208.7219516403057)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 208.7219516403057)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 347.5640214815096), ('move_right', -30.0)]
best: nothing current state : (0, -1.0, -10) 150 [('nothing', 191.61592173000003), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2053 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 234.2674365190534), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 234.2674365190534), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 330.2367902315909), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -10) 150 [('nothing', 0), ('move_left', 171.06512999999998), ('move_right', 0)]
best: nothing current state : (2, 3, 3) 200 [('nothing', 139.81754999999998), ('move_right', 0)]
Reward: 217
Iteration 2054 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.26860205496607)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.26860205496607)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 357.4189105302019), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 203.34446771833612), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2055 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 230.8857507087186), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 230.8857507087186), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 328.94097093567837), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 224.30881920933444), ('move_right', 0)]
best: nothing current state : (2, 3, 2) 200 [('nothing', 117.294), ('move_right', 0)]
Reward: 215
Iteration 2056 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.15351399937893)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.15351399937893)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 342.22784232781953), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 217.75059764630507), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2057 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 221.41439199450897)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 221.41439199450897)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 296.6066067996291), ('move_right', -20.37)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 198.02541835241354), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2058 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 228.1298248527105), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 228.1298248527105), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 342.55132541777516), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.22335582580666)]
Reward: 216
Iteration 2059 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.5033205738151)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.5033205738151)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 349.8846689233652), ('move_right', 0)]
best: nothing current state : (0, -1.75, -11) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -4, 3) 100 [('nothing', 0), ('move_left', 96.15), ('move_right', 0)]
Reward: 86
Iteration 2060 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 186.6836373840774)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 186.6836373840774)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 312.0322502654644), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 206.8411274028353), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2061 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 227.09273680918187), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 227.09273680918187), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 346.6529345401846), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.2520592902263), ('move_right', 0)]
Reward: 194
Iteration 2062 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.24523315458413)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.24523315458413)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 356.1965776866422), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 190.38878918198472), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2063 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 227.59725791543468), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 227.59725791543468), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 327.4852921621136), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 252.2043734465341), ('move_right', 0)]
best: nothing current state : (2, 3, 2) 200 [('nothing', 146.6058), ('move_right', 0)]
Reward: 215
Iteration 2064 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.17045591604364)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.17045591604364)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 351.45424113524496), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 184.21779284668946), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2065 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 225.39117626534232), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 225.39117626534232), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 349.9010165474397), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.5870965773385)]
Reward: 215
Iteration 2066 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.19541088364616)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.19541088364616)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 346.2833066486783), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.8152973463482)]
Reward: 215
Iteration 2067 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 230.5716364258755), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 230.5716364258755), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 360.77544024986537), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.1764415031584), ('move_right', 0)]
Reward: 215
Iteration 2068 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.0615990149979)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.0615990149979)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.2492797273249), ('move_right', -4.736258560676714)]
best: move_left current state : (0, -1.75, -7) 150 [('nothing', 0), ('move_left', 183.636), ('move_right', 0)]
Reward: 152
Iteration 2069 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 215.01187583788712)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 215.01187583788712)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 314.5946812894262)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 214.719069), ('move_right', 0)]
Reward: 289
Iteration 2070 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 108.67822806768604), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 108.67822806768604), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -19) -47.8784607102 [('nothing', 0), ('move_left', 332.93411495220937), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 150 [('nothing', 228.1166021163271), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2071 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 212.7142255492528)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 212.7142255492528)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 329.63199760259835)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 169.31205)]
Reward: 289
Iteration 2072 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 140.59145591999504), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 140.59145591999504), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 320.64070293560377), ('move_left', -30.0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 244.68179858206113), ('move_right', 0)]
Reward: 215
Iteration 2073 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 240.67259697491457), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 240.67259697491457), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 359.9957406258533), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.2235090522109), ('move_right', 0)]
Reward: 216
Iteration 2074 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.1577226305381)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.1577226305381)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 345.8429038579793), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.87070814244373)]
Reward: 215
Iteration 2075 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 247.50935947203828), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 247.50935947203828), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 360.06407115376055), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.95645633654763), ('move_right', 0)]
Reward: 215
Iteration 2076 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.7030964006126)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.7030964006126)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 347.35124514331864), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.218435)]
Reward: 204
Iteration 2077 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 252.31559237839707), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 252.31559237839707), ('move_right', -30.0)]
best: nothing current state : (0, 1.75, -19) -26.5339353272 [('nothing', 304.6491295133164), ('move_left', -11.172491924096027), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.86951943558336), ('move_right', 0)]
Reward: 204
Iteration 2078 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.1373604252665)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.1373604252665)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 349.711402100323), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 220.24567898403353), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2079 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 239.05547292071498), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 239.05547292071498), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 351.93267196519713), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.27455845)]
Reward: 215
Iteration 2080 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.23708100368745)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.23708100368745)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 355.8716851654362), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 218.67197528882346), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2081 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 237.5550944210116), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 237.5550944210116), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.73513580230366), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 208.66308370121467)]
Reward: 215
Iteration 2082 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.2672816540542)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.2672816540542)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 359.7117722024524), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -11) 150 [('nothing', 91.02000000000001), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2083 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.74892623724134), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.74892623724134), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 360.6317867085967), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 280.5248014125739), ('move_right', 0)]
Reward: 215
Iteration 2084 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.32813689447764)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.32813689447764)]
best: move_right current state : (1, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 263.44803271646913)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.8529045)]
Reward: 278
Iteration 2085 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 223.97024693930373), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 223.97024693930373), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 379.5413880280546), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 245.64848494436475), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 2086 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 215.61706524116045)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 215.61706524116045)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 345.77959155605674), ('move_right', -30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 197.7721524273893), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2087 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 249.85360378049003), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 249.85360378049003), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 359.3548364079924), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.51096760413697)]
Reward: 215
Iteration 2088 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.49161371697906)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.49161371697906)]
best: move_right current state : (1, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 290.8694942515284)]
best: nothing current state : (0, -1.75, -11) 150 [('nothing', 58.845), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2089 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 238.46909734183296), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 238.46909734183296), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 384.37351710294763), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 233.15393946105533), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2090 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 222.4933312115333)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 222.4933312115333)]
best: nothing current state : (0, -0.5, -19) -26.5339353272 [('nothing', 343.37003762792204), ('move_left', 0), ('move_right', -30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 184.0405066991725), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2091 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 250.06793134607133), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 250.06793134607133), ('move_right', -30.0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 282.2884056063259)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 247.697956977), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2092 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.74379297058286), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.74379297058286), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 359.70167576683576), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 260.8673609888017), ('move_right', 0)]
Reward: 204
Iteration 2093 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.53248595324783)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.53248595324783)]
best: move_right current state : (1, 2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 266.26214597606986)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 193.32835468942076), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2094 Learning Q-Table
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', 43.488502309772436), ('move_right', -57.68726494502512)]
best: move_left current state : (0, -1.5, -24) -100.0 [('nothing', -72.0), ('move_left', 43.488502309772436), ('move_right', -57.68726494502512)]
best: nothing current state : (0, 0.75, -19) -15.7875285356 [('nothing', 384.00764381037993), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -7) 200 [('nothing', 243.08162148142898), ('move_left', 0), ('move_right', 0)]
Reward: 237
Iteration 2095 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 229.79616253829204)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 229.79616253829204)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 326.5360133218188)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.02984828259454), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2096 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 165.64604942651977), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 165.64604942651977), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -0.75, -20) -37.241639747 [('nothing', 112.98341013299999), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 239.65874861813626), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2097 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.3586658853627), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.3586658853627), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 381.59969111978984), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.89219091500001)]
Reward: 216
Iteration 2098 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.7788920359984)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 195.7788920359984)]
best: move_right current state : (1, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 289.38200859007515)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 230.17219656)]
Reward: 289
Iteration 2099 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 227.56158170005168), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 227.56158170005168), ('move_right', -30.0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 316.9112710175281)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 232.2611240326954), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2100 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 262.87079285753293), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 262.87079285753293), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 353.235237910638), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.0245336405)]
Reward: 215
Iteration 2101 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.68733507812541)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 191.68733507812541)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 324.10424054171665), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.1094956997106)]
Reward: 204
Iteration 2102 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 257.80763444936844), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 257.80763444936844), ('move_right', -30.0)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 329.4256487579294), ('move_right', -27.759)]
best: move_right current state : (2, 3, -10) 150 [('nothing', 0), ('move_right', 116.556)]
Reward: 204
Iteration 2103 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 199.23991479310675)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 199.23991479310675)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 333.4058170891148), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 181.9785623707218)]
Reward: 215
Iteration 2104 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 250.33285814377885), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 250.33285814377885), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 374.7874410583529), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.15634907806466)]
Reward: 215
Iteration 2105 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.31719355781314)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 207.31719355781314)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 352.26529580912745), ('move_right', -4.736258560676714)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 163.41254074838074), ('move_right', 0)]
Reward: 142
Iteration 2106 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 226.64562584925403)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 226.64562584925403)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 325.4749134066757), ('move_right', -20.37)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 193.45245499268262), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2107 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 258.70905241999316), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 258.70905241999316), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 375.0513813334255), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.85767732289588)]
Reward: 215
Iteration 2108 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.84144363504953)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.84144363504953)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 332.9776406735969), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.77664698979743)]
Reward: 204
Iteration 2109 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 264.651570495865), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 264.651570495865), ('move_right', -30.0)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 310.56475413055057), ('move_right', -27.759)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 214.33437109886253), ('move_right', 0)]
Reward: 205
Iteration 2110 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 219.81876453356574)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 219.81876453356574)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 339.5173425684571), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.5436528928582)]
Reward: 204
Iteration 2111 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 249.46534498811275), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 249.46534498811275), ('move_right', -30.0)]
best: move_left current state : (0, 2, -19) -26.5339353272 [('nothing', 0), ('move_left', 326.6956392210442), ('move_right', -27.759)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.20866360490834), ('move_right', 0)]
Reward: 204
Iteration 2112 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.55584601993712)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.55584601993712)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 344.0252356657774), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 242.12089379781617), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2113 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.67425265983428), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 243.67425265983428), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 370.0981134642664), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.34606452343584), ('move_right', 0)]
Reward: 215
Iteration 2114 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.7364823155313)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.7364823155313)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 364.12355434778505), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -7) 150 [('nothing', 0), ('move_left', 0), ('move_right', 191.88499365950526)]
Reward: 215
Iteration 2115 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 252.641230303006), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 252.641230303006), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -18) -37.241639747 [('nothing', 0), ('move_left', 355.913520171977), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 210.56415859085027)]
Reward: 215
Iteration 2116 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.58011200111142)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.58011200111142)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 358.45393310538907), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.38055702500074)]
Reward: 215
Iteration 2117 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 251.45042533960128), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 251.45042533960128), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 366.57249878201725), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.90944435464527)]
Reward: 215
Iteration 2118 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.5820777342368)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.5820777342368)]
best: move_right current state : (1, 2.0, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 316.6190649810526)]
best: nothing current state : (0, -1.75, -11) 150 [('nothing', 124.5915), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2119 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 222.19399657119857), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 222.19399657119857), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 401.7298371116947), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, 3, -8) 150 [('nothing', 0), ('move_left', 235.7772590074428), ('move_right', 0)]
Reward: 215
Iteration 2120 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 195.32804065033562)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 195.32804065033562)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 330.8681758824778), ('move_right', -20.37)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 217.57038270217643), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2121 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 257.0268667741682), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 257.0268667741682), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 355.57202662959656), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.3422451664051), ('move_right', 0)]
Reward: 205
Iteration 2122 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.52963569523354)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.52963569523354)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 350.94063493209336), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.56638991750052)]
Reward: 204
Iteration 2123 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 254.41792280670066), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 254.41792280670066), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 352.5068405564094), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 4, -9) 150 [('nothing', 156.8115), ('move_right', 0)]
Reward: 204
Iteration 2124 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.18044354219546)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 235.18044354219546)]
best: move_right current state : (1, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 304.0107954867368)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 233.98462565847132), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2125 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 247.0945681351895), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 247.0945681351895), ('move_right', -30.0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 336.5162269220783)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 215.9885698839), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2126 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 251.67210620751723), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 251.67210620751723), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.8735824538057), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 208.73957161648357), ('move_right', 0)]
Reward: 204
Iteration 2127 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.65705720146184)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.65705720146184)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 289.91926824635567), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 181.01671849487784), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2128 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 227.33423151832264)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 227.33423151832264)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 346.3773598174565), ('move_right', -30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 247.18923796092992), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2129 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.46005715730774), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.46005715730774), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 338.7982383894866), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 216.49329873691877), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2130 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.36322859083398)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 211.36322859083398)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 357.23192028127255), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.63246657265094), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2131 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 246.88901960286537), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 246.88901960286537), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 357.0030921906391), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.21717354835002)]
Reward: 216
Iteration 2132 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.95134417386953)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 222.95134417386953)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 359.75208416868605), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -11) 150 [('nothing', 170.61405), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2133 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 247.75074945510147), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 247.75074945510147), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 371.09327013026666), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.80037412602712)]
Reward: 215
Iteration 2134 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.81907424821847)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 231.81907424821847)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 302.24850332091233), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 215.44272660085565), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2135 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 234.0869894099049)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 234.0869894099049)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 340.18416381005153)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 247.820537592)]
Reward: 289
Iteration 2136 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 117.67476571436781), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 117.67476571436781), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.5, -20) -37.241639747 [('nothing', 0), ('move_left', 106.37630019000001), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 196.79199891873), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2137 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 233.74364980585284)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 233.74364980585284)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 361.62092326049856), ('move_right', -30.0)]
best: move_left current state : (0, -1.25, -10) 150 [('nothing', 0), ('move_left', 237.0033483), ('move_right', 0)]
Reward: 131
Iteration 2138 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 255.79332505949313), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 255.79332505949313), ('move_right', -30.0)]
best: move_right current state : (0, 2.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 336.07003353698974)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 211.8949110135952)]
Reward: 142
Iteration 2139 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 207.0299006218204)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 207.0299006218204)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 341.8788379283874), ('move_right', -20.37)]
best: nothing current state : (0, -1.5, -8) 150 [('nothing', 156.7870576971), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2140 Learning Q-Table
best: move_left current state : (0, 1.0, -24) -100.0 [('nothing', -3.166126952631439), ('move_left', 73.08077730477065), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 1.0, -24) -100.0 [('nothing', -3.166126952631439), ('move_left', 73.08077730477065), ('move_right', -28.960180598157898)]
best: move_left current state : (0, 2.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 336.7495465362034), ('move_right', -27.759)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.31770013153852), ('move_right', 0)]
Reward: 184
Iteration 2141 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.7754110459306)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 220.7754110459306)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 348.0106739180802), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -11) 150 [('nothing', 183.929835), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2142 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 250.91615700458422), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 250.91615700458422), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.30871169763896), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 243.8071526921612), ('move_right', 0)]
Reward: 215
Iteration 2143 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.77349798347947)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.77349798347947)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 343.78642224265616), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 196.40990862059897), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2144 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.87374281434273), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.87374281434273), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 363.033379202609), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 200.32239009207697), ('move_right', 0)]
Reward: 215
Iteration 2145 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.91719466307458)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 232.91719466307458)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 344.573468156039), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 206.49647294225036)]
Reward: 215
Iteration 2146 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 257.66145313266475), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 257.66145313266475), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 368.6054013289948), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.46026188821898)]
Reward: 204
Iteration 2147 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.453896112806)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.453896112806)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 348.1503695919024), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.04753105957525)]
Reward: 215
Iteration 2148 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 258.7721456674677), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 258.7721456674677), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 367.06185949676205), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.62218332175328)]
Reward: 215
Iteration 2149 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.4903462324389)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 238.4903462324389)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 351.4195180322043), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 194.8992678915235), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2150 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 262.29887921809814), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 262.29887921809814), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 347.10675649371626), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 3, -10) 150 [('nothing', 0), ('move_left', 221.690856), ('move_right', 0)]
Reward: 204
Iteration 2151 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.40891717421061)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 243.40891717421061)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 396.9440636804191), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 201.98693603441927), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2152 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 255.56875047668754), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 255.56875047668754), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 354.4819863456014), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.1366110482517)]
Reward: 215
Iteration 2153 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.5092805279153)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.5092805279153)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 383.45692538661916), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -3, -9) 150 [('nothing', 0), ('move_left', 103.29), ('move_right', 0)]
Reward: 215
Iteration 2154 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.07022931326566), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 253.07022931326566), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 356.7783737563965), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.9355283252273)]
Reward: 215
Iteration 2155 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.43339338736854)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.43339338736854)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 344.4068477706334), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 236.25567482809237)]
Reward: 215
Iteration 2156 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 252.01018072210888), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 252.01018072210888), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 365.12995664425944), ('move_left', -10.930128756135296), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.85486982765912)]
Reward: 215
Iteration 2157 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.2652491041901)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.2652491041901)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 356.9614958878711), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 2158 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 256.98593290059614), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 256.98593290059614), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 368.2582439959956), ('move_right', 0)]
best: move_left current state : (1, 2, -7) 150 [('nothing', 0), ('move_left', 178.82385), ('move_right', 0)]
Reward: 226
Iteration 2159 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.7139425411365)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.7139425411365)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 321.2067703048953), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 169.31170294641447), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2160 Learning Q-Table
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 243.14665124408867)]
best: move_right current state : (0, 2.0, -24) -100.0 [('nothing', -12.08367501019269), ('move_left', -30.0), ('move_right', 243.14665124408867)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 331.3513038590012), ('move_right', -20.37)]
best: move_right current state : (0, -1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 260.1743763144)]
best: move_right current state : (0, -2, 3) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 170
Iteration 2161 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 241.74857384716012), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 241.74857384716012), ('move_right', -30.0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 345.35792981062485)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 227.70775762273874), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2162 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 261.40744563105807), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 261.40744563105807), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 359.2200824694494), ('move_right', 0)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.35202148384502)]
Reward: 215
Iteration 2163 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.3892989461681)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 247.3892989461681)]
best: move_left current state : (1, 1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 320.63825009735103), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.83327174170267)]
best: move_left current state : (0, -4, 3) 150 [('nothing', 0), ('move_left', 93.105), ('move_right', 0)]
Reward: 181
Iteration 2164 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 258.57874475847944), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 258.57874475847944), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 360.4596641737681), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 235.16500688451285), ('move_right', 0)]
Reward: 215
Iteration 2165 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.19149236742697)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.19149236742697)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 349.46344299000003), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 205.89085522409349), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2166 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 260.1828399849081), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 260.1828399849081), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 367.87126698699154), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.9956277337762)]
Reward: 215
Iteration 2167 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.91289695604098)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.91289695604098)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 351.39166666022805), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 226.79703315)]
Reward: 215
Iteration 2168 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 263.5291874873753), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 263.5291874873753), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -37.241639747 [('nothing', 364.44743059927936), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 204.72567306445387), ('move_right', 0)]
Reward: 215
Iteration 2169 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.7963472691392)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.7963472691392)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 359.01327660715964), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 164.11819206249012), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2170 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 261.63216849685045), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 261.63216849685045), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 366.4085752110269), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 207.8079711451177), ('move_right', 0)]
Reward: 215
Iteration 2171 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.80124547238745)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.80124547238745)]
best: nothing current state : (1, 1.75, -19) -26.5339353272 [('nothing', 345.5447512437588), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.51479021919187)]
Reward: 215
Iteration 2172 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 264.1049099129455), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 264.1049099129455), ('move_right', -30.0)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 363.82839399125413), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.9655798015824), ('move_right', 0)]
Reward: 215
Iteration 2173 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.264116605641)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.264116605641)]
best: move_right current state : (1, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 328.00294453825717)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.86035315343432)]
Reward: 289
Iteration 2174 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 240.6588887121035), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 240.6588887121035), ('move_right', -30.0)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 355.062878154259)]
best: nothing current state : (0, 2.0, -10) 150 [('nothing', 221.15439924311102), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 2, 3) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 108
Iteration 2175 Learning Q-Table
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 265.0617745382802), ('move_right', -30.0)]
best: move_left current state : (0, 0.25, -24) -100.0 [('nothing', -11.263576948576292), ('move_left', 265.0617745382802), ('move_right', -30.0)]
best: nothing current state : (0, 1.25, -19) -26.5339353272 [('nothing', 361.5309033388317), ('move_left', -10.930128756135296), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 211.53405976920376), ('move_right', 0)]
Reward: 213
Iteration 2176 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.41327306132982)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.41327306132982)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 352.9283614277155), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 179.3827344437431), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2177 Learning Q-Table
best: move_right current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: move_right current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', -30.0), ('move_right', -15.611403493750192)]
best: move_right current state : (0, -0.25, -20) -47.8784607102 [('nothing', 0), ('move_left', 0), ('move_right', 8.034238026384685)]
best: move_right current state : (-1, -3, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 42.6)]
best: move_left current state : (-2, -4, 3) 250 [('nothing', 0), ('move_left', 0)]
Reward: 254
Iteration 2178 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 5.358908904866215)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 5.358908904866215)]
best: nothing current state : (-1, -1.5, -19) -26.5339353272 [('nothing', 206.87244195), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -10) 150 [('nothing', 199.80807947017772), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2179 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', -30.0), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', -30.0), ('move_right', -43.881249250757726)]
best: move_right current state : (0, 0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 322.5638566469163)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.4984088793614)]
best: nothing current state : (0, 3, 2) 150 [('nothing', 45.6), ('move_left', 0), ('move_right', 0)]
Reward: 34
Iteration 2180 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 43.596665069978854), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 43.596665069978854), ('move_right', -43.881249250757726)]
best: move_left current state : (0, 1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 362.6695497343526), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.12888621555297)]
Reward: 254
Iteration 2181 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.90761897308764)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.90761897308764)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 345.8646733325238), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 208.62359865686545), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2182 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 110.35834987113307), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 110.35834987113307), ('move_right', -43.881249250757726)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 294.8730471215098), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.4759058611077), ('move_right', 0)]
Reward: 215
Iteration 2183 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.93455468276062)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.93455468276062)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 349.6923509298263), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 210.5365190598058), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2184 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 133.54026712215006), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 133.54026712215006), ('move_right', -43.881249250757726)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 314.85390474338914), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.59693941364333)]
Reward: 215
Iteration 2185 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.5894016327843)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 245.5894016327843)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 352.9456013688202), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.87556334186408), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2186 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 158.97417781036387), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 158.97417781036387), ('move_right', -43.881249250757726)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 361.3073506787127), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 221.8902203508871)]
Reward: 215
Iteration 2187 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.83608095543718)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.83608095543718)]
best: nothing current state : (1, 1.25, -19) -37.241639747 [('nothing', 319.6603231863018), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.81289433930485), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2188 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 187.50163774677247), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 187.50163774677247), ('move_right', -43.881249250757726)]
best: move_right current state : (0, 0.5, -20) -37.241639747 [('nothing', -13.71), ('move_left', 0), ('move_right', 357.47507594463605)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.01785758955032)]
Reward: 152
Iteration 2189 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 61.28886202403473)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 61.28886202403473)]
best: nothing current state : (0, 0.0, -20) -37.241639747 [('nothing', -11.172491924096029), ('move_left', -30.0), ('move_right', -30.0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.4690260375134), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2190 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 121.9383190746419), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 121.9383190746419), ('move_right', -15.460180598157898)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 186.8395413701989), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 208.18278682288678), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2191 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 7.377963915499471)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 7.377963915499471)]
best: nothing current state : (0, -0.25, -18) -26.5339353272 [('nothing', 342.85303162954096), ('move_left', -30.0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.9283182262594), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 2192 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 112.4485051651511), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 112.4485051651511), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.25, -19) -26.5339353272 [('nothing', 0), ('move_left', 354.9982255956208), ('move_right', -20.37)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 210.22795077602075), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2193 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.91086170060055)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 237.91086170060055)]
best: move_left current state : (1, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 300.11224270456785), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 190.06791411062017), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 2194 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 79.060303631554)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 79.060303631554)]
best: move_right current state : (0, -0.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 334.8442223166498)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 156.98877852386653), ('move_right', 0)]
Reward: 289
Iteration 2195 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 82.11273413296144), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 82.11273413296144), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -19) -26.5339353272 [('nothing', 0), ('move_left', 346.4888611014447), ('move_right', 0)]
best: move_left current state : (0, 3, -7) 150 [('nothing', 0), ('move_left', 231.5177904), ('move_right', 0)]
Reward: 278
Iteration 2196 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 123.62298731298671)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 123.62298731298671)]
best: move_right current state : (0, -0.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 326.4875891788148)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.94982275838157), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2197 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 132.4653916253485), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 132.4653916253485), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -1.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 120.6047473542008)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 233.85956554321453), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2198 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 156.25324069613413), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 156.25324069613413), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 369.235650772349), ('move_right', -30.0)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 204.99543033591712), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2199 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.39878407769473)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 224.39878407769473)]
best: move_left current state : (1, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 312.09894412638357), ('move_right', 0)]
best: nothing current state : (0, -2, -10) 150 [('nothing', 172.34753987743412), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2200 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 155.52218727457725)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 155.52218727457725)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 307.312947697739)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 234.3648759308671), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2201 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 99.9470177458463), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 99.9470177458463), ('move_right', -76.5965361502152)]
best: move_right current state : (0, -1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 199.58119281090492)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 206.30169588025018), ('move_left', 0), ('move_right', 0)]
Reward: 131
Iteration 2202 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 187.97547179490255), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 187.97547179490255), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 364.96358464141946), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 226.896801235142), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2203 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.53634016820536)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 218.53634016820536)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 355.6245899607334), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 247.45541315160696), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2204 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 206.3211772820355), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 206.3211772820355), ('move_right', -43.881249250757726)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 329.4768151444654), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -7) 150 [('nothing', 0), ('move_left', 192.976695), ('move_right', 0)]
Reward: 215
Iteration 2205 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 227.49032318186772)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 227.49032318186772)]
best: nothing current state : (1, 1.25, -19) -37.241639747 [('nothing', 332.60609453220275), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 237.71878920612488), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2206 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 211.09537671666843), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 211.09537671666843), ('move_right', -43.881249250757726)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 333.5267791011258), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 219.82315424562097)]
Reward: 215
Iteration 2207 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.8525626628722)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 226.8525626628722)]
best: move_left current state : (1, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 315.17352285169875), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 166.24327791420387), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2208 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 168.88692347742975)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 168.88692347742975)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 356.5671431497408), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.90315244428743), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2209 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 218.86461683384775), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 218.86461683384775), ('move_right', -43.881249250757726)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 359.8903344809146)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 195.4125003126852)]
Reward: 152
Iteration 2210 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 193.01849745502705)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 193.01849745502705)]
best: move_left current state : (0, 0.25, -20) -37.241639747 [('nothing', 0), ('move_left', 302.0678993368607), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 239.90224720740403)]
Reward: 142
Iteration 2211 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 228.99984020387177), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 228.99984020387177), ('move_right', -43.881249250757726)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.482211580365), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.3762079719347)]
Reward: 227
Iteration 2212 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.17635879542414)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.17635879542414)]
best: nothing current state : (1, 1.25, -19) -26.5339353272 [('nothing', 349.1399029343794), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 207.2322067110012), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2213 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 237.4720596927237), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 237.4720596927237), ('move_right', -43.881249250757726)]
best: move_right current state : (0, 0.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 355.5469842304458)]
best: move_right current state : (1, 2, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.8464150386915)]
Reward: 131
Iteration 2214 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 193.5608260954811)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 193.5608260954811)]
best: move_left current state : (0, 0.0, -18) -37.241639747 [('nothing', 0), ('move_left', 353.52070929380295), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 209.56254469770084), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2215 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 240.7220451299443), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 240.7220451299443), ('move_right', -43.881249250757726)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 344.41569164447435), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 229.11550481915899), ('move_right', 0)]
best: nothing current state : (2, 4, 2) 200 [('nothing', 0), ('move_right', 0)]
Reward: 226
Iteration 2216 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.60524143895285)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 230.60524143895285)]
best: move_left current state : (1, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 315.4944493704503), ('move_right', 0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 223.257923205)]
Reward: 152
Iteration 2217 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 209.37629913088165)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 209.37629913088165)]
best: move_right current state : (0, -0.0, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 336.82625925268485)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 229.87897237966465)]
Reward: 289
Iteration 2218 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 97.66477834126786), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 97.66477834126786), ('move_right', -76.5965361502152)]
best: nothing current state : (0, -1.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 242.2277608645994), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2219 Learning Q-Table
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 239.65764716020726), ('move_right', -43.881249250757726)]
best: move_left current state : (0, -0.25, -24) -100.0 [('nothing', -43.810229254203776), ('move_left', 239.65764716020726), ('move_right', -43.881249250757726)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 354.82563559687975), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -7) 150 [('nothing', 0), ('move_right', 190.92643770951662)]
Reward: 215
Iteration 2220 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.89951189430607)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 223.89951189430607)]
best: move_left current state : (1, 1.5, -20) -47.8784607102 [('nothing', 0), ('move_left', 332.8234915208152), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.53157304518282)]
Reward: 142
Iteration 2221 Learning Q-Table
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 218.6511065692647)]
best: move_right current state : (0, 1.5, -24) -100.0 [('nothing', -31.42087756820301), ('move_left', -13.147298604470329), ('move_right', 218.6511065692647)]
best: nothing current state : (0, 0.0, -20) -37.241639747 [('nothing', 101.21996346438681), ('move_left', -30.0), ('move_right', -30.0)]
best: move_right current state : (0, -1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.8805462435)]
Reward: 204
Iteration 2222 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 212.11172505069973), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 212.11172505069973), ('move_right', -15.460180598157898)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 368.54354961953624), ('move_right', -30.0)]
best: nothing current state : (0, 2.0, -10) 150 [('nothing', 204.3656556291244), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2223 Learning Q-Table
best: move_right current state : (2, 0.75, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: nothing current state : (2, 0.75, -24) -100.0 [('nothing', 0), ('move_right', 0)]
best: move_left current state : (1, -0.25, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.5, -10) 100 [('nothing', 0), ('move_left', 0), ('move_right', 227.12206342008)]
Reward: -300
Iteration 2224 Learning Q-Table
best: nothing current state : (2, 0.75, -24) -100.0 [('nothing', -11.172491924096027), ('move_right', -30.0)]
best: nothing current state : (2, 0.75, -24) -100.0 [('nothing', -11.172491924096027), ('move_right', -30.0)]
best: move_right current state : (2, 0.5, -19) -99.6587727449 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, -0.25, -7) -99.6587727449 [('nothing', 0), ('move_right', 0)]
Reward: -100
Iteration 2225 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 211.92971594531883), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 211.92971594531883), ('move_right', -56.92696867322963)]
best: move_left current state : (1, 0.5, -19) -47.8784607102 [('nothing', 0), ('move_left', 30.0), ('move_right', 0)]
best: move_right current state : (2, 2, -9) 100 [('nothing', -75.0), ('move_right', -45.962999999999994)]
Reward: 119
Iteration 2226 Learning Q-Table
best: move_right current state : (2, 0.75, -24) -100.0 [('nothing', -58.71837617034536), ('move_right', -30.0)]
best: move_right current state : (2, 0.75, -24) -100.0 [('nothing', -58.71837617034536), ('move_right', -30.0)]
best: move_right current state : (1, -0.5, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -3, -9) 150 [('nothing', 0), ('move_left', 136.803), ('move_right', 0)]
Reward: 289
Iteration 2227 Learning Q-Table
best: move_left current state : (0, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -33.64062865236543)]
best: move_left current state : (0, -3, -24) -100.0 [('nothing', -51.0), ('move_left', -30.0), ('move_right', -33.64062865236543)]
best: nothing current state : (0, -1.5, -19) -26.5339353272 [('nothing', 18.549352144944528), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.25, -8) 150 [('nothing', -52.53000000000001), ('move_left', 0), ('move_right', 57.6)]
Reward: 215
Iteration 2228 Learning Q-Table
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 230.0810918231928), ('move_right', -15.460180598157898)]
best: move_left current state : (0, -1.0, -24) -100.0 [('nothing', -30.0), ('move_left', 230.0810918231928), ('move_right', -15.460180598157898)]
best: move_right current state : (2, 1.25, -19) -26.5339353272 [('nothing', 0), ('move_right', 0)]
best: move_right current state : (2, 1.5, -9) 100 [('nothing', 0), ('move_right', 0)]
Reward: -100
Iteration 2229 Learning Q-Table
best: move_left current state : (1, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 0.0, -24) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 0.75, -19) -29.2234803541 [('nothing', 0), ('move_right', 0)]
best: move_left current state : (1, -0.5, -9) -91.9818406071 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -150
Iteration 2230 Learning Q-Table
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 119.66331650776357), ('move_right', -49.9601805981579)]
best: move_left current state : (0, -1.75, -24) -100.0 [('nothing', -49.10994), ('move_left', 119.66331650776357), ('move_right', -49.9601805981579)]
best: move_left current state : (1, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 37.2111), ('move_right', 0)]
best: move_right current state : (2, 2, -9) 100 [('nothing', -75.0), ('move_right', 3.5259)]
Reward: 136
Iteration 2231 Learning Q-Table
best: move_right current state : (2, 0.75, -24) -100.0 [('nothing', -58.71837617034536), ('move_right', -53.17249192409602)]
best: move_right current state : (2, 0.75, -24) -100.0 [('nothing', -58.71837617034536), ('move_right', -53.17249192409602)]
best: nothing current state : (1, -0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 189.2937812883906), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2232 Learning Q-Table
best: move_left current state : (0, -2, -24) -100.0 [('nothing', -56.572126418710525), ('move_left', 54.3409960536129), ('move_right', -30.0)]
best: move_left current state : (0, -2, -24) -100.0 [('nothing', -56.572126418710525), ('move_left', 54.3409960536129), ('move_right', -30.0)]
best: move_left current state : (0, -1.25, -19) -37.241639747 [('nothing', -7.960180598157898), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 1.75, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2233 Learning Q-Table
best: nothing current state : (2, 0.75, -24) -100.0 [('nothing', -58.71837617034536), ('move_right', -66.18092494502511)]
best: nothing current state : (2, 0.75, -24) -100.0 [('nothing', -58.71837617034536), ('move_right', -66.18092494502511)]
best: nothing current state : (2, 0.5, -19) -100.0 [('nothing', 0), ('move_right', -29.89763182347814)]
best: nothing current state : (2, -0.25, -8) -100.0 [('nothing', 0), ('move_right', 0)]
Reward: -150
Loading mission from ghast_survival_mission.xml
Iteration 2235 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.0281508441579), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.0281508441579), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 281.1546157880709), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.5331341027754), ('move_right', 0)]
Reward: 209
Iteration 2236 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.2131675692108)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 221.2131675692108)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.4519861413011), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 197.0056469018734), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2237 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.7059097291739), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 236.7059097291739), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 350.6558762306708), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 182.38875021887964)]
Reward: 215
Iteration 2238 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.12463254268002)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 233.12463254268002)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 368.17383691799546), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.97210113162797)]
Reward: 204
Iteration 2239 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 238.71840775552693), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 238.71840775552693), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.6496167466519), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 193.45390635111409)]
Reward: 204
Iteration 2240 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.46690193117863)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 241.46690193117863)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 354.3180843694728), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 194.18047079213957)]
Reward: 215
Iteration 2241 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.33758985470652), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.33758985470652), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 305.56817128248224), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.47319387194278), ('move_right', 0)]
Reward: 215
Iteration 2242 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.36207606450898)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 246.36207606450898)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 351.2768002962728), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 202.4039528313114), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2243 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.14658368488134), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.14658368488134), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.65041049783594), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 216.04530911584314), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2244 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.87631273588025)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 248.87631273588025)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 351.6149460567844), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 196.59214496670657), ('move_right', 0)]
Reward: 215
Iteration 2245 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.12523980467168), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.12523980467168), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 322.3396780593204), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 192.17212515321575)]
Reward: 215
Iteration 2246 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.7377221339936)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.7377221339936)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 353.0357629363887), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 206.18276698191798), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2247 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.22939068290842), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 237.22939068290842), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 328.289412187489), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.53123571035994), ('move_right', 0)]
Reward: 215
Iteration 2248 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.25464245061613)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.25464245061613)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 350.10810572976106), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 208.8279368873426), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2249 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.58721653612469), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 235.58721653612469), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.76888008323806), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 199.02048760725103)]
Reward: 215
Iteration 2250 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.5505008362017)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.5505008362017)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 353.9798641500475), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 202.1145014766946), ('move_right', 0)]
Reward: 215
Iteration 2251 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.46922367616267), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 242.46922367616267), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 345.17573842713347), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 203.81434132507573)]
Reward: 204
Iteration 2252 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.40681790625942)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.40681790625942)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 352.72405507703553), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.4263295544977)]
Reward: 204
Iteration 2253 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.10868617735787), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 241.10868617735787), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.74436234044197), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.27186499725195), ('move_right', 0)]
Reward: 215
Iteration 2254 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.44180845933437)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.44180845933437)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 352.03473742027415), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.67955582113981), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2255 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.82689710218705), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 244.82689710218705), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 361.50261313748496), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 203.87003892755303)]
Reward: 215
Iteration 2256 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.6595065494584)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.6595065494584)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 353.4202553480416), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.97568907479786), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2257 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.6571199886804), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 247.6571199886804), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 359.2128408745054), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.79030549807638), ('move_right', 0)]
Reward: 215
Iteration 2258 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.71523926493734)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.71523926493734)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 354.62818294053386), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 201.4984306881484)]
Reward: 215
Iteration 2259 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.95134433033186), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.95134433033186), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 338.5619592443503), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.15321384865348), ('move_right', 0)]
Reward: 215
Iteration 2260 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.9289417694584)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.9289417694584)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 353.68925726481825), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 205.98015103368624), ('move_right', 0)]
Reward: 215
Iteration 2261 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.8743482063795), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 246.8743482063795), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.5860802615767), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.40724969405744), ('move_right', 0)]
Reward: 215
Iteration 2262 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.19685581990845)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.19685581990845)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.7133161820852), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.8829823523585), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2263 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.8153758988426), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 248.8153758988426), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 361.7324310913209), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.58507478584022), ('move_right', 0)]
Reward: 215
Iteration 2264 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.67930200446546)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.67930200446546)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 355.9868854660685), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 205.5489014817039)]
Reward: 215
Iteration 2265 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.51800053249005), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.51800053249005), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 346.2393356256413), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.20902724928712)]
Reward: 215
Iteration 2266 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.19908511885035)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.19908511885035)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 355.8554902707591), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.38423103719273)]
Reward: 204
Iteration 2267 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.27422046227753), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 250.27422046227753), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.5882241996767), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 211.97384183844264), ('move_right', 0)]
Reward: 204
Iteration 2268 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.12351474032695)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.12351474032695)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.6642160331672), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.0689617260349)]
Reward: 215
Iteration 2269 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.79592965940122), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.79592965940122), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.4039094913065), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.70955235008816), ('move_right', 0)]
Reward: 215
Iteration 2270 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.81323320408302)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.81323320408302)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.5856397410275), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.51808764665097), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2271 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.80583168487675), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.80583168487675), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.095602348941), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.54631907450099)]
Reward: 215
Iteration 2272 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.97246324107033)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.97246324107033)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.76537411271454), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.44827320822444)]
Reward: 204
Iteration 2273 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.72027096), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.72027096), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.03081736660897), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 196.61773444577986)]
Reward: 204
Iteration 2274 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.43784457846758)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.43784457846758)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 356.6141125006892), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.8137912457571)]
Reward: 215
Iteration 2275 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.04094295788664), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.04094295788664), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 347.7673192965161), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.7966866450617), ('move_right', 0)]
Reward: 215
Iteration 2276 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.51823303103805)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.51823303103805)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 356.9740161242096), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 208.68610572358037), ('move_right', 0)]
Reward: 215
Iteration 2277 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.98636393537944), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 249.98636393537944), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.4279257971969), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.85768065154318), ('move_right', 0)]
Reward: 215
Iteration 2278 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.9824760348935)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 250.9824760348935)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 366.50769086746)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.9626613526557), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2279 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 121.98726294867518), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 121.98726294867518), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 352.8761295010798), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 234.05943260521957), ('move_left', 0), ('move_right', 0)]
Reward: 204
Iteration 2280 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 215.31208988969445)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 215.31208988969445)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 374.4033886689699), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 236.473862946859), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2281 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.9586518957668), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.9586518957668), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 357.40689249036024), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.1824233521507)]
Reward: 226
Iteration 2282 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.67985988650554)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.67985988650554)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 354.37652539547867), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.96965387202997)]
Reward: 215
Iteration 2283 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.12063215004878), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.12063215004878), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 358.5395517488974), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.9003764560802), ('move_right', 0)]
Reward: 215
Iteration 2284 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.0286789410396)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.0286789410396)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 356.0544639384441), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.47875771042098)]
Reward: 215
Iteration 2285 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.87381610560732), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 251.87381610560732), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.9568522535008), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.93026351925616), ('move_right', 0)]
Reward: 215
Iteration 2286 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.776233842103)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.776233842103)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.68175207003713), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 208.1317040628013), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2287 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.03854635181747), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.03854635181747), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 362.23112043232175), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.62769634650547)]
Reward: 215
Iteration 2288 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.78770871232535)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.78770871232535)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 357.4876430040208), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 210.19219284396092), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2289 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.02382665187272), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.02382665187272), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.4477991610522), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.43938744255382)]
Reward: 215
Iteration 2290 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.225197075738)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.225197075738)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.37024384136754), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 211.63453499077264), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2291 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.47852648053055), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.47852648053055), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 349.53024311273504), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.9511844634793), ('move_right', 0)]
Reward: 215
Iteration 2292 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.29621918133083)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.29621918133083)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.7495311861891), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 212.64417449354085), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2293 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.03386087203398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.03386087203398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 361.9452756455027), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.7317163810902), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2294 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.75972085869228)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.75972085869228)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 357.8167376678664), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.3509221454786), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2295 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.23479337997856), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.23479337997856), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 354.1565255179583), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.30757120978768)]
Reward: 215
Iteration 2296 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.7166453032866)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.7166453032866)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.47699301115006), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.5351303972947)]
Reward: 204
Iteration 2297 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.25113242321459), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.25113242321459), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 363.2500932065769), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 198.8324141120459)]
Reward: 204
Iteration 2298 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.58456901748775)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.58456901748775)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.39443422699344), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 213.845645501835), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2299 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.47832873412725), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.47832873412725), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.74887563322744), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.51220146676314), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2300 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.1673479821816)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.1673479821816)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 358.29900795600287), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.9745912781063)]
Reward: 204
Iteration 2301 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0993122056994), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0993122056994), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 355.4909036279905), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 200.38268987843213)]
Reward: 204
Iteration 2302 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.43435405023195)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.43435405023195)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 361.3179241783946), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.1822138946744)]
Reward: 215
Iteration 2303 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3566090342288), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3566090342288), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.08120786617894), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.21529984685137)]
Reward: 215
Iteration 2304 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.42693316458474)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.42693316458474)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 358.8016829526339), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.22754972627206)]
Reward: 215
Iteration 2305 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.6014967597178), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.6014967597178), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.17787338328816), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.15070989279596)]
Reward: 215
Iteration 2306 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.96686617690347)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.96686617690347)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 359.2294429847253), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.1919518512845), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2307 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.014229148631), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.014229148631), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.0697243361405), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.96582912443552), ('move_right', 0)]
Reward: 215
Iteration 2308 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.073147295154)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.073147295154)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 360.7181956446931), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.43436629589914), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2309 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.97069710672594), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.97069710672594), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.5018392255071), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.97608038710487), ('move_right', 0)]
Reward: 215
Iteration 2310 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.89416987591972)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 253.89416987591972)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 361.8330468400549), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.65928480839045)]
Reward: 215
Iteration 2311 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.6698591442024), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.6698591442024), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.7214354603807), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.10549692495718)]
Reward: 215
Iteration 2312 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.10334104106425)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.10334104106425)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 340.6094692909034), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 200.92948752406645), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2313 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 234.0792989253192)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 234.0792989253192)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 364.2901814224127), ('move_right', -30.0)]
best: move_left current state : (0, -1.25, -9) 150 [('nothing', 0), ('move_left', 116.709), ('move_right', 0)]
Reward: 131
Iteration 2314 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.11284011495985), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.11284011495985), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.13665389975364), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.07384784747003)]
Reward: 205
Iteration 2315 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.0949989178581)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.0949989178581)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.37721109327856), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.6040564071294), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2316 Learning Q-Table
best: move_left current state : (0, -1.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -1.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.0, -20) -37.241639747 [('nothing', 176.41813829812077), ('move_left', -30.0), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -9) -65.6388261835 [('nothing', -41.009699999999995), ('move_left', 0), ('move_right', -51.99000000000001)]
Reward: -300
Iteration 2317 Learning Q-Table
best: move_right current state : (0, -1.25, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 41.752949565340195)]
best: move_right current state : (0, -1.25, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 41.752949565340195)]
best: move_right current state : (0, -1.0, -19) -26.9002703422 [('nothing', 0), ('move_left', 0), ('move_right', 246.5973437317085)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.6614993658733)]
Reward: 267
Iteration 2318 Learning Q-Table
best: move_left current state : (-2, -4, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_left current state : (-2, -4, -25) -100.0 [('nothing', 0), ('move_left', 0)]
best: move_right current state : (-1, -2, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 1.5, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, 3, -5) 150 [('nothing', 0), ('move_left', 0), ('move_right', 67.8)]
Reward: 23
Iteration 2319 Learning Q-Table
best: nothing current state : (-2, -4, -25) -100.0 [('nothing', 0), ('move_left', -32.172491924096015)]
best: nothing current state : (-2, -4, -25) -100.0 [('nothing', 0), ('move_left', -32.172491924096015)]
best: move_left current state : (-2, -3, -19) -100.0 [('nothing', -7.960180598157891), ('move_left', 0)]
best: move_left current state : (-2, -1.25, -9) -100.0 [('nothing', 0), ('move_left', 0)]
Reward: -100
Iteration 2320 Learning Q-Table
best: move_left current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -30.0), ('move_right', -32.867220651351666)]
best: move_left current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -30.0), ('move_right', -32.867220651351666)]
best: move_right current state : (0, -1.25, -20) -37.241639747 [('nothing', -14.7), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 1.75, -9) 150 [('nothing', 149.1909), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2321 Learning Q-Table
best: move_right current state : (0, -1.0, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.0, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.0, -10) -55.0161685623 [('nothing', 176.731145211), ('move_left', 0), ('move_right', 0)]
Reward: -300
Iteration 2322 Learning Q-Table
best: nothing current state : (0, -1.0, -25) -100.0 [('nothing', 0), ('move_left', -11.172491924096027), ('move_right', -30.0)]
best: nothing current state : (0, -1.0, -25) -100.0 [('nothing', 0), ('move_left', -11.172491924096027), ('move_right', -30.0)]
best: nothing current state : (0, -0.75, -20) -99.6828741662 [('nothing', 195.98601167854088), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 0.0, -9) -99.6828741662 [('nothing', -75.87), ('move_left', -90.0), ('move_right', -121.5)]
Reward: -300
Iteration 2323 Learning Q-Table
best: move_right current state : (0, -1.25, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 74.13618671260365)]
best: move_right current state : (0, -1.25, -25) -100.0 [('nothing', 0), ('move_left', -30.0), ('move_right', 74.13618671260365)]
best: move_left current state : (0, -2.0, -20) -38.0885470407 [('nothing', -30.0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (-1, -3, -10) 150 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: 119
Iteration 2324 Learning Q-Table
best: move_right current state : (0, -2.0, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -53.17249192409603), ('move_right', -32.867220651351666)]
best: move_right current state : (0, -2.0, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -53.17249192409603), ('move_right', -32.867220651351666)]
best: move_left current state : (0, -2, -20) -37.241639747 [('nothing', -30.0), ('move_left', 45.0), ('move_right', 0)]
best: nothing current state : (-2, -3, -9) 150 [('nothing', 100.5), ('move_left', 0)]
Reward: 81
Iteration 2325 Learning Q-Table
best: nothing current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -53.17249192409603), ('move_right', -41.6795463800422)]
best: nothing current state : (0, -2, -25) -100.0 [('nothing', -33.666000000000004), ('move_left', -53.17249192409603), ('move_right', -41.6795463800422)]
best: move_left current state : (0, -2, -20) -100.0 [('nothing', -30.0), ('move_left', 106.65), ('move_right', 0)]
best: move_left current state : (0, -0.75, -9) -100.0 [('nothing', -90.0), ('move_left', 58.284406319063336), ('move_right', -54.3)]
best: move_left current state : (0, 2.0, 2) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
Reward: -200
Iteration 2326 Learning Q-Table
best: move_right current state : (0, -0.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -0.25, -25) -100.0 [('nothing', 0), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -19) -26.5339353272 [('nothing', 75.26454650146117), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 228.96304955611132)]
Reward: 215
Iteration 2327 Learning Q-Table
best: move_right current state : (0, -2, -25) -100.0 [('nothing', -42.571200000000005), ('move_left', -53.17249192409603), ('move_right', -41.6795463800422)]
best: move_right current state : (0, -2, -25) -100.0 [('nothing', -42.571200000000005), ('move_left', -53.17249192409603), ('move_right', -41.6795463800422)]
best: move_left current state : (-1, -2, -19) -26.5339353272 [('nothing', 0), ('move_left', 71.32669095059737), ('move_right', 0)]
best: nothing current state : (-2, -2, -10) 100 [('nothing', 0), ('move_left', 0)]
Reward: -100
Loading mission from ghast_survival_mission.xml
Iteration 2329 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.147492326302), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.147492326302), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.638555772629), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.9832562709734), ('move_right', 0)]
Reward: 209
Iteration 2330 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.70717064638822)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.70717064638822)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 361.7809182305556), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 224.77413468927793)]
Reward: 204
Iteration 2331 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5346307620422), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5346307620422), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.95843950312303), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 201.4678829149025)]
Reward: 204
Iteration 2332 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.5568029975424)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.5568029975424)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 365.6788831681723), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 218.54189428249455)]
Reward: 204
Iteration 2333 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3015927862085), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3015927862085), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 358.9247894782176), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 202.22751804043176)]
Reward: 204
Iteration 2334 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.1298888356834)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.1298888356834)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 361.64526468743384), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.1793259977462)]
Reward: 204
Iteration 2335 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.7160598697152), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.7160598697152), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.21127252665684), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.18827938968138), ('move_right', 0)]
Reward: 204
Iteration 2336 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.11200966711252)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.11200966711252)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 365.7441820130187)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 214.72283948499057), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2337 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 159.08143099030053), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 159.08143099030053), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 335.0158269956889), ('move_right', -30.0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 183.71118711617513), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2338 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.2414807727265)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.2414807727265)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 361.4297976094459), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 237.0059876394934), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2339 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.4044430686398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.4044430686398), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 364.0419659221323), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.05169349322904)]
Reward: 215
Iteration 2340 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.53779522558443)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.53779522558443)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 362.4054830805276), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 230.4041913476454), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2341 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.4355193265297), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.4355193265297), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.41781208406854), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.93618544526032)]
Reward: 215
Iteration 2342 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.22560965797135)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.22560965797135)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 369.1026546184602), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.12552819842233)]
Reward: 215
Iteration 2343 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.4577152296953), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.4577152296953), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 356.9156080468818), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.5553298116822)]
Reward: 204
Iteration 2344 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.5285425479601)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.5285425479601)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 366.537786502469), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.28786973889564)]
Reward: 215
Iteration 2345 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.5225911507552), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.5225911507552), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.44488419346135), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 220.3808533734113), ('move_right', 0)]
Reward: 226
Iteration 2346 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.5588238102167)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.5588238102167)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 366.7095166924488), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 225.78293394335176), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2347 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6390984654092), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6390984654092), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.9733240924261), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.68873086817754)]
Reward: 215
Iteration 2348 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.1438510767285)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 264.1438510767285)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 367.80509556066295), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.10150881722694)]
Reward: 215
Iteration 2349 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.7668742294182), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.7668742294182), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 358.9075245763219), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.98211160772428)]
Reward: 204
Iteration 2350 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.06973249781277)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.06973249781277)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 369.43154186771966), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 222.54805376034625), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2351 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.6365774093933), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.6365774093933), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.98794612515155), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 215.3585410267342), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 2352 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.01809471062694)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.01809471062694)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 370.36649543550766), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 220.28363763224237), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2353 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.3694961000247), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.3694961000247), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 359.82990068574264), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.587478125407)]
Reward: 204
Iteration 2354 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.15012300399513)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.15012300399513)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 365.262811473397), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.67105617205885)]
Reward: 215
Iteration 2355 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.0440792626921), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.0440792626921), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.74411157398646), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.91123468778488)]
Reward: 226
Iteration 2356 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.0114376207197)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.0114376207197)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 366.3940195376322), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.0697393204412)]
Reward: 215
Iteration 2357 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.3939083579225), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.3939083579225), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.194248508126), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.43179557277696), ('move_right', 0)]
Reward: 215
Iteration 2358 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.8537202716974)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.8537202716974)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 364.78528488299554), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.34881752430883)]
Reward: 204
Iteration 2359 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.57382980482566), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.57382980482566), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 359.7571739176419), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 202.75926262830222)]
Reward: 204
Iteration 2360 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.5606977309908)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.5606977309908)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 370.3416380945281), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.24417226701618)]
Reward: 204
Iteration 2361 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.0563411145745), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.0563411145745), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.2043745855642), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.80225690094386), ('move_right', 0)]
Reward: 204
Iteration 2362 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.32248791595595)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.32248791595595)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 365.69673547247487), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.69854634256967), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2363 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.1405705577135), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.1405705577135), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.5655126275213), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 209.4615798306607), ('move_right', 0)]
Reward: 215
Iteration 2364 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.4622702588156)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.4622702588156)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.6123983462745), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.58898243979877), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2365 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.90787258049795), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.90787258049795), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.69912459562636), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.3378642814494)]
Reward: 215
Iteration 2366 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.6471280868954)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.6471280868954)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.6053735743318), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 216.81228770785913), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2367 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.17275626094045), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.17275626094045), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 365.5256749474463), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.8365049970146)]
Reward: 215
Iteration 2368 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.87442113496843)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.87442113496843)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 343.7054747608523), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 215.155428672), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 142
Iteration 2369 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 240.9700717503512)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 240.9700717503512)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 363.8679459381048), ('move_right', -20.37)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 216.26860139550138), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2370 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.4184512687343), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.4184512687343), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.59074650137325), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.18555349791023)]
Reward: 216
Iteration 2371 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.2635566245757)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.2635566245757)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.36744781439), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 193.98802097685098), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2372 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.89764791442997), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.89764791442997), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.76918860033436), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.72988744853717)]
Reward: 215
Iteration 2373 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.4345433833621)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.4345433833621)]
best: nothing current state : (1, 1.75, -19) -47.8784607102 [('nothing', 364.65434467538955), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 200.29161468379567), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2374 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.88661819610525), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.88661819610525), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 357.65780053084), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.1231058814625), ('move_right', 0)]
Reward: 215
Iteration 2375 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.43694555792234)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.43694555792234)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 366.5972787335033), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.0709205869113)]
Reward: 204
Iteration 2376 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.34548097242964), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.34548097242964), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 357.88373928017813), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.13148383981155)]
Reward: 204
Iteration 2377 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.71255358650063)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.71255358650063)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 360.3455256779114), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 210.58027400650627), ('move_right', 0)]
Reward: 204
Iteration 2378 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.8467778665963), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.8467778665963), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 358.69739213602674), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.39203868786808)]
Reward: 204
Iteration 2379 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.02995328982786)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.02995328982786)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.3536197631283), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 204.70413027865698), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2380 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.92947022332942), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.92947022332942), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 365.01892396231676), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 209.58168928690984), ('move_right', 0)]
Reward: 215
Iteration 2381 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.06687263366007)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.06687263366007)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 364.3393712895257), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 207.7928911950599), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2382 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6961257468677), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6961257468677), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.0573982547952), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 218.55097871871394), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2383 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.47613030632374)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.47613030632374)]
best: nothing current state : (1, 1.5, -19) -26.5339353272 [('nothing', 362.37542726118596), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -10) 150 [('nothing', 158.9702945399427), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -5, 2) 200 [('nothing', 0), ('move_left', 164.25), ('move_right', 0)]
Reward: 215
Iteration 2384 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8320155751499), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8320155751499), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 357.10578610157916), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.81092121397603)]
Reward: 204
Iteration 2385 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.6857387946245)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.6857387946245)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 360.41595017648984), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 247.61528066576525)]
Reward: 215
Iteration 2386 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.95060852003067), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 252.95060852003067), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.40547239397085), ('move_right', 0)]
best: move_right current state : (1, 3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 220.9633455803543)]
Reward: 226
Iteration 2387 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.4323102850881)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.4323102850881)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 371.5757493232725), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 208.60619180455438), ('move_right', 0)]
Reward: 215
Iteration 2388 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.51457575811668), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 254.51457575811668), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 359.53433278846313), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.28617411702373), ('move_right', 0)]
Reward: 215
Iteration 2389 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.2028500724474)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.2028500724474)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 358.6587729177869), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.5496444108379)]
Reward: 215
Iteration 2390 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.84801094312456), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.84801094312456), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 359.4173266352982), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.56764484978322)]
Reward: 204
Iteration 2391 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 264.79799451309975)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 264.79799451309975)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 350.1404609341966), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 209.95502383654193), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2392 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 245.66694208258124)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 245.66694208258124)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 378.02453095233665), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.78475108758653)]
Reward: 142
Iteration 2393 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.34631372668062), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.34631372668062), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 360.0624220996437), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 222.06659736138792), ('move_right', 0)]
Reward: 215
Iteration 2394 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.7794463278914)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.7794463278914)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 367.68488206765704), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.44932576131058)]
Reward: 215
Iteration 2395 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.18865431447352), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 253.18865431447352), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.3877535596947), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.29735139484825)]
Reward: 227
Iteration 2396 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.678585125725)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.678585125725)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 353.0848298049002), ('move_right', -4.736258560676714)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 210.52433426318808), ('move_right', 0)]
Reward: 152
Iteration 2397 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 256.41403814535)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 256.41403814535)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 330.42852616767743)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 189.56851668557934), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2398 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 36.19285291479148), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 36.19285291479148), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 372.5525969929116), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 215.2978309813226), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2399 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 249.65820395389034)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 249.65820395389034)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 364.5881425753238), ('move_right', -20.37)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 197.1145280329174)]
Reward: 131
Iteration 2400 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.288203489882), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.288203489882), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 367.07283434988585), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.60814597639379)]
Reward: 205
Iteration 2401 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.4402779313197)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.4402779313197)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 365.4377792546103)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.39796167990553), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2402 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 179.689257867821), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 179.689257867821), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 238.24251500600525), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 237.40848168692582), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2403 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 251.96469361622434)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 251.96469361622434)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 333.170523323048)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 240.27857317593387), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2404 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 108.14059554006963), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 108.14059554006963), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 356.9975398910113), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 225.0416028236537), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2405 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 244.1539506041754)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 244.1539506041754)]
best: move_right current state : (0, 0.25, -18) -37.241639747 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 350.30293827891376)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 254.8950012231537), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2406 Learning Q-Table
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 36.852788220248456)]
best: move_left current state : (-2, -3, -24) -100.0 [('nothing', -51.0), ('move_left', 36.852788220248456)]
best: move_left current state : (0, -0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 362.410758770804), ('move_right', 0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 240.92912197655758), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2407 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 243.82615498250087)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 243.82615498250087)]
best: move_left current state : (0, -0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 370.3761671894349), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 177.28016962304218)]
Reward: 142
Iteration 2408 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0511008237871), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0511008237871), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 366.3334278378382), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 219.94661815297155), ('move_right', 0)]
Reward: 226
Iteration 2409 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.27934773014897)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.27934773014897)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 346.353887444813), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 166.69611873612953)]
Reward: 204
Iteration 2410 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3633070039064), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.3633070039064), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 356.45806264806816), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.1003218819166), ('move_right', 0)]
Reward: 204
Iteration 2411 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.32921772045216)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.32921772045216)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 359.2142151757531), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 193.2088000704), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 215
Iteration 2412 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.83155309899706), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.83155309899706), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.3598851870313), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.37022531734164), ('move_right', 0)]
Reward: 215
Iteration 2413 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.32222503294642)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 254.32222503294642)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 366.62583398219886)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 265.1265008562076), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2414 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 168.29505441111837), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 168.29505441111837), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.5, -18) -26.5339353272 [('nothing', 282.9923050102814), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: nothing current state : (0, 2.0, -9) 150 [('nothing', 252.0503853835903), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2415 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 252.83097804642318)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 252.83097804642318)]
best: move_left current state : (0, 0.0, -18) -37.241639747 [('nothing', 0), ('move_left', 355.3332599149723), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 237.83069646603568)]
Reward: 152
Iteration 2416 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3298721272494), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3298721272494), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -47.8784607102 [('nothing', 0), ('move_left', 367.4173849323782), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 217.48568510309974), ('move_left', 0), ('move_right', 0)]
Reward: 216
Iteration 2417 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.05312711956424)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.05312711956424)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 354.4125906441472), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 272.28855059934534), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2418 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.09258775574006), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.09258775574006), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 363.66367467816696), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.72570218347565)]
Reward: 215
Iteration 2419 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.4884742528431)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.4884742528431)]
best: move_left current state : (1, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 355.3166811423866), ('move_right', -4.736258560676714)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 183.25064126684651), ('move_left', 0), ('move_right', 0)]
Reward: 142
Iteration 2420 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 251.4091706828919)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 251.4091706828919)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 359.34605821260186), ('move_right', -20.37)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 192.96703398423165), ('move_right', 0)]
Reward: 152
Iteration 2421 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.8914219083721), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.8914219083721), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 360.3629872261244), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 221.7626327070801), ('move_right', 0)]
Reward: 216
Iteration 2422 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.4767557215483)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.4767557215483)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 358.3260343657022), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 255.10198541954173), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2423 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.9727109055399), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.9727109055399), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.1606329102408), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.70799152843296)]
Reward: 215
Iteration 2424 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.07135871663655)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.07135871663655)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 337.4565568322079), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 243.0713897936792), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2425 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.9689069087923), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.9689069087923), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.3248404956984), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.75915772213915), ('move_right', 0)]
Reward: 215
Iteration 2426 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.71442622721196)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 249.71442622721196)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 372.3588196818541), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 177.88728311529067)]
Reward: 215
Iteration 2427 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.4155063867062), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.4155063867062), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 363.0822829297596), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.39559406990307)]
Reward: 204
Iteration 2428 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.5475636654467)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.5475636654467)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.01735871188504), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -3, -8) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.08148752622498)]
Reward: 215
Iteration 2429 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.4430474255262), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.4430474255262), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 367.43787498359467), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 220.03384289495605), ('move_right', 0)]
Reward: 226
Iteration 2430 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.0283215812203)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.0283215812203)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 359.936597356187), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 234.64997285557544), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2431 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3690037688507), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.3690037688507), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 363.17627627180264), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.57691584893215)]
Reward: 215
Iteration 2432 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.34062371555245)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.34062371555245)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 354.14100672064933), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 189.02109818070346)]
Reward: 215
Iteration 2433 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.0386935956402), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.0386935956402), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.78288087041113), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.7314104054974), ('move_right', 0)]
Reward: 215
Iteration 2434 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.3082466929855)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.3082466929855)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 349.60503415866555), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 196.81476872649242)]
Reward: 204
Iteration 2435 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5017691799136), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.5017691799136), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.4507404182227), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.4119872838482), ('move_right', 0)]
Reward: 204
Iteration 2436 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.1247910085935)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.1247910085935)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 374.77537863070665), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 198.9703381085447)]
Reward: 204
Iteration 2437 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.62627995324846), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.62627995324846), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 362.3964681449415), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.57442708150765)]
Reward: 204
Iteration 2438 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.74747537113143)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 256.74747537113143)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 348.7679545290136), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 228.7549809989028), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2439 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6848444866603), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6848444866603), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 359.74985582591137), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.9038410942525)]
Reward: 204
Iteration 2440 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.18112719440006)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 252.18112719440006)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 367.35061000600354), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 200.4792366759813)]
Reward: 215
Iteration 2441 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.5318559643396), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.5318559643396), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.15513566363063), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 217.0399795721698), ('move_left', 0), ('move_right', 0)]
Reward: 226
Iteration 2442 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.7717914397232)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.7717914397232)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.28919800699686), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 224.62848669923196), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2443 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.958659275969), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.958659275969), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 363.46743973093703), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.58839109869373), ('move_right', 0)]
Reward: 215
Iteration 2444 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.1668328117474)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.1668328117474)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 357.76406246998033), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 204.83546567318692)]
Reward: 215
Iteration 2445 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8388014883634), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8388014883634), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.603725141264), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.53268876597676)]
Reward: 215
Iteration 2446 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.27350978512123)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.27350978512123)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 365.9909846146674), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 207.88482597123084)]
Reward: 215
Iteration 2447 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.0080979860757), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.0080979860757), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 363.6205888361924), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 211.2071825008369), ('move_right', 0)]
Reward: 215
Iteration 2448 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.9285716358272)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.9285716358272)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.55913702163645), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.75, -8) 150 [('nothing', 170.87544888679255), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2449 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.83166464295283), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.83166464295283), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 368.2166653570031), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.17288213618372)]
Reward: 215
Iteration 2450 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.7575606534121)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.7575606534121)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 350.7540305811833), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 221.73994068946237), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2451 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.2746729330719), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 262.2746729330719), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 366.10353039075727), ('move_right', 0)]
best: nothing current state : (2, 4, -8) 150 [('nothing', 212.3450277505858), ('move_right', 0)]
Reward: 215
Iteration 2452 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.1963210335856)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.1963210335856)]
best: nothing current state : (1, 1.5, -18) -37.241639747 [('nothing', 357.04980361366705), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.71795848262366), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2453 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.2508382462815), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.2508382462815), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 360.3960514064137), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 211.91187376908562), ('move_right', 0)]
Reward: 215
Iteration 2454 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.079873883514)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.079873883514)]
best: nothing current state : (1, 1.5, -19) -47.8784607102 [('nothing', 356.8854834309423), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 210.01937817986158)]
Reward: 215
Iteration 2455 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8219102702251), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.8219102702251), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.97597959870586), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.83831163835993), ('move_right', 0)]
Reward: 215
Iteration 2456 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.6580185346945)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 251.6580185346945)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 360.85025007435405), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 218.30257093783655), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2457 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.4956391446733), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.4956391446733), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.3346792106021), ('move_right', 0)]
best: nothing current state : (1, 3, -9) 150 [('nothing', 219.72798570051887), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2458 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.45550739843446)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.45550739843446)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 363.0859463333988), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2.0, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.5135647259031)]
Reward: 215
Iteration 2459 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0748592403559), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0748592403559), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 365.95267115757713), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.3210174953286)]
Reward: 215
Iteration 2460 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.78445848076586)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.78445848076586)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 381.1760340444015)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.3117996564856), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2461 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 173.7440489927094), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 173.7440489927094), ('move_right', -56.92696867322963)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 360.85079811521524), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 230.68593718084807), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2462 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 251.61774501770884)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 251.61774501770884)]
best: move_right current state : (0, 0.25, -18) -26.5339353272 [('nothing', -7.960180598157894), ('move_left', -8.050428508287618), ('move_right', 366.6805571621857)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 238.8182597595399), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2463 Learning Q-Table
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 150.6251869212561), ('move_right', -76.5965361502152)]
best: move_left current state : (-1, -2, -24) -100.0 [('nothing', -60.0), ('move_left', 150.6251869212561), ('move_right', -76.5965361502152)]
best: move_left current state : (0, -0.75, -19) -37.241639747 [('nothing', 0), ('move_left', 370.96626773253007), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 225.98015602659365), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2464 Learning Q-Table
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 257.176408062894)]
best: move_right current state : (0, 1.75, -24) -100.0 [('nothing', -71.73597830811146), ('move_left', -68.02412154865192), ('move_right', 257.176408062894)]
best: move_left current state : (0, 0.25, -19) -37.241639747 [('nothing', 0), ('move_left', 354.4323509440908), ('move_right', -20.37)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 199.74616004928), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 152
Iteration 2465 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.26571089142624), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.26571089142624), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.8631750589026), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.12471224673)]
Reward: 216
Iteration 2466 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.54175055169867)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 266.54175055169867)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 357.8256518556181), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.55949530813217)]
Reward: 204
Iteration 2467 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0724582175731), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.0724582175731), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 359.9391144779104), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.70209895705534)]
Reward: 204
Iteration 2468 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.75442901877847)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 261.75442901877847)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 362.61423185115007), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 250.57278183167793), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2469 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6722744975164), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.6722744975164), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.34163621525084), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 213.987298572711)]
Reward: 215
Iteration 2470 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.05218927033206)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.05218927033206)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 367.0338664740581), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 180.67692378896214), ('move_right', 0)]
Reward: 215
Iteration 2471 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.9005910887407), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.9005910887407), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.8965669355857), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.2911090008977)]
Reward: 215
Iteration 2472 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.07420050735385)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 262.07420050735385)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.2458048913723), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.99164671569253)]
Reward: 215
Iteration 2473 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.13920324463635), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.13920324463635), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.2353349224889), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.5037763006284)]
Reward: 215
Iteration 2474 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.05318989846336)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.05318989846336)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 359.46955743866835), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.49415270098476)]
Reward: 215
Iteration 2475 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.8955508238961), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.8955508238961), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 361.6824142286778), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.48681814685196), ('move_right', 0)]
Reward: 215
Iteration 2476 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.0056082364288)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.0056082364288)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.07693601736327), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 212.54590689068934)]
Reward: 204
Iteration 2477 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.4714292471727), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.4714292471727), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 358.06800982165385), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.94077270279638), ('move_right', 0)]
Reward: 204
Iteration 2478 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.75451464661313)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 255.75451464661313)]
best: move_right current state : (1, 1.25, -18) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 377.0167637280267)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 239.90094728217454), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2479 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 197.7035818053651), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 197.7035818053651), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 334.62443503183476), ('move_right', -30.0)]
best: nothing current state : (0, 2, -9) 150 [('nothing', 240.93526976851322), ('move_left', 0), ('move_right', 0)]
Reward: 278
Iteration 2480 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.9606974469412)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.9606974469412)]
best: move_right current state : (1, 1.25, -18) -26.5339353272 [('nothing', 0), ('move_left', 0), ('move_right', 380.88201879427106)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 254.6306630975222), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2481 Learning Q-Table
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 206.60734584920996), ('move_right', -56.92696867322963)]
best: move_left current state : (0, -0.75, -24) -100.0 [('nothing', -51.0), ('move_left', 206.60734584920996), ('move_right', -56.92696867322963)]
best: move_left current state : (0, 0.75, -18) -26.5339353272 [('nothing', 0), ('move_left', 362.2237354041301), ('move_right', 0)]
best: nothing current state : (0, 2, -8) 150 [('nothing', 244.88610921861556), ('move_left', 0), ('move_right', 0)]
Reward: 289
Iteration 2482 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.27691325298224)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 267.27691325298224)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 374.00179684530843), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 264.94146416826555), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2483 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.49022282135917), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 261.49022282135917), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 364.31586733593076), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 210.95854089195745), ('move_right', 0)]
Reward: 215
Iteration 2484 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 270.3341977325222)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 270.3341977325222)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 356.1267836685293), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 249.95902491778588), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2485 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.1654242516346), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.1654242516346), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 363.30866940273876), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 212.1709786243702), ('move_right', 0)]
Reward: 215
Iteration 2486 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.89948158922834)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.89948158922834)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.8176272793611), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 209.98213482348254)]
Reward: 204
Iteration 2487 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.9359058728698), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 258.9359058728698), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 362.9673621692282), ('move_right', 0)]
best: move_right current state : (2, 3, -9) 150 [('nothing', 0), ('move_right', 203.79146926993874)]
Reward: 204
Iteration 2488 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.8024333721721)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 260.8024333721721)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 360.5669795425975), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 239.47131744245013), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2489 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.9728508376813), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.9728508376813), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.75, -18) -37.241639747 [('nothing', 0), ('move_left', 372.0224475484757), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.01968503705913), ('move_right', 0)]
Reward: 215
Iteration 2490 Learning Q-Table
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.4405538412709)]
best: move_right current state : (2, 3, -23) -100.0 [('nothing', -56.12212641871052), ('move_right', 261.4405538412709)]
best: nothing current state : (1, 1.5, -19) -37.241639747 [('nothing', 369.2382809125533), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 232.1299222097151), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2491 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.0152379268236), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 260.0152379268236), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -37.241639747 [('nothing', 366.8013398349051), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 214.65264341043988)]
Reward: 204
Iteration 2492 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.55930529920374)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 258.55930529920374)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 369.27645604330627), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -1.5, -9) 150 [('nothing', 185.422312034496), ('move_left', 0), ('move_right', -26.285999999999973)]
Reward: 215
Iteration 2493 Learning Q-Table
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.878576575152), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 259.878576575152), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.21459429944133), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 211.45685038730792)]
Reward: 226
Iteration 2494 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.60195859833846)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 259.60195859833846)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 386.28369704219557), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 226.99094554680056), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2495 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.8068899683428), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 257.8068899683428), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 360.5872711258013), ('move_right', 0)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 213.6137795259414), ('move_right', 0)]
Reward: 215
Iteration 2496 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.6462995333377)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 268.6462995333377)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 383.4958715935771), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 223.3936618827604), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2497 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.4685123914843), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 256.4685123914843), ('move_right', -87.43070932334369)]
best: move_left current state : (0, 1.0, -19) -37.241639747 [('nothing', 0), ('move_left', 361.49522364584334), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 221.82369002646925), ('move_right', 0)]
Reward: 215
Iteration 2498 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.14099055325164)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 274.14099055325164)]
best: nothing current state : (1, 1.5, -18) -26.5339353272 [('nothing', 380.46520868033207), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2.0, -8) 150 [('nothing', 220.8755633179323), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2499 Learning Q-Table
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.80403384369598), ('move_right', -87.43070932334369)]
best: move_left current state : (0, -0.0, -24) -100.0 [('nothing', -106.07279994516816), ('move_left', 255.80403384369598), ('move_right', -87.43070932334369)]
best: nothing current state : (0, 0.75, -19) -47.8784607102 [('nothing', 366.15673090756553), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (1, 2, -8) 150 [('nothing', 0), ('move_left', 219.77658301852847), ('move_right', 0)]
Reward: 215
Iteration 2500 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 277.0780753932179)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 277.0780753932179)]
best: nothing current state : (1, 1.75, -19) -37.241639747 [('nothing', 359.1202128406632), ('move_left', 0), ('move_right', 0)]
best: move_left current state : (0, -1.75, -9) 150 [('nothing', 0), ('move_left', 190.9738466522735), ('move_right', 0)]
Reward: 215
Iteration 2501 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 242.80759362065413), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 242.80759362065413), ('move_right', -30.0)]
best: move_left current state : (0, 0.5, -19) -26.5339353272 [('nothing', 0), ('move_left', 351.5176854528383), ('move_right', -30.0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.81979527111554)]
Reward: 215
Iteration 2502 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.5182247033555)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 269.5182247033555)]
best: nothing current state : (1, 1.25, -19) -26.5339353272 [('nothing', 351.5675940673659), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 219.1128943225526), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2503 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 246.46044057215147), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 246.46044057215147), ('move_right', -30.0)]
best: nothing current state : (0, 0.75, -19) -26.5339353272 [('nothing', 367.24268654085444), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (1, 2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 215.57385668978088)]
Reward: 215
Iteration 2504 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.1728549144007)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 265.1728549144007)]
best: nothing current state : (1, 1.25, -19) -26.5339353272 [('nothing', 356.8311841439219), ('move_left', 0), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.8790260257868), ('move_left', 0), ('move_right', 0)]
Reward: 215
Iteration 2505 Learning Q-Table
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 253.73493376460448), ('move_right', -30.0)]
best: move_left current state : (0, -0.5, -24) -100.0 [('nothing', -3.6040987621875944), ('move_left', 253.73493376460448), ('move_right', -30.0)]
best: nothing current state : (0, 0.5, -18) -37.241639747 [('nothing', 318.7097291222741), ('move_left', -52.5), ('move_right', -20.743498289314488)]
best: nothing current state : (2, 3, -8) 150 [('nothing', 214.029645668159), ('move_right', 0)]
Reward: 215
Iteration 2506 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.7101730850992)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 263.7101730850992)]
best: move_left current state : (1, 1.5, -20) -26.5339353272 [('nothing', 0), ('move_left', 341.13591597812547), ('move_right', 0)]
best: nothing current state : (0, -1.75, -11) 150 [('nothing', 193.25088449999998), ('move_left', 0), ('move_right', 0)]
Reward: 152
Iteration 2507 Learning Q-Table
best: move_left current state : (0, 1.25, -24) -100.0 [('nothing', -30.0), ('move_left', 112.21460643145731), ('move_right', 0)]
best: move_left current state : (0, 1.25, -24) -100.0 [('nothing', -30.0), ('move_left', 112.21460643145731), ('move_right', 0)]
best: move_right current state : (1, 2.0, -20) -37.241639747 [('nothing', 0), ('move_left', 0), ('move_right', 340.2601671228103)]
best: move_right current state : (2, 2.0, -9) 100 [('nothing', -75.0), ('move_right', 43.26813)]
Reward: -150
Iteration 2508 Learning Q-Table
best: move_right current state : (1, 2, -24) -100.0 [('nothing', -45.759667591069395), ('move_left', -40.16127660754649), ('move_right', 105.82923671764863)]
best: move_right current state : (1, 2, -24) -100.0 [('nothing', -45.759667591069395), ('move_left', -40.16127660754649), ('move_right', 105.82923671764863)]
best: move_left current state : (0, 0.5, -19) -37.241639747 [('nothing', 0), ('move_left', 355.8083183983215), ('move_right', -30.0)]
best: move_right current state : (0, -2, -9) 150 [('nothing', 0), ('move_left', 0), ('move_right', 208.18749437643777)]
Reward: 152
Iteration 2509 Learning Q-Table
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 106.29917969056234), ('move_right', -32.786626279003926)]
best: move_left current state : (0, 0.5, -24) -100.0 [('nothing', -30.0), ('move_left', 106.29917969056234), ('move_right', -32.786626279003926)]
best: nothing current state : (0, 1.25, -20) -37.241639747 [('nothing', 358.32552012704576), ('move_left', 0), ('move_right', 0)]
best: move_right current state : (2, 2, -9) 150 [('nothing', -75.0), ('move_right', -14.71230899999999)]
Reward: 163
Iteration 2510 Learning Q-Table
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.9777153548492)]
best: move_right current state : (2, 3, -24) -100.0 [('nothing', -101.4), ('move_right', 257.9777153548492)]
best: move_left current state : (1, 1.5, -20) -37.241639747 [('nothing', 0), ('move_left', 341.7704065346878), ('move_right', 0)]
best: nothing current state : (0, -2, -8) 150 [('nothing', 217.01531821805077), ('move_left', 0), ('move_right', 0)]
Reward: 152
